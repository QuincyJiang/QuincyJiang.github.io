{"meta":{"title":"瘟疫青年","subtitle":null,"description":null,"author":"QuincyJiang","url":"http://wenyiqingnian.xyz"},"pages":[{"title":"Categories","date":"2018-10-24T16:07:43.691Z","updated":"2018-05-05T15:10:05.000Z","comments":true,"path":"categories/index.html","permalink":"http://wenyiqingnian.xyz/categories/index.html","excerpt":"","text":""},{"title":"About","date":"2018-11-15T05:06:38.705Z","updated":"2018-06-17T07:11:26.000Z","comments":true,"path":"about/index.html","permalink":"http://wenyiqingnian.xyz/about/index.html","excerpt":"","text":"Name： Quincyjiang Male 24 (1993/08/19) Major：ICS（Information and computer science） Location：Guangzhou，China Contact： &#x31;&#x30;&#x38;&#51;&#x38;&#x37;&#51;&#x32;&#55;&#50;&#x40;&#113;&#x71;&#46;&#x63;&#x6f;&#109; &#106;&#105;&#97;&#x6e;&#x67;&#x39;&#x33;&#48;&#x36;&#50;&#53;&#64;&#103;&#x6d;&#97;&#105;&#108;&#x2e;&#x63;&#x6f;&#x6d; Intro：文艺码农，胶片玩家 skill Java Android Python C/C++ CV(Computer vison)"},{"title":"Tags","date":"2018-11-15T09:17:20.936Z","updated":"2018-05-05T15:10:05.000Z","comments":true,"path":"tags/index.html","permalink":"http://wenyiqingnian.xyz/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"吴恩达深度学习课程笔记 第二周","slug":"吴恩达深度学习课程笔记 第二周","date":"2018-11-15T03:52:50.000Z","updated":"2018-11-15T10:40:24.723Z","comments":true,"path":"2018/11/15/吴恩达深度学习课程笔记 第二周/","link":"","permalink":"http://wenyiqingnian.xyz/2018/11/15/吴恩达深度学习课程笔记 第二周/","excerpt":"","text":"本博是吴恩达DeepLearning.ai 的学习笔记从第二周开始记录 改善深层神经网络： 超参调试、正则化以及优化训练集 开发集 测试集 的划分假设所有的训练数据如下一个典型的数据划分： 即：一部分作为 训练集一部分作为 简单交叉验证集/验证集一部分作为 测试集 具体的流程是 在训练集上 对各模型运行训练算法 将训练完成的模型 带入 交叉验证集 选择出最佳模型然后带入测试集对神经网络做出无偏评估 小数据量的时候，一般会将数据划分为 训练集（70%） 测试集（30%）或者训练集（60%）、验证集（20%、测试集（20%）。在大数据量（百万级）时，验证集 测试集的数据量和小数据量的情况差不多，仍然可能需要成千上万，但是相比百万级的训练集来说，测试集所占的比例理所当然的变小了。比如我们拥有1000000，这么多的数据，训练集：验证集：测试集=98:1:1。 保证 验证集合测试集具有相同的分布有时候 训练集和测试集的数据来源往往不同，比如说 训练集可能是通过爬虫爬取的网页图片，但是测试集是来自用户通过app上传的图片，这些图片的质量和对齐方式参差不齐，这种情况 最好能保证 测试集和交叉验证集具有相同的分布。 为什么要保证分布相同我们先从测试集和验证集的作用开始说起当我们在拿到数据后，会把数据划分为三部分，将训练集丢给模型，这个步骤是为了进行梯度下降，以期得到模型参数。然后拿到训练完成的模型，带入验证集，这个部分是为了检查模型是否能够很好的拟合验证数据，因为这部分数据是没有经过梯度下降的，可以说验证集和测试集没有交集，测试的准确率是可靠的。 但是模型除了普通参数（w和b）之外，还有超参数的存在，当不引入强化学习的情况下，普通参数可以被梯度下降更新，也就是可以被训练集更新，但是为了提高模型性能，我们往往会对 神经网络层数、网络节点数、迭代次数、学习步长等进行调整，这些参数不受梯度下降的影响，一般都是根据验证集的表现情况进行人为调整。 所以可以说，验证集也对学习结果产生了影响，所以需要一份完全没有经过学习影响的数据，来评估最终模型的表现情况，这个就是测试集存在的意义。 为什么要保证测试集和验证集有相同的分布呢？ 因为一旦定义好了测试集和验证集，开发人员的目的就是专注提高验证集的表现，这便要求验证集的选取可以分布均匀，可以体现核心任务。如果验证集和测试集分布不同，就可能导致 系统在验证集上表现良好，在测试集表现不好。这种情况可能会有多种原因： 算法在开发集上过拟合了。 测试集比开发集更难进行预测，尽管算法做得足够好了，却很难有进一步的提升空间。 测试集不一定更难预测，但它与开发集性质并不相同（分布不同）。因此在开发集上表现良好的算法不一定在测试集上也能够取得出色表现。这样就引入了新的不确定性–提高算法在验证集的表现，是否能提高其在测试集的表现？如果是这种情况，大量针对开发集性能的改进工作将会是徒劳的。 如何评估模型表现？ 偏差、方差偏差(bias)：可以理解为 模型在训练集的表现不佳 也就是模型无法很好的拟合数据 称之为欠拟合偏差(variance)：模型在训练集表现良好，但在测试集表现差，模型过于拟合了训练集数据导致无法正确反映数据规律，称之为 过拟合 在实际中，判断偏差和方差一般会通过 训练集和测试集误差来判断 从左到右: 高方差：模型过拟合了 高偏差：模型没有被很好的训练 但是貌似没有过拟合 高方差 高偏差： 模型没有很好拟合数据 同时在测试集表现也不佳 有时有些高维数据中会出现这种情况，就是在某些区域的偏差高，有些区域的方差高 低方差 低偏差： 模型可以很好表现数据特征 即：训练集误差高 表示 偏差大测试集误差高 表示 方差大 关于方差和偏差的数学原理 ，见文章附录[1]。 一个基本流程 123456789101112131415161718st=&gt;start: 获取数据e=&gt;end: 训练结束op=&gt;operation: 评估训练集误差（偏差值）op1=&gt;operation: 评估测试集误差（方差值）op2=&gt;operation: 选择更深层的神经网络或花费更多时间训练算法，或尝试更先进算法op3=&gt;operation: 获取更多数据，或者通过正则化减少过拟合cond=&gt;condition: 偏差正常?cond2=&gt;condition: 方差偏高?st-&gt;opop-&gt;condcond(yes)-&gt;op1cond(no)-&gt;op2op2-&gt;condop1-&gt;cond2cond2(yes)-&gt;op3cond2(no)-&gt;eop3-&gt;cond2 在早期机器学习的时代，我们没有太多工具可以只影响偏差或者方差的一种而不对另一种造成影响，所以往往需要在两者间权衡。现在在大数据时代，我们有了一些工具，比如只要对数据进行适当正则，再构建一个更大的神经网络，就可以在几乎不影响方差的情况下，减少偏差。而采用更多数据，或者对数据正则化，可以在不过多影响偏差的情况下，减少方差 降低方差的手段：正则化出现高方差往往就表示，模型对数据过拟合了。前面讲到 降低方差的手段，可以通过获取更多数据或者对数据进行正则来实现。 更多数据的获取，实现起来成本比较高，那正则化又为什么可以减少方差呢？ 如何实施正则化logistic 回归我们之前定义的损失函数为 现在在其基础上加上正则化参数 也就是向量w的二范数（也有使用一范数的，但目前更多倾向于使用二范数） 至于b的正则化参数，可加可不加，因为w通常是一个高维度的矩阵，它已经包含很多参数了，b只是众多参数的其中之一，加不加影响也不是很大。 其中 λ是正则化参数。这个参数需要我们在验证集经过多次调试来选择最佳取值，λ属于超参数的一种。 神经网络神经网络和logistic回归的差别在于，神经网络是有多层隐藏神经元的数学模型。 它的正则化参数则是将所有层的w向量写成一个矩阵后 矩阵W的二范数，在DL中，习惯将矩阵的二范数称之为 F范数，或者弗罗贝尼乌斯范数 在之前的梯度下降过程中，我们通过反向传播 计算出了原始J对w[l]的导数：现在代价函数J增加了一项正则化参数对正则化参数求导 为 则新的dw[l]为 带入w[l] = w[l]-α*dw[l]得到 可以看到，如果将w[l]提取出来，每次反向传播后，更新的权重值相当于在其前面乘上了这么一个参数： 显而易见这个参数是小于1的。 所以L2正则化也被称之为 权重衰减 所以 对神经网络 应用L2 正则化的过程 其实相当于在每次反向传播更新梯度的过程中，对w[l]乘上了一个小于1的参数1-αλ/m这个参数是小于1的，所以 L2正则化 也被称之为 权重衰减。 为什么正则化可以减少过拟合从直观上理解，因为我们的代价函数加上了对权重矩阵W的正则化参数，也就是W的F范数，在训练过程中，为了降低代价函数J，必然会压缩正则化参数，当λ设置的足够大，会导致矩阵W的F范数接近于0，也就意味着W中的很多元素变为了0，等于原始神经网络中的很多神经元失去了作用，模型也被精简了。 此时模型越来越趋近于logistic回归模型过于简单的时候，会导致偏差变高，模型甚至无法很好的拟合数据。但这种W中参数变为0的情况在现实情况下一般不会发生，往往是某些w会变得很小，等于在训练过程中，这些神经元没有消失，只不过权重值变得很小而已。这样来看，貌似神经网络变得更简单了，这样更不容易出现过拟合。 下面举一个直观一些的例子。 假设每一层的激活函数都是tanh(),tanh()函数具有一个特殊性质，就是当x范围比较小的时候，tanh()接近y=x。 当我们对神经网络施加L2正则化，在训练中会导致w变小，又因为g(z)中的z 等于 当w[l]变小，会导致z[l]变小，当z落在tanh的中间那一小部分范围时，整个神经网络只利用到了tanh的线性部分，模型也会趋近于线性回归。这样会有效降低过拟合出现的情况 另一种正则化方式： Dropout正则化Dropout，也被称之为随机失活。其实就是 令神经网络的每一层的每个神经元，按照一定的概率失活。我们将原始训练集分为若干子集，对每一个子集，都利用一次dropout 假设在这个神经网络中，我们设置每个元素的失活概率为0.5，那么在这个子集中，我们便会得到一个精简的神经网络 对每一个训练子集机型dropout，便会得到很多精简的神经网络，我们对每一个神经网络进行训练。其实这里也能看出来，为什么dropout可以有效防止过拟合，以为实施过dropout的神经网络变小了。 下面以python代码示例 12345678910import numpy as np# 假设当前为layer3# 意味每个单元的保留概率是0.8 keep-prop = 0.8 # 生成一个随机矩阵，该矩阵和a3具有相同的行列数，且矩阵中 任一元素 d3[i,j] = 0的概率是0.2，等于1的概率是0.8d3 = np.random.rand(a3.shape[0],a3.shape[1])&lt;keep-prop# 重新计算a3a3 = np.multiply(a3,d3)# 除以keep-prop的目的是为了不减少a3的期望a3 /= keep-prop","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://wenyiqingnian.xyz/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://wenyiqingnian.xyz/tags/机器学习/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://wenyiqingnian.xyz/tags/Tensorflow/"}]},{"title":"机器学习算法的演进","slug":"机器学习算法的演进","date":"2018-11-11T11:33:50.000Z","updated":"2018-11-12T01:41:59.229Z","comments":true,"path":"2018/11/11/机器学习算法的演进/","link":"","permalink":"http://wenyiqingnian.xyz/2018/11/11/机器学习算法的演进/","excerpt":"","text":"人工智能、机器学习、深度学习三者的关系：人工智能/AI：这是对高级计算智能的最宽泛的说法。1956年，在达特茅斯人工智能大会上，该技术被描述为：“原则上，学习的每一个方面或任何其他智能特征都可以精确描述，并且一台机器可以模拟它。”。AI 可以分为大致三个种类： 狭义AI、通用AI、超AI。狭义AI 就类比与深蓝计算机以及AlphaGO，只在特定领域表现出色，而通用AI则彼此更高一层，成为与人类大脑具有相同本质的智慧体从而具有解决一系列问题的能力。超AI则是目前人工智能科学家的终极梦想，此时的机器具备观察和感知的能力，具备超越人类的创造力。 机器学习/ML： 一种实现人工智能的方法机器学习最基本的做法，是使用算法来解析数据、从中学习，然后对真实世界中的事件做出决策和预测。与传统的为解决特定任务、硬编码的软件程序不同，机器学习是用大量的数据来“训练”，通过各种算法从数据中学习如何完成任务。举个简单的例子，当我们浏览网上商城时，经常会出现商品推荐的信息。这是商城根据你往期的购物记录和冗长的收藏清单，识别出这其中哪些是你真正感兴趣，并且愿意购买的产品。这样的决策模型，可以帮助商城为客户提供建议并鼓励产品消费。 机器学习直接来源于早期的人工智能领域，传统的算法包括决策树、聚类、贝叶斯分类、支持向量机、EM、Adaboost等等。 从学习方法上来分，机器学习算法可以分为监督学习（如分类问题）、无监督学习（如聚类问题）、半监督学习、集成学习、深度学习和强化学习。 传统的机器学习算法在指纹识别、基于Haar的人脸检测、基于HoG特征的物体检测等领域的应用基本达到了商业化的要求或者特定场景的商业化水平，但每前进一步都异常艰难，直到深度学习算法的出现。 所谓深度学习的深度，指的是神经网络的层数，机器学习算法经过： 单层感知机：心理学家Rosenblatt提出，对复杂函数无能为力 多层感知机：多层感知机可以摆脱早期离散传输函数的束缚，使用sigmoid或tanh等连续函数模拟神经元对激励的响应，在训练算法上则使用Werbos发明的反向传播BP算法。这就是我们现在所说的神经网络，但多层感知机面临的致命问题是：随着神经网络层数的加深：一是优化函数越来越容易陷入局部最优解，并且这个“陷阱”越来越偏离真正的全局最优。利用有限数据训练的深层网络，性能还不如较浅层网络。二：“梯度消失”现象更加严重 深度学习：2006年，Hinton利用预训练方法缓解了局部最优解问题，将隐含层推动到了7层，神经网络真正意义上有了“深度”，由此揭开了深度学习的热潮，随后的DBN、CNN、RNN、LSTM等才逐渐出现。 这里的“深度”并没有固定的定义——在语音识别中4层网络就能够被认为是“较深的”，而在图像识别中20层以上的网络屡见不鲜。 为了克服梯度消失，ReLU、maxout等传输函数代替了sigmoid，形成了如今DNN的基本形式。单从结构上来说，全链接的多层感知机是没有任何区别的。 深度学习/DL： 如上所言，深度学习是机器学习算法演进过程中诞生的一种。深度学习本来并不是一种独立的学习方法，其本身也会用到有监督和无监督的学习方法来训练深度神经网络。但由于近几年该领域发展迅猛，一些特有的学习手段相继被提出（如残差网络），因此越来越多的人将其单独看作一种学习的方法。 深度神经网络的三个致命问题：深度神经网络有三个致命问题： 非凸优化问题，即优化函数越来越容易陷入局部最优解；线性回归，本质是一个多元一次函数的优化问题，设f(x,y)=x+y多层神经网络，本质是一个多元K次函数优化问题，设f(x,y)=xy在线性回归当中，从任意一个点出发搜索，最终必然是下降到全局最小值附近的。所以置0也无妨（这也是为什么我们往往解线性回归方程时初值为0）。而在多层神经网络中，从不同点出发，可能最终困在局部最小值。局部最小值是神经网络结构带来的挥之不去的阴影，随着隐层层数的增加，非凸的目标函数越来越复杂，局部最小值点成倍增长，利用有限数据训练的深层网络，性能还不如较浅层网络。。避免的方法一般是权值初始化。为了统一初始化方案，通常将输入缩放到[−1,1]，但是仍然无法保证能够达到全局最优，其实这也是科学家们一直在研究而未解决的问题。所以，从本质上来看，深度结构带来的非凸优化仍然不能解决（包括现在的各类深度学习算法和其他非凸优化问题都是如此），这限制着深度结构的发展。 （Gradient Vanish）梯度消失问题；梯度爆炸和梯度消失问题都是因为网络太深，网络权值更新不稳定造成的，本质上是因为梯度反向传播中的连乘效应。对于更普遍的梯度消失问题，可以考虑用ReLU激活函数取代sigmoid激活函数。另外，LSTM的结构设计也可以改善RNN中的梯度消失问题 过拟合问题过拟合，庞大的结构和参数使得，尽管训练error降的很低，但是test error却高的离谱。当出现梯度消失时，上层神经元的梯度变化非常小，几乎相当于把原始输入信息，没有经过任何非线性变换，或者错误变换推到高层去，使得高层解离特征压力太大。如果特征无法解离，强制性的误差监督训练就会使得模型对输入数据直接做拟合，就会出现训练方差大的问题 深度学习的常见模型：这张图基本囊括了目前常见的主流神经网络模型","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://wenyiqingnian.xyz/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://wenyiqingnian.xyz/tags/机器学习/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://wenyiqingnian.xyz/tags/Tensorflow/"}]},{"title":"下个阶段的学习计划整理","slug":"八月份学习计划","date":"2018-08-21T09:12:50.000Z","updated":"2018-08-21T09:13:54.000Z","comments":true,"path":"2018/08/21/八月份学习计划/","link":"","permalink":"http://wenyiqingnian.xyz/2018/08/21/八月份学习计划/","excerpt":"","text":"下个阶段的学习计划整理基础知识 YUV RGB的图像表示方式 PCM音频数据处理 H.264 编码格式 android平台的MediaCodec AAC音频流 视频的几种封装格式 传输协议 UDP/RTP 协议 框架 FFmpeg 要看的书 音视频开发进阶指南 机械工程出版社 展晓凯 著","categories":[{"name":"学习计划","slug":"学习计划","permalink":"http://wenyiqingnian.xyz/categories/学习计划/"}],"tags":[{"name":"android","slug":"android","permalink":"http://wenyiqingnian.xyz/tags/android/"},{"name":"音视频","slug":"音视频","permalink":"http://wenyiqingnian.xyz/tags/音视频/"},{"name":"学习计划","slug":"学习计划","permalink":"http://wenyiqingnian.xyz/tags/学习计划/"}]},{"title":"一些知识点总结","slug":"一些知识点总结","date":"2018-08-16T11:00:50.000Z","updated":"2018-08-16T10:04:17.000Z","comments":true,"path":"2018/08/16/一些知识点总结/","link":"","permalink":"http://wenyiqingnian.xyz/2018/08/16/一些知识点总结/","excerpt":"","text":"博客好久没更新了，把最近总结的一些零星知识点汇总一下吧。 view 绘制流程相关：如何在activity中正确获取view的宽高： activity/view onwindowFocusChanged() view.post(new Runnable{}) ViewTreeObserver.addOnGlobalLayoutListener(); 手动调用view.measure(); setWillNotDraw()如果view不需要绘制任何内容，设置这个标记为true后系统会对其进行优化，默认View是没有启用的，但是viewGroup会默认启用，当我们开发的自定义控件继承viewGroup且本身不具备绘制功能，就可以开启该标记位便于系统优化。如果需要绘制内容，要显示关闭。 当子view的measureSpec的type是unspecified时子view的宽高是getSuggestMinWidth/Height 来获取的，如果有背景图，为背景图宽高，否则为布局制定的android:minWidth属性 （默认为0） layout过程自己的位置是由layout()方法决定，layout()中首先会调用setFrame() 来决定自己的上下左右位置，其次调用onLayout() 来确定子view的位置，不**同的viewGroup需要继承并自己实现其逻辑。 MotionEvent()getX/getY getRawX getRawY 返回的分别为 相对于当前view左上角的x 和 y 以及相对于屏幕左上角的 x 和 y坐标。 view 的事件分发 当事件走到view这一层级的时候，首先会回调dispatchTouchEvent() –&gt; 是否设置了onTouchListener? 设置了 –&gt; 回调 onTouch() 并看onTouch的返回值 如果返回true -&gt; 回调 onTouchEvent() 否则 不回调onTouchEvent() view 的onTouchEvent()，先判断是否可用，如果不可用，当view可点击（长按 短按都行）会默认消费掉事件，当view可用，通过event.getAction（）判断当前事件类型，在actionUP的时候，调用performClick(),会判断是否调用OnClick() 和 onLongClick(). 当viewGroup决定拦截事件后，后续的事件都会交给她处理，不会再走onInterceptTouchEvent()方法，因为在调用onInterceptTouchEvent（）之前会判断mFirstTouchTarget是否为空，如果viewGroup自己拦截处理，onInterceptTouchEvent = null 就进不到判断里，也就不走onInterceptTouchEvent（）了。 当子view设disallowInterceptTouchEvent()之后，会修改父view的FLAG_DISALLOW_INTERCEPT 这个标记位，一旦设置之后，viewGroup就无法拦截down以后的事件了，但下次是还是可以收到down事件，因为在down事件来临的时候，viewGroup会重置这个标志位。也就是shidisallowInterceptTouchEvent()无法阻止父view 对down事件的处理。 当viewGroup不打算拦截，会将事件分发给子view，首先先判断哪些在触摸范围的子view，然后依次调用他们的dispatchTouchEvent 一般处理滑动冲突，最好用外部拦截法a. 重写父view的OnInterceptTouchEvent()b. 父容器的ACTION_DOWN必须返回false 如果返回true 后续事件将都有他处理，子view是收不到其他事件的c. ACTION_MOVE 要根据业务需求决定是否拦截d. ACTION_UP 必须返回false 因为这个事件作为事件结尾本身没有什么意义，而且如果返回true，子view将收不到up事件，onclick方法将无法触发。 requestLayout、invalidate与postInvalidaterequestLayout：当前view将自己设置一个flag 同时调用父view的requestLayout，父view会设置一个标志位：PFLAG_FORCE_LAYOUT，这样逐级上调，直到decorView，decorView会吧view上报到viewRootImpl上，viewRootImp会调用 requestLayout(),依次触发子view的measure layout draw方法。 invalidatainvalidate有多个重载方法，但最终都会调用invalidateInternal方法，在这个方法内部，进行了一系列的判断，判断View是否需要重绘，接着为该View设置标记位，然后把需要重绘的区域传递给父容器，即调用父容器的invalidateChild方法。 在该方法内部，先设置当前视图的标记位，接着有一个do…while…循环，该循环的作用主要是不断向上回溯父容器，求得父容器和子View需要重绘的区域的并集(dirty)。当父容器不是ViewRootImpl的时候，调用的是ViewGroup的invalidateChildInParent方法，我们来看看这个方法，ViewGroup#invalidateChildInParent: 这个方法做的工作主要有：调用offset方法，把当前dirty区域的坐标转化为父容器中的坐标，接着调用union方法，把子dirty区域与父容器的区域求并集，换句话说，dirty区域变成父容器区域。最后返回当前视图的父容器，以便进行下一次循环。 回到上面所说的do…while…循环，由于不断向上调用父容器的方法，到最后会调用到ViewRootImpl的invalidateChildInParent方法该方法所做的工作与上面的差不多，都进行了offset和union对坐标的调整，然后把dirty区域的信息保存在mDirty中，最后调用了scheduleTraversals方法，触发View的工作流程，由于没有添加measure和layout的标记位，因此measure、layout流程不会执行，而是直接从draw流程开始。 好了，现在总结一下invalidate方法，当子View调用了invalidate方法后，会为该View添加一个标记位，同时不断向父容器请求刷新，父容器通过计算得出自身需要重绘的区域，直到传递到ViewRootImpl中，最终触发performTraversals方法，进行开始View树重绘流程(只绘制需要重绘的视图)。 postinvalidata发送了一个异步消息到主线程，显然这里发送的是MSG_INVALIDATE，即通知主线程刷新视图 activity的启动流程 A activity启动B activity A 最终调用startActivityForResult() Instrumentation.exeStartActivity() ActivityManagerNative.getDefault() 通过binder机制 获得远端AMS的引用，在创建这个Binder对象时，传入了一个IBinder，其实是ServiceManager获得的，这个IBinder持有远端AMS服务的handle值，作为跟远AMS交流的信使。 AMS.startActivity【此处有个分水岭 如果应用没有启动过 任务战中尚无待启动的应用程序 会走下面的流程 当应用是首次启动 会走22】 ActivityStackSupervisor.startActivityMayWait() ActivityStackSupervisor.startActivityMayWait().startActivityLocked() startActivityLocked().startActivityUncheckedLocked() ActivityStack.resumeTopActivitiesLocked 回到ActivityStackSupervisor，调用到realStartActivityLocked() 通过binder机制 调用会ApplicationThread(本身是个binder类型，被AMS远程访问)的scheduleLaunchActivity() 发送一个启动activity的消息给handler H处理。 H 收到之后，调用ActivityThread 的handleLaunchActivity（） 在handleLaunchActivity() 中，调用performLaunchActivity 完成activity的创建 在performLaunchActivity中，通过ActivityClientRecord 获取启动的activity信息，通过Instrumentation的newActivity 使用类加载器创建activity，通过LoadApk 创建Application对象，其实还是通过Instrumentation通过类加载器创建的，随后会调用application类的onCreate方法。创建ContextImp对象，并调用activity的attach方法，在attach方法中完成对window的创建，调用activity的onCreate方法。 在attach中，创建了window接口的唯一实现类PhoneWindow对象，并将activity设置为window的回调接口（activity默认是实现了这些接口的），也就是我们在activity中可以复写的onAttachedToWindow,onDetachedToWindow之类。 回调activity的onCreate（）方法 执行setContentView（） setContentView()实际是PhoneWindow执行的，首先创建顶级视图decorView 并把自定义布局添加到decorView中，此时该视图还没被添加到window中 handleLaunchActivity之后会立刻回调onResume方法 会回调activity的makeVisible() 此时decorView 才真正被添加到PhoneWindow中，也就是执行了window.addView方法 addView方法中，会创建viewRootImp 并将view添加到列表中，将viewRootImp添加到mRoots列表中 调用viewRootImp的setView（） 在该方法内部会调用 requestLayout()开启异步刷新请求，通过scheduleTraversals()开始一次调用view的 onMeasure onLayout onDraw 注意viewRootImp的绘制方法 都是通过WMS 通过binder机制完成的。 如果应用尚未启动过，AMS的startActivity() 会调用zygoteSendAndGetResult() , 通过socket方式通知zygote进程为待启动应用fork一个新进程。 fork新进程，其实就是创建了一个ActivityThread，并执行main()方法。 在目标activity的ActivityThread的main() 方法中，首先创建ActivityThread对象实例。 调用thread.attach() ，通过binder机制 通过AMS最终调用到ApplicationThread的bindApplication()方法。通过H handler发送了一H.BIND_APPLICATION的消息。 在attach方法内部 初始化了一个叫做H的handler 并开始looper.loop 轮训获取消息。 当H收到bindApplication的消息后，调用handleBindApplication()方法，通过loadAPK.makeApplication()来创建Application对象，此时application还是通过instrument对象通过反射创建的，创建完成之后调用application的oncreate，并创建ContextImp对象。 回到14 A 的activity 中 通过Instrumentation.checkStartActivityResult() 检查启动是否正常，不正常会抛出相应异常 12345678910Application 构造函数-&gt; Application.attachBaseContext()-&gt; Application.onCreate()-&gt; Activity 构造函数-&gt; Activity.setTheme()-&gt; Activity.onCreate()-&gt; Activity.onStart-&gt; Activity.onResume-&gt; Activity.onAttachedToWindow-&gt; Activity.onWindowFocusChanged 如果要记录应用启动时间 在attachBaseContext()中打log 为启动开始时间在activity的onWindoewFocusChanged() 打log记录结束时间， 热更新 PathClassloader 和 DexClassLoader均继承自BaseDexClassLoader pathClassLoader只能加载安装包安装后解压路径下的dex文件，而DexClassLoader可以加载jar包,zip文件，APK文件中的dex文件，所以DexClassLoader肯定有一步解压操作，将压缩包的dex文件解压到制定目录，所以再构造函数中需要传入一个解压目录 在父类BaseDexClassLoader的loadClass()方法中，实际是通过dexPathList的findClass 来查找class的 DexPathList的构造函数中，保存了当前的类加载器，同时将一个个的apk，dex，zip、jar之类的文件封装为一个个的Element，添加到Elements集合中，每个Element元素中都保存着对应的dex文件dexFile。 封装Element的过程调用的makeDexElements()方法，用loadDexFile() 来装载dex文件 调用DexPathlist的findClass(),其实就是遍历Elements集合，对每个Element，DexFile dex = element.dexFile 取出dexFile，并调用loadClassBinaryName()来加载class 热修复的原理 热修复步骤：a. 定义好要修复的java文件，先编译为class，再编译为dexb. 也可以创建个压缩包或者apk文件或者jar包，但要求是apk文件解压后里面必须有一个class.dex 的文件，因为DexPathList类中的loadDexFile方法中会对这个做判断，如果没有就会报异常。c. 123456789101112131. PathClassLoader pathLoader = (PathClassLoader) appContext.getClassLoader();2. DexClassLoader dexLoader = new DexClassLoader( dex.getAbsolutePath(),// 修复好的dex（补丁）所在目录 fopt.getAbsolutePath(),// 存放dex的解压目录（用于jar、zip、apk格式的补丁） null,// 加载dex时需要的库 pathLoader// 父类加载器3.合并 Object dexPathList = getPathList(dexLoader); Object pathPathList = getPathList(pathLoader); Object leftDexElements = getDexElements(dexPathList); Object rightDexElements = getDexElements(pathPathList);4. 合并完成 Object dexElements = combineArray(leftDexElements, rightDexElements);5. 重写给PathList里面的Element[] dexElements;赋值 Object pathList = getPathList(pathLoader);// 一定要重新获取，不要用pathPathList，会报错6. setField(pathList, pathList.getClass(), \"dexElements\", dexElements); 9 . 各热更新框架的差异 阿里andFix hook 方法在native的具体字段。art虚拟机上是一个叫ArtMethod的结构体。通过修改该结构体上有bug的字段来达到修复bug方法的目的，但这个artMethod是根据安卓原生的结构写死的，国内很多第三方厂家会改写ArtMethod结构，导致替换失效。 qq的dex插装就类似上面分析的那种。通过将修复的dex文件插入到app的dexFileList的前面，达到更新bug的效果，但是不能及时生效，需要重启。但虚拟机在安装期间会为类打上CLASS_ISPREVERIFIED标志，是为了提高性能的，我们强制防止类被打上标志是否会有些影响性能 美团robust 是在编译器为每个方法插入了一段逻辑代码，并为每个类创建了一个ChangeQuickRedirect静态成员变量，当它不为空会转入新的代码逻辑达到修复bug的目的。有点是兼容性高,但是会增加应用体积 网络请求框架：volley适合轻量 频率快的网络请求因为volley的异步任务 其实用的是一个默认数量为4的固定数量线城池，超过4个线程会排在等待队列中阻塞。volley为了提高速度 做了一些优化： 请求是用队列维护的 而且可以设置队列的出入方式 对response做了缓存，如果下次请求的内容没变会优先从缓存中获取 网络请求的数据 是在工作线程中进行解析并分发到主线程，所以volley的回调是在主线程中，可以直接操作ui，okhttp是回调在工作线程的。 重要】：volley为了提高访问速度，会将整个response加载在内存中，所以如果下载的文件太大 会引发oom，但是它存储在内存中又是一个缓冲池实现的，ByteArrayPool，每次需要保存数据 先看缓冲池中有无可用空间，有的话就可以直接复用，减少了内存分配的次数，所以比较适合小数据量 但是频繁访问的场景。 换肤 主要是反射获取AssetManager 然后反射调用AssetManager的addAssetPath() 方法 将自定义的资源文件（可以是zip 或者apk的路径）加入AssetManager之后，重新构造一个Resource对象。 1new Resources(assetManager,context.getResources().getDisplayMetrics(),context.getResources().getConfiguration()); layoutInflator.Factory()对象是一个会根据布局树来依次生成对应view的类，我们可以hook这个类的方法，对其生成相关view的逻辑做修改，比如就可以通过下面的方式，将id = R.id.text的一个TextView 改为一个button 123456789101112131415161718192021222324252627LayoutInflater.from(this).setFactory(new LayoutInflater.Factory() &#123; @Override public View onCreateView(String name, Context context, AttributeSet attrs) &#123; if (\"TextView\".equals(name)) &#123; Log.e(TAG, \"name = \" + name); int n = attrs.getAttributeCount(); //打印所有属性标签 for (int i = 0; i &lt; n; i++) &#123; Log.e(TAG, attrs.getAttributeName(i) + \" , \" + attrs.getAttributeValue(i)); &#125; for (int i = 0; i &lt; n; i++) &#123; if (attrs.getAttributeName(i).equals(\"id\")) &#123; String attributeValue = attrs.getAttributeValue(i); String id = attributeValue.substring(1, attributeValue.length()); if (R.id.text == Integer.valueOf(id)) &#123; Button button = new Button(context, attrs); button.setBackgroundColor(Color.RED); return button; &#125; &#125; &#125; &#125; return null; &#125; &#125;); setContentView(R.layout.activity_main); 为所有activity写好基类，在基类的onCreate()方法中，将我们自定义的LayoutInflator.Factory设置给当前activity的LayoutInflator。 在自定义的LayoutInflator中，首先根据我们自己定义的tag来判断是否需要换肤，如果需要，先通过layoutInflate将当前view创建出来，然后将需要换肤的view的属性值去除一些带“@”符号的资源引用的，做成一个集合，集合的每个成员里都带有当前需要换肤的view 以及view需要更换的属性（比如 字体颜色，背景色之类的） 通过前面创建的皮肤资源Resource 来获取需要婚换肤的资源，比如对应的夜间模式的颜色，drawable之类。mResources.getIdentifier(resName, &quot;color&quot;, skinPackageName); lrucache的实现原理Lrucache在初始化的时候 需要指定缓存大小 以及缓存文件大小的计算方法 sizeof()内部实现其实是用了一个LinkedHashMapL&lt;k,v&gt; 来实现保存缓存文件的。 每次添加缓存文件到缓存中时，都会调用trimToSize()方法。先计算当前缓存文件大小，与已使用缓存大小做比较，当缓存文件不够用的时候会调用LinkedHashMap 的eldest查找到最久未使用的文件，将其从hashMap中删除，将缓存文件加入hashMap中同时更新已使用缓存大小。 crash的相关处理：java crash 查看崩溃类型 是否是哪几种特定类型比如badTokenException 一般是activity正在销毁但是Fragment要弹吐司或者dialog导致的。一般是异步请求会出现这种情况 查看是否进行过异常处理，有些方法的执行过程出错了，但是因为在代码层进行了trycatch，导致应用并没有崩溃，但是传递了错误的执行结果导致后面的方法出现crash 查看崩溃机型，有些rom厂商会对rom进行深度定制导致部分方法会crash。尤其国产厂商会对权限做更严格的限制，稍有不慎就会导致意料之外的结果，比如华为手机7.0之后申请牌照权限 除了要申请camera之外，还要申请读写外部存储。 注意异步操作，可能会内存泄漏导致溢出。 自定义一个UncaughtExceptionHandler 因为当appcrash的时候，系统会恢复activitiy栈的的第一个activity，有时候会导致不停崩溃，最好在handler中将应用任务栈中的activity清空，并调用System.exit(0) 还是使用uncaughtExceptionHandler来捕获crash堆栈信息并上传服务器。 通过替换ActivityThread的H handler对象来达到统一处理异常，并处理异常Activity的声明周期，减少不必要crash的发生。通过 123456789101112Looper.getMainLooper.post(new Runnable()&#123; void run()&#123; while(true)&#123; try&#123; Looper.loop(); &#125; catch&#123; handleException(); &#125; &#125; &#125;&#125;) native crash 检查对应abi 版本 使用对应的工具 查看错误地址，判断是不是空指针异常 用add2line还原堆栈，看调用方法信息 如果还分析不出为什么出错，就要还原当时的寄存器现场和内存现场 JNI技术相关 jni的方法可以动态注册 也就可以静态注册 在java层写好native 方法名，如果是 动态注册 将方法的全路径名写上 将点 换成下划线 比如 `JNIEXPORT void JNICALLJava_android_media_MediaScanner_processFile (JNIEnv *, jobject, jstring,jstring, jobject); ， 动态注册 通过JniNativeMethod结构体列表来实现，static JNINativeMethod gMethods构建一个JniNativeMethod结构体 需要传入方法名，方法签名（根据传入参数和返回值类型来生成的一定格式的字符串）以及一个jni层对应的函数指针 然后调用AndroidRuntime::registerNativeMethods`来动态注册jni方法 动态注册 是当调用 system.loadLibrary（）时，系统会在native层寻找JNI_OnLoad函数 在这里要完成动态注册的工作 JNIEnv是线程相关的，每个线程独一份儿，当我们要手动从一个native方法回调java层方法时，需要手动传入一个JNIEnv，这个JNIEnv需要从JavaVM构造，JavaVM会在 JNI_OnLoad方法中由jvm传递给native，\u0016JNIEnv.AttachCurrentThread 来获取一个当前线程的jniEnv。当然退出的时候还要DetachCurrentThread 来释放资源 通过JniEnv调用方法 NativeType Call&lt;type&gt;Method(JNIEnv *env,jobject obj,jmethodID methodID, ...)。 操作成员变量 123 NativeType Get&lt;type&gt;Field(JNIEnv *env,jobject obj,jfieldID fieldID)//或者调用Set&lt;type&gt;Field系列函数来设置jobject对应成员变量的值。void Set&lt;type&gt;Field(JNIEnv *env,jobject obj,jfieldID fieldID,NativeType value) 并发相关 启动一个新线程 继承thread 对象复写run方法 或者创建一个runnable对象，其实这两种方式没有太大区别，本质上Thread 对象就是一个runnable接口的实现类，网上很多人说 头一种方式不面向对象，不能复用资源是由继承 这种创建方式导致的，其实你完全可以new 一个thrad对象 把它像runable一样交给一个thread 同样可以达到复用资源的目的（本质上会吧这个thread 赋值给Thread中的target） 新建线程 使用start（） 如果调用run() 实际是在调用线程去执行Thread 中run方法的内容 线程挂起有两种方式：sleep() 不释放锁，wait() 会释放锁 终止线程不要使用stop() 因为该方法过于暴力，会直接终止当前线程并释放锁，可能造成数据不一致 导致安全隐患。 如何实现多线程通讯：通过共享对象，或者使用wait notify，但是要注意假唤醒和唤醒型号丢失，唤醒信号丢失是指 当a线程调用notify时，等待池中尚无等待锁对象的线程，此时信号就丢失了，当b线程再调用wait的时候就永远不会被唤醒，解决办法是b线程调用wait的时候，先判断一下有无线程调用过notify。 假唤醒是指有时候线程会因为一些莫名其妙的原因在没有notify的时候被jvm唤醒，解决办法是使用while循环轮训判断是否有线程调用过nofity，这种类似于java的自旋，但是比较消耗cpu。记住不要对字符串常亮或者全局对象中使用wait和notify。 如何停止一个正在运行的线程？ 设置一个判断标识。通常是一个volentaile类型的变量。如果标识被设置为false 就停止运行，不要直接调用stop。 suspend 和 resume 方法已经过时了，因为这两个方法使用时序不当会非常容易造成死锁。 因为suspend 会让线程挂起吗，但是却不会释放锁。只有当该线程被其他线程调用了resume() 之后 才会继续执行。但如果其他线程调用t1的resume时要获得锁，这时候死锁就产生了 t2始终无法获得锁，t1永远无法被唤醒。 reentranLock 可重入锁和syncornoized的比较：首先 reentranLock 的设计并不是为了替代syncornized。只是为了在syncornized不能满足使用需求时，为加锁增加一些新的特性。syncornized 的缺点：无法中断一个正在等待锁的线程，当多个线程争夺某个锁时，未获得的对象只能不断等待锁对象的释放而不能终端这个过程。对于大量线程争夺锁的情况性能比较低。reentranLock 是对固有锁的补充，提供了可中断lockInterruptibly()，可等待tryLock，超时中断 tryLock(long, TimeUnit)，公平和非公平锁的实现。而且在某些jvm版本上提供了比固有锁更好的性能。 但是不会自动释放锁，需要在final块中 手动实行释放操作。 新的jdk已经对固有锁做了很多优化，尤其是针对固有锁无法中断导致多线程争夺场景下性能低的情况。比如增加了偏向锁，轻量级锁和重量级锁的特性。当多线程的执行过程类似于顺序执行时，jvm会默认使用偏向锁来提高并发性能，当一旦出现多线程争夺，便会膨胀为重量级锁。 相同点：都是可重入锁 多线程协作： 主要是解决同步互斥、资源互斥、协调竞争的问题。可以使用syncnornized lock wait notify 以及信号量Semaphore、CountdownLatch来解决互斥同步问题。 注意 sleep会抛出InteruptException异常。 乐观锁：每次操作时不加锁，而是假设没有冲突去完成某项操作，如果因为冲突失败，就去重试知道成功为止。 可以使用volatile 和 cas原语实现（a.compateAndSet(oldValue,newValue)）;在操作前每次先读取这个volatile修饰的字段，判断与旧值是否相等，相等则操作，否则重试。可以避免阻塞。 悲观锁：每次操作前先尝试获取锁，获取不到就等待，直到某个线程释放了锁为止。可以使用syncornize和lock实现。 悲观锁会频繁的导致线程挂起和恢复执行，这个开销非常重量级，会导致时间代价比较大 判断线程是否拥有锁： Thread.holdsLock() 返回true表示拥有一个具体锁 如果你提交任务时，线程池队列已满。会时发会生什么？这个问题问得很狡猾，许多程序员会认为该任务会阻塞直到线程池队列有空位。事实上如果一个任务不能被调度执行那么ThreadPoolExecutor’s submit()方法将会抛出一个RejectedExecutionException异常 Interupt()方法会将isInterupt置为false。 但是不可以对一个已经调用了sleep() 的方法执行interupt，会抛异常，而且在异常块里，会将isInterupt的值置为true。 为什么进行指令重排序：为了提高效率，现代cpu都是采用流水线来执行指令。一个操作会被分为：取指令，译码，访存，执行，写回等若干阶段，多条指令可以同时存在在流水线中并行执行，为了避免一条指令的执行过程太长导致后续指令都卡在执行之前，cpu会对令重拍以提高效率。 Condition 是与lock配合使用的，也称为条件队列 或条件变量，主要作用是 a: 以原子方式 释放相关的锁，并挂起当前线程 b: 唤醒相关等待队列的线程，是为了解决Object.wait/notify/notifyAll 不好用而出来的。 wait 和 notify 只有一个阻塞队列，如果在生产者和消费者模型中，想当产品满了唤醒一个消费者线程 如果使用wait，无法保证唤醒的一定是消费者线程，因为只有一个阻塞队列，队列中可能会有生产者线程 也可能会有消费者线程，wait会从等待队列中随机唤醒一个 所以wait 是有局限性的。 我们可以实现两个Condition 条件队列，生产者线程一个 消费者线程一个 当我们想唤醒对应线程 只需要调用对应的条件队列就可以了。如果是用syncornized 对应的就是wait 和 nofity。 如果是用并发包的lock reentranlock 对用的就是await signal signalAll。 Semaphore 等于是个共享锁 和Lock类似 可以为他设置值，如果设为1 就等于lock ThreadLocal的实现： ThreadLocal set的时候，会传入一个Thread对象。通过Thread对象获取其中的成员变量ThreadLocalMap threadLocals ，如果没有就创建，有就往里面写值。 可以看到 ThreadLocal真正存储数据其实是放在Thread对象中的，这就是为什么ThreadLocal可以做到线程隔离的原因，但是ThreadLocalMaps其实是ThreadLocal的内部类，所以Thread对象应该会持有ThreadLocal才对，但是因为ThreadLocalMap 中的key 其实是Threadlocal的弱引用。所以并不会出现内存泄漏的问题。使用ThreadLocal 也可以做到被其他线程访问，比如InheritableThreadLocal对象中的 数据就可以被其他线程访问。 子线程访问父线程的InheritableThreadLocal的值时，使用了浅拷贝。 Java中long和double赋值不是原子操作，因为先写32位，再写后32位，分两步操作,这样就线程不安全了。如果改成下面的就线程安全了 并发相关的集合： currentHashMap ：通过锁分段技术保证并发环境下的写操作； 通过 HashEntry的不变性、Volatile变量的内存可见性和加锁重读机制保证高效、安全的读操作； 通过不加锁和加锁两种方案控制跨段操作的的安全性。 HashMap 当在并发情况下进行扩容重哈希的时候，可能在链表中形成闭环，这样在进行查找 插入 删除操作的时候会陷入死循环。CorrentHashMap 解决了这个问题。 分段锁的实现依赖于Segment ，继承ReentranLock，里面有一个计数器变量mCount表示自己管理的table中hashEntry数量，每次插入删除元素都会更新这个值。成员变量table，表示自己管理的HashEntry链表。当写操作发生在不同的segment段时，可以允许多个写线程并发执行。HashEnrty是个四元组，key，hash和next域都被声明为final的，value域被volatile所修饰，因此HashEntry对象几乎是不可变的，这是ConcurrentHashmap读操作并不需要加锁的一个重要原因。这意味着，我们不能把节点添加到链表的中间和尾部，也不能在链表的中间和尾部删除节点。这个特性可以保证：在访问某个节点时，这个节点之后的链接不会被改变，这个特性可以大大降低处理链表时的复杂性注意 ：CorrentHashMap 不允许插入null的key 和value 而HashMap是可以的。CorrentHashMap 初始化的时候 默认大小是2的n此方。jdk 1.8以后，已经将segment的同步机制更改为了Syncornized和CAS操作。 说明Syncornized的性能已经优化到不比ReentranLock差了。 JDK对Syncnonized的优化 ： 引入偏向锁，轻量级锁和重量级锁。synchronized的执行过程： 检测Mark Word里面是不是当前线程的ID，如果是，表示当前线程处于偏向锁 如果不是，则使用CAS将当前线程的ID替换Mard Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1 如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。 当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁 如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 如果自旋成功则依然处于轻量级状态。 如果自旋失败，则升级为重量级锁 copyOnArrayList 写时复制机制。add元素的时候，先加锁，然后拷贝一份相同的数组，在新数组上操作，写完之后将对原数组的引用修改为对新数组的引用。 读可以不用加锁读。1、如果写操作未完成，那么直接读取原数组的数据；2、如果写操作完成，但是引用还未指向新数组，那么也是读取原数组数据；3、如果写操作完成，并且引用已经指向了新的数组，那么直接从新数组中读取数据缺点：写会拷贝数组，如果容量很大容易频繁触发gc不能实时读，但保证最终一致性。适合都多写少的场景，但要慎用，因为容易oom CopyOnWriteHashSet HashTable 解决hash冲突：链地址法 BlockQuene 阻塞队列：一般用来解决生产者消费者问题。提供了四组方法，分别产生四种结果，抛异常，返回特定值，阻塞，超时。无参构造方法默认是误解队列，也可以创建时默认设置一个缓冲区大小。linkedBlockedQuene 本质还是一个单向链表，为了提高生产和消费的效率，使用了两个锁分别对表头和表尾数据进行同步，如果take() 方法执行时队列为空，线程会阻塞在await上。只有等put()方法执行之后，会唤醒一个线程取一条数据。 并发包中 锁机制的实现其实就是通过CAS机制 在lock的时候 CAS 在unlock的时候讲atom值设置回去，如果CAS失败 就enquene 将当前线程记录在链表中，然后挂起线程 LockSupport.park()， LockSupport.park()会调Unsafe.park()的native方法，虚拟机在linux中执行pthread_mutex_lock函数 实现阻塞线程的操作。用当其他占有锁的线程 释放锁的时候，会调用Usafe.unpark唤醒阻塞队列的对头线程，线程继续递归调用lock()方法尝试获取锁。 12345678910111213141516171819public void lock() &#123; // step 1. cas 尝试 检查当前是否有其他线程改写了值 boolean ok = state.compareAndSet(0, 1); // step 2. 如果没有 线程将值改写为1 同时独占该方法 if (ok) &#123; setExclusiveThread(Thread.current()); // 这只是个标志位，不用太介意 return; &#125; // step 3. 如果cas失败 就进不去步骤2 当前线程要被阻塞 此时执行入队 用队列记录被阻塞的线程 enqueue(); // step 4. park方法将当前线程挂起 停止调度 线程就执行到这里阻塞 当其他独占线程释放锁的时候 会调用unsafa.Unpark() 会将阻塞队列对头线程唤醒 此时线程可以往下执行到step5 尝试递归获取锁 Unsafe.park(); // step 5. retry lock();&#125; 这些步骤可以提取出共有的特性 dogue lee 就写了一个框架 叫AbstractQueuedSynchronizer 简称AQS框架 是通用的锁框架AQS 伪代码 123456public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; 步骤分为四步: tryAcquire，抽象方法，由子类实现，子类通过控制原子变量来表示是否获取锁成功，类似于上文代码的Step1、Step2 addWaiter，已经实现的方法，表示将当前线程加入等待队列，类似于上文的Step3acquireQueued()，* 挂起线程，唤醒后重试，类似于上文的Step4、Step5 处理线程中断标志位。 如果需要自定义一个锁 只需要复写tryAqcuire方法 根据具体逻辑来由子类控制原子变量是否成功获取锁 可重入与不可重入锁 其实就是tryAcquire这地方的逻辑不一样，不可重入锁 一旦cas失败直接就返回了可重入锁内部会有一个持有锁的线程信息，并在cas失败的时候判断，如果线程信息是一致的 将原子变量+1就好。当然 解锁的时候还要对应-1 重入了几次 就要解锁几次，不然原子变量的值无法恢复为原始值。 并发的底层实现：volatile 禁止指令重拍（保证访问次序） 对线程强制可见（存强制刷新回主存，读强制从主存读取） class Singleton{ private volatile static Singleton instance = null; private Singleton() { } public static Singleton getInstance() { if(instance == null) { synchronized (Singleton.class) { if(instance == null) instance = new Singleton(); } } return instance; } } 这里为什么要使用volatile修饰instance？主要在于instance = new Singleton()这句，这并非是一个原子操作，事实上在JVM中这句话大概做了下面3件事情: （1）给instance分配内存 （2）调用Singleton的构造函数来初始化成员变量 （3）将instance对象指向分配的内存空间（执行完这步instance就为非null了）。 但是在JVM的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在3执行完毕、2未执行之前，被线程二抢占了，这时instance已经是非null了（但却没有初始化），所以线程二会直接返回instance，然后使用，然后顺理成章地报错。 1.可见性的保证：算机在运行程序时，每条指令都是在CPU中执行的，在执行过程中势必会涉及到数据的读写。我们知道程序运行的数据是存储在主存中，这时就会有一个问题，读写主存中的数据没有CPU中执行指令的速度快，如果任何的交互都需要与主存打交道则会大大影响效率，所以就有了CPU高速缓存。CPU高速缓存为某个CPU独有，只与在该CPU运行的线程有关。 有了CPU高速缓存虽然解决了效率问题，但是它会带来一个新的问题：数据一致性。在程序运行中，会将运行所需要的数据复制一份到CPU高速缓存中，在进行运算时CPU不再也主存打交道，而是直接从高速缓存中读写数据，只有当运行结束后才会将数据刷新到主存中。 volatile 使用了缓存一致性协议：缓存一致性协议（MESI协议）它确保每个缓存中使用的共享变量的副本是一致的。其核心思想如下：当某个CPU在写数据时，如果发现操作的变量是共享变量，则会通知其他CPU告知该变量的缓存行是无效的，就是在cpu缓存中写入一个缓存状态标记位：Invalid，因此其他CPU在读取该变量时，先读取标记位。发现其无效会重新从主存中加载数据（汇编代码会在指令前+LOCK字段。） 2 访问一致性：（禁止指令重拍）lock 指令会保证 在lock指令前的指令 在lock前执行 在lock指令后的 在lock执行完执行。lock汇编指令就是所谓的内存屏障。 syncornized实现原理：对当前对象和引用对象加锁：syncornized(this)syncornized(object.class)system.out.println()都是sync方法 反编译classa字节码 会发现在方法执行前有两个指令 monitorentermonitorExist如果修饰的是方法 在常量池中 方法对应的访问标记位 会添加一个ACC_SYNCHRONIZED访问标记在执行该方法时，原理还是一样 操作monitor监视器对象来实现的。 Monitor 是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联（对象头的MarkWord中的LockWord指向monitor的起始地址），同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。其结构如下Owner：初始时为NULL表示当前没有任何线程拥有该monitor record，当线程成功拥有该锁后保存线程唯一标识，当锁被释放时又设置为NULL；EntryQ:关联一个系统互斥锁（semaphore），阻塞所有试图锁住monitor record失败的线程。RcThis:表示blocked或waiting在该monitor record上的所有线程的个数。Nest:用来实现重入锁的计数。HashCode:保存从对象头拷贝过来的HashCode值（可能还包含GC age）。Candidate:用来避免不必要的阻塞或等待线程唤醒，因为每一次只有一个线程能够成功拥有锁，如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程，会引起不必要的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下降。Candidate只有两种可能的值0表示没有需要唤醒的线程1表示要唤醒一个继任线程来竞争锁。 Unsafe对象是java与native交互的中间者Unsafe.park() 阻塞线程Unsafe.unPark() 回复线程Unsafe.compareAndSwapInt() CAS操作 CAS原理：原理CAS（比较与交换，Compare and swap） 是一种有名的无锁算法。CAS, CPU指令，在大多数处理器架构，包括IA32、Space中采用的都是CAS指令，CAS的语义是“我认为V的值应该为A，如果是，那么将V的值更新为B，否则不修改并告诉V的值实际为多少”，CAS是项 乐观锁 技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。 123public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; 设置之前先比对 值是否与预期一致，一致就设置为预期值，不一致就重试直到一致为止。（注意 是一直重试，不是阻塞式，当cas失败 线程并不会被阻塞。） 因为cas的对象是被volatile关键子修饰的，它保证可见性和禁止指令重拍 CAS缺点 CAS虽然很高效的解决原子操作，但是CAS仍然存在三大问题。ABA问题，循环时间长开销大和只能保证一个共享变量的原子操作 ABA问题。因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A。 从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 关于ABA问题参考文档: http://blog.hesey.net/2011/09/resolve-aba-by-atomicstampedreference.html 循环时间长开销大。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。 只能保证一个共享变量的原子操作。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij。从Java1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作。 SAQ模型并发的实战问题 如何让一段程序并发执行，并最终汇总结果目前想到两种实现方式： 采用fork/join实现方式定义一个RecurisiveTask 这种Task继承Future，可以返回一个结果。在该Task中定义一个阈值，复写compute()方法，在该方法里不超过阈值就不fork新线程，直接计算并返回 ，超过就将任务分割 再创建两个task 并调用fork方法。 调用join等待两个线程执行完将结果合并。伪代码如下： 12345678910111213141516171819202122232425262728293031public static void main(String[] args) &#123; CountTask t = new CountTask(1,7); ForkJoinPool pool = new ForkJoinPool(); Future&lt;Integer&gt; future = pool.submit(t); &#125; static class CountTask extends java.util.concurrent.RecursiveTask&lt;Integer&gt;&#123; private int threadhold = 2; int start; int end; CountTask(int start,int end)&#123; this.start = start; this.end = end; &#125; @Override protected Integer compute() &#123; if((end -start)&gt;threadhold)&#123; return start +end; &#125; else &#123; int mid = (int) ((end-start)/2+start); CountTask t1 = new CountTask(start,mid); CountTask t2 = new CountTask(mid,end); t1.fork(); t2.fork(); int result1 = t1.join(); int result2 = t2.join(); return result1+result2; &#125; &#125; &#125; 2.使用线程池 创建多个futureTask 并阻塞等待get()方法返回值。 如何合理的配置java线程池？如CPU密集型的任务，基本线程池应该配置多大？（少配置一些核心线程数，一般和cpu核心数一致， 为了使所有线程都能使用到cpu。）IO密集型的任务，基本线程池应该配置多大？（大部分线程都阻塞，所以要多配置核心线程数，一般使用cpu核心的两倍）用有界队列好还是无界队列好？（没有好坏之分，要分业务场景，一般配置有界队列。当有可能会出现爆发式增长的场景，使用无线队列，会不断增长直到内存耗尽。）任务非常多的时候，使用什么阻塞队列能获取最好的吞吐量？（使用非阻塞队列并结合cas操作以获得更好的吞吐量） 什么场景使用可重入锁：syncornized无法满足需要的情况，包括可中断，可超时，公平，非公平等高级特性时使用ReentranLock 什么场景下可以使用volatile替换synchronized？只需要可见性，不需要保证原子性时可以代替。volatile不适用那种新值依赖旧值的场景 CountDownLaunch 一般这么用：主任务等待n个子任务完成，创建一个CountDownLaunch(n)，子任务执行一次，CountDownLaunch.countDown()一次。主任务调用CountDownLaunch.await（）阻塞等待， 只有CountDownLaunch倒数完成，主任务才会继续执行。 使用阻塞队列实现生产者消费者模型：伪代码 1234567891011121314151617181920212223242526272829303132public static void main()&#123; LinkedBlockedQueue queue = new LinkedBlockedQueue(10); class producer extends Runnable&#123; Producer(BlockedQueue queue)&#123; this.queue = queue; &#125; void run()&#123; try&#123; while(true) queue.put() &#125; catch (InteruptException e)&#123;&#125; &#125; &#125; clase Consumer extends Runnable&#123; BlockedQueue queue; Consumer(BlockedQueue queue)&#123; this.queue = queue; &#125; void run()&#123; try&#123; queue.take(); &#125;catch(Exception e)&#123;...&#125; &#125; &#125; new Thread(new Producer(queue)).start(); new Thread(new Consumer(queue)).start();&#125; Rxjava相关 什么时候将订阅者和被订阅者关联起来的。在subscribe()方法调用的时候。 1234567891011121314151617181920// 等于是日程表，告诉订阅者要依次做什么class OnSubscribe(Subscriber subscriber)&#123; void call(subscriber)&#123; subscriber.onNext(); subscriber.onNext(); subscriber.onComplete(); &#125;&#125;class Observable&#123;...public Subscription subscribe(Subscriber subscriber)&#123; subscriber.onStart();//先执行onStart() 做些准备工作 注意这个方法无法切换线程只能在事件发送端的线程执行。 if（!subscriber instance of SafeSubscriber）&#123; subscriber = new SafeSubscriber(subscriber);// 将传入的subscriber包装为safeSubscriber 为了保证onComplete onError 只被执行一次。 &#125; onSubscribe.call(subscriber);// 手动调了上面日程表的call方法。开始发送时间序列 return subscriber; &#125;&#125; flatMap observerOn() subscribeOn() 切换线程的原理：lift()变换 可以这么理解： 每次lift() 都会创建一个新的Observable，因为链式调用的缘故，最终subscribe()将观察者和被观察着绑定关系的时候，都会绑定到最后一次lift()变换生成的新的Observable上，当调用subscribe()方法的时候，会先调用最终那个subscriber的onStart(),然后调用新Observable() 的OnObservable()方法，在新Observable（）中，它的onObservable被lift操作很机智的修改了，它首先创建了一个新的subsciber 这个subscriber持有原来那个订阅着的引用，然后它会调用上一级的那个obServable ,也就是调用lift()方法那个被观察者的call()方法，让自己创建的新的观察者来观察原来那被观察者发送的序列。 在这个心的被观察者中 它可以将原来观察者发送的消息处理一下，然后再发给最终的观察者。 说的非常绕口，用一个形象的例子来说明一下： 建立简单的观察者被观察者并建立关联关系。 假设一个场景是部队操练表演。 我们是军官A(最原始的那个Observable)表演动作的流程由我们制定，基地里所有的士兵(Subscriber)都可以主动申请参加表演（订阅）。我们制定了一个动作流程表（OnObservable对象），表里我们制定好了 “先左转（onNext），然后右转（onNext），然后稍息（onNext），然后立正，最后敬礼，结束（onComplete）！”这套表演流程。这个表上有个签名栏，谁说要表演，就要在签名栏签上自己的大名。（OnSubscribe的 call方法 会传入一个观察者）。当然我们基地的士兵还是新人，只能执行一些比较简单的动作，复杂的动作不会做。 现在有一个士兵主动请缨要表演了(Observable.subscribe(new Subscriber())，军官会告诉他你可以先准备一下，（subscribe 方法会在里面先调用一下 Suscriber的onStart(),观察者可以先做些准备工作），然后士兵在流程表上签上了自己的名字(调用Onsubscribe.call(subscriber)，将观察者自己传入call（）方法中)。 要开始表演了，军官开始依次按照流程表的动作开始喊口号“士兵A,左转！”(被观察着会等subscribe方法调用之后才开始发送事件序列。)士兵A完成了一次左转动作。军官一个口号一个口号的喊完了，士兵也完整执行了所有的动作，并敬礼(onComplete()调用了)。 使用Lift变换 上面说过 士兵只可以执行简单的操作，复杂的操作还不会，如果我们要他做一个托马斯回旋，他不明白什么意思，但是你要是跟他说，就是先转一圈，再转一圈，他就明白了。 这时候可以这么做： 我们还是按照名单上的流程念，但是这时候名单变为了”先转体360度，再立正敬礼结束！”，士兵A不懂转体360是什么意思，这时候军官B 出来了，他有个手下士兵B 跟表演的士兵关系很好(士兵B 是 新构建的Subscriber，他存在在lift变换新创建出来的观察者内)。士兵b比较有文化，知道360转体就是“转一圈再转一圈的意思”。为了帮助士兵A顺利完成任务，他决定，将军官A的名单上名字改成自己的，现在士兵B现在直接面向军官A。他收到军官A的消息后 处理之后再告诉士兵A怎么做。 现在准备表演了。士兵A对军官B说 “我准备好了”，（Observable.subscribe()）,军官B 收到了(在lift方法创建的新的Observable的subscibe()方法中，先创建了一个新的Subscriber(old subscriber),然后调用上一个Observable中的OnSubscribe()方法，开始发送原始观察者中的事件，不过这些时间都被新的观察者接收了)，通知军官A开始喊口号（调用旧的OnSubscribe对象中的call方法，此时call传入的是新的观察者）。 军官A 叫到“士兵B ， 转体360”，士兵B收到，翻译了一下“士兵A，转体360 就是 转一圈，再转一圈”的意思。 士兵A 按照B 说的 ，顺利完成了这次表演。 rxjava 的线程切换subscribeOn() 和 observeOn() 都做了线程切换的工作（图中的 “schedule…” 部位）。不同的是， subscribeOn() 的线程切换发生在 OnSubscribe 中，即在它通知上一级 OnSubscribe 时，这时事件还没有开始发送，因此 subscribeOn() 的线程控制可以从事件发出的开端就造成影响；而 observeOn() 的线程切换则发生在它内建的 Subscriber 中，即发生在它即将给下一级 Subscriber 发送事件时，因此 observeOn() 控制的是它后面的线程图中共有 5 处含有对事件的操作。由图中可以看出，①和②两处受第一个 subscribeOn() 影响，运行在红色线程；③和④处受第一个 observeOn() 的影响，运行在绿色线程；⑤处受第二个 onserveOn() 影响，运行在紫色线程；而第二个 subscribeOn() ，由于在通知过程中线程就被第一个 subscribeOn() 截断，因此对整个流程并没有任何影响。这里也就回答了前面的问题：当使用了多个 subscribeOn() 的时候，只有第一个 subscribeOn() 起作用。 关键成员Subscriber： 继承Observable 比它多了几个方法onStart()unSubscribe() 用来接触绑定 因为在 subscribe() 之后， Observable 会持有 Subscriber 的引用，这个引用如果不能及时被释放，将有内存泄露的风险 里面有个成员Producer 用来处理跟Observable的背压问题toRequest 为请求数 Producer用的 用来请求数据源发送的数据数可以调用setProducer() 为subscriber 设置Producer调用request() 为其设置请求数 首先，如果在设置请求数时还没有初始化Producer，就进行累加保存。直到Producer被设置时，如果当前Subscriber未设置请求数且内部Subscriber不为空就把Producer赋值给内部的Subscriber，否则就会赋值给当前的Subscriber。要是当前Subscriber至今未设置请求数，就请求Long.MAX_VALUE数量的数据,多余部分就会忽略。 Scheduler 线程调度Scheduler 线程调度器 其中真正实现线程切换的是Worker Worker实现了Subscription接口 所以Worker具有取消订阅的功能。 当调用SubscriberOn(Scheduler.newThread())时，创建了一个新的OperatorSubscribeOn对象，并将我们的Scheduler作为参数传递了进。 OperatorSubscribeOn本身也是一个Observable，在它的OnSubScribe()的call方法中，其实可以猜到，它一定会通过某种手段，将我们原始的Observable的发送线程切换到目标线程。 那RxJava是怎么做的呢？ 重写 OperatorSubscribeOn的onSubscribe()的call()方法 根据传入的Scheduler 对象 创建了一个worker对象 执行worker的schedule()方法 传入了一个Action() worker 的schedule()方法会保证在目标线程中执行Action0的call()方法 在Action0的call()方法中 创建了一个新的Subscriber 这个新的Subscriber是原观察者和被观察者之间的中间人 我们在worker线程中 将原被观察者与新的Subscriber订阅，此时原观察者会在Worker线程中开始发射数据 数据被我们的新Subscriber转发给原Suscriber 这样数据就转到我们自定义的线程中发送了 就完成SubscribeOn的目的 map()函数：创建了一个新的Observable 返回new OnSubscribeMap&lt;T, R&gt;(this, func)当被订阅时，会调用新Observable的call方法 12345678910@Override public void call(final Subscriber&lt;? super R&gt; o) &#123; // 对传入的 Subscriber 进行再次封装成 MapSubscriber // 具体 Observable.map() 的逻辑是在 MapSubscriber 中 MapSubscriber&lt;T, R&gt; parent = new MapSubscriber&lt;T, R&gt;(o, transformer); o.add(parent); // 加入到 SubscriptionList 中，为之后取消订阅 // Observable.interval() 返回的 Observable 进行订阅(关键点) source.unsafeSubscribe(parent); 创建了一个新的Subsriber对象。他会对原来发送的消息进行处理 看一下它的onNext方法 123456789101112@Override public void onNext(T t) &#123; R result; ... result = mapper.call(t); // 数据进行了变换 ... actual.onNext(result); // 往下流传 &#125; interval（）函数构建流程几乎类似 唯一的区别是新创建的Subscriber对象的call方法 1234567891011121314151617@Override public void call(final Subscriber&lt;? super Long&gt; child) &#123; final Worker worker = scheduler.createWorker(); child.add(worker); worker.schedulePeriodically(new Action0() &#123; long counter; @Override public void call() &#123; ... child.onNext(counter++); ... &#125; &#125;, initialDelay, period, unit); &#125; rxjava 如何保证串行发射的发送者循环 和队列漏 高级方法： backPressure 背压所谓背压 其实就是在异步任务过程中，发送者的事件流太快，接收方来不及处理，告诉上游发送者降低时间发送速率的一种策略。其实就是被观察者支不支持观察者通过调用request(int length) 来手动通知被观察者发送length数量的数据。 这个需要rxjava的被观察者支持才行，1.x版本的有部分是不支持的比如interval，timer等操作符创建的Observable。而类似range创建的Observable 是支持request这样的背压请求的。 不支持背压的Observable 该如何做到流程控制呢： 抛弃部分数据 123这个操作符简单理解就是每隔200ms发送里时间点最近那个事件， //其他的事件浪费掉 .sample(200,TimeUnit.MILLISECONDS) 缓存数据 处理不过来可以先缓存一部分 buffer（包装为list） window（包装为新Observable）操作符 12//这个操作符简单理解就是把100毫秒内的事件打包成list发送 .buffer(100,TimeUnit.MILLISECONDS) 使用特殊的两个操作符，使其可以相应request请求 onBackpressurebuffer(int buffersize)：把observable发送出来的事件做缓存，当request方法被调用的时候，给下层流发送一个item(如果给这个缓存区设置了大小，那么超过了这个大小就会抛出异常)。 onBackpressureDrop：将observable发送的事件抛弃掉，直到subscriber再次调用request（n）方法的时候，就发送给它这之后的n个事件。 小细节： range 默认缓冲是16个事件。zip 128个事件缓冲区 rxjava2将支持背压和不支持背压分开不支持背压的：Observable/Observer支持背压:Flowable/SubscriberFlowable 可以通过range这样的操作符创建，也可以通过create方法创建，但是create需要手动制定背压规则 BackpressureStrategy.BUFFER。 注意： 在观察者调用了request之后，会立刻回调到onNext，而不一定等onSubsbcribe方法走完其实就是流程控制 为了解决发送端速率与接收端速率不一致的问题 flatMap()在调用flatMap() 会传入一个Funx(){},它会根据原始数据源创建一个新的Observable。 猜也能猜出来实现的原理是什么，还是用的lift()变换。比较适合用在需要嵌套请求的情形。比如 先获取token，然后携带token去请求数据，再返回一个新的Observable。 线程池：当线程数小于核心线程数时，创建线程。当线程数大于等于核心线程数，且任务队列未满时，将任务放入任务队列。当线程数大于等于核心线程数，且任务队列已满若线程数小于最大线程数，创建线程若线程数等于最大线程数，抛出异常，拒绝任务 Retrofit1. 首先构造Retrofit对象12345Retrofit retrofit = new Retrofit.Builder() .baseUrl(\"https://api.github.com/\") .addConverterFactory(GsonConverterFactory.create()) .build(); 使用的建造者模式。在调用build()方法之后，已经传入了结果转换器还有baseUrl，此时会根据当前平台类型 Platform.get()来进行一系列初始化操作。 如果是android，就会创建一个Android类。 在Android类中，定义一个call转换器工厂。我们可以添加自己的call转换器。callAdapter其实是为了将OkHttp3的call对象进行我们需要的定制化包装。 同时会创建一个默认线程池MainThreadExecutor。 现在Retrofit对象构建完成，有了一个ExecutorCallAdapterFactory,这个factory的get()方法会返回一个CallAdapter。 2. 通过注解定义网络请求的Api，并且创建了请求服务的实体对象。123456public interface GitHubService &#123; @GET(\"users/&#123;user&#125;/repos\") Call&lt;List&lt;Repo&gt;&gt; listRepos(@Path(\"user\") String user);&#125;GitHubService github = retrofit.create(GitHubService.class); 这里使用的是动态代理innovationHandler create 方法的实现： 1234567891011public &lt;T&gt; T create(final Class&lt;T&gt; service) &#123; // 省略非关键代码 return (T) Proxy.newProxyInstance(service.getClassLoader(), new Class&lt;?&gt;[] &#123; service &#125;, new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object... args) throws Throwable &#123; // 先省略实现 &#125; &#125;);&#125; 由我们传入的interface 动态代理出一个对象，代理对象就是service实体。它实现了请求api的接口。 3. 调用请求接口：实际就干了这三件事： 123ServiceMethod serviceMethod = loadServiceMethod(method);OkHttpCall okHttpCall = new OkHttpCall&lt;&gt;(serviceMethod, args);return serviceMethod.callAdapter.adapt(okHttpCall); 1. 创建ServiceMethod使用了单例模式+缓存的方式，每一个api接口都对应的一个单例ServiceMethod。注意，构建的时候传入的是class对象。ServiceMethod的成员包括： 1234567891011121314ServiceMethod(Builder&lt;T&gt; builder) &#123; this.callFactory = builder.retrofit.callFactory(); this.callAdapter = builder.callAdapter; this.baseUrl = builder.retrofit.baseUrl(); this.responseConverter = builder.responseConverter; this.httpMethod = builder.httpMethod; this.relativeUrl = builder.relativeUrl; this.headers = builder.headers; this.contentType = builder.contentType; this.hasBody = builder.hasBody; this.isFormEncoded = builder.isFormEncoded; this.isMultipart = builder.isMultipart; this.parameterHandlers = builder.parameterHandlers;&#125; callFactory：创建网络请求的客户端，不指定默认为okhttp3.okHttpClient也可以在创建时指定。callAdapter： 负责吧okhttp3的call适配为我们的retrofit的call 也就是默认的ExecutorCallBackCallresponseConverter: 将返回结果转化为我们想要的javabeanparameterHandlers: 负责解析api定义时的参数，并在构造http请求的时候填入参数。 2. 创建okHttpCall 同步 execute 异步 enqueue（callBack callback） a 创建okhttp3.call由parameterHandlers 构建请求体request由callFactory.newCall(request)构建okhttp3请求（当然也可以由过时的HttpUrlConnection构建） b 同步请求网络并转换结果okhttp3.Call.execute()来同步执行网络请求将结果用responseConventer转换为javabean c 异步请求okhttp3.call.enqueue(callback callback)来异步执行网络请求回调callback接口 3. callAdapter 将okhttpCall 转换为我们想要的call类型比如我们常用的RxJavaCallAdapter 会吧请求转化为一个Observable 看一下RxjavaCallAdapter 会将OkhttpCall 适配为Observable 根据同步还是异步(默认是异步请求 isAs = false) 创建了两个OnSubscribe 123OnSubscribe&lt;Response&lt;R&gt;&gt; callFunc = isAsync ? new CallEnqueueOnSubscribe&lt;&gt;(call) : new CallExecuteOnSubscribe&lt;&gt;(call); 以这个OnSubscribe对象来构建Observable 当被订阅时，Onsubscribe对象开始发送事件，call方法会被调用 12345678910111213public void call()&#123; ... Response&lt;T&gt; response; try &#123; response = call.execute(); &#125; catch (Throwable t) &#123; Exceptions.throwIfFatal(t); arbiter.emitError(t); return; &#125; arbiter.emitResponse(response); &#125; 里面阻塞调用了okhttp3.call 的execute()方法获取网络请求结果 开始网路请求调用了请求接口，经过转换器 将call转换为了我们要的被观察者。当调用了subscribe()方法的时候，开始触发网络请求 123456Observable.subscribe//触发 API 调用的执行；CallOnSubscribe(call)，//clone call，创建并设置 producer；RequestArbiter(request)//subscriber 被设置了 producer 之后最终调用 request，在 request 中发起请求，把结果发给下游；OperatorMapResponseToBodyOrError$1(onNext)//把 response 的 body 发给下游；最终就到了我们 subscribe 时传入的回调里面了； retrofit里丰富的设计模式： 建造者模式: 在创建Retrofit客户端的时候，通过builder()构建者模式将需要的一些适配器创建并赋值。 适配器模式： retrofit在Android版本上默认是用okhttp3来请求网络的，okhttp3的网络请求okhttp3.call被转换为OkHttpCall，这个call.enqueue 是在子线程调用，callback的回调也是在子线程，为了在主线程操作这些回调我们势必要Handler来切换线程，但是这个okHttpCall 肯定是不适用java1.8 或者ios 等平台的，而且我们如果想使用RXjava的流式调用，okhttpCall肯定还要做进一步的适配，为了隔离网络请求接口的平台不一致性，retrofit将一些共有属性抽取出来，通过我们自定义的CallAdapter 隔离各种平台和网络请求框架的具体实现差异，适配成我们想要的方式。 静态代理：默认的CallAdapter是AndroidCallAdapter，为了把okhttp3.call 封装为子线程请求，主线程回调，使用了静态代理方式 ExecutorCallbackEnqueue() 将okhttp3.call 代理为OkHttpCall。 动态代理： 在我们调用对应的网络请求接口的时候，使用了动态代理，在调用方法的地方，动态的获取注解信息，拼装为完整的请求体，同时将返回的数据适通过我们自定义的转换器，比如讲xml 或者json转为javabean，同时将请求call 通过callAdapter适配为我们想要的格式，比如如果是RxJavaAdapter 就适配为Observable 如果不定义，就适配为OkhttpCall。 OkHttp3 1. 创建HttpClient对象OkHttpClient client = new OkHttpClient(){new Builder();} 2. Builder里做了什么1 构造了Dispacher2 设置了链接超时时间和读写超时时间 3. 创建request通过url method body header 构建Request对象 123Request request = new Request.Builder() .url(url) .build(); 创建RealCall对象client.newCall(request)根据request构建一个RealCall对象 1new RealCall(this, request); 同步请求网络 call.execute()call.execute()其实调用的RealCall.execute() 1234567891011121314@Override public Response execute() throws IOException &#123; synchronized (this) &#123; if (executed) throw new IllegalStateException(\"Already Executed\"); // (1) executed = true; &#125; try &#123; client.dispatcher().executed(this); // (2) Response result = getResponseWithInterceptorChain(); // (3) if (result == null) throw new IOException(\"Canceled\"); return result; &#125; finally &#123; client.dispatcher().finished(this); // (4) &#125;&#125; 先判断call 是否执行过，每个call、只能执行一次其次 会调用dispatcher.executed(this); 这个dispatcher是个请求分发器，同步调用的时候没起到什么特殊作用，只是通知一下 请求开始了（executed），请求结束了（finished），它更多的是用在异步调用的时候，处理多个请求的异步调度。 然后getResponseWithInterceptorChain（） 是真正开始网路请求并处理结果的方法 最后 调用dispatcher 通知其已经完成请求。 Dispatcher是网络请求任务的分发器。 当决定异步请求时，Dispatcher会调用enquene(new AysncCall()) 将网络请求任务添加到请求队列中。 Dispatcher中使用了一个核心线程为0 超时时间为60s的无上限线程池。任务队列是一个FIFO的阻塞队列来实现。在Dispatcher中有三个链表， readyAsyncCalls记录等待执行的异步请求。 runningAsyncCalls记录正在执行的异步请求 RunningSyncCalls记录正在执行的同步请求。 dispatcher的线程池配置 只有一个核心线程，而且任务队列长度只有0，那就是每次有请求，就先看有无空闲线程，有就交给线程执行，否则创建新的线程。 当执行call.enqueue()方法准备发起网路请求的时候，首先判断 runningAsyncCalls队列中是不是没有超过最大请求数64 且同一个请Host下的请求不超过5，如果满足，加入runningAsyncCalls队列，否则加入readyAsyncCalls队列。 依次从runningAsyncCalls队列表头取出call任务，加入线程池执行。通过getResponseFromInterceptorChain()去发起网络请求并获取response，这个方法被trycatch包裹，成功就回调callback的onResponse，注意此时并没有切换线程，所以okhttp的回调是在线程池中执行的。 如果失败，进入catch块，并回调onFailure(); 在finally块中，移除当前的runningCalls，并扫描runningCalls链表，取出下一个等待执行的call加入线程池执行。 123syncornized(this)&#123; promoteCalls();&#125; 可以看到 不管是同步 还是异步，都是调用ResponseWithIntercepotionChain()去真正开始网络请求并获取response getResponseWithInterceptorChain 请求网并处理数据责任链模式 每个拦截器被串联在一起 各自处理各自能处理的工作，并将工作流向下传递。 123456789101112131415161718private Response getResponseWithInterceptorChain() throws IOException &#123; // Build a full stack of interceptors. List&lt;Interceptor&gt; interceptors = new ArrayList&lt;&gt;(); interceptors.addAll(client.interceptors()); interceptors.add(retryAndFollowUpInterceptor); interceptors.add(new BridgeInterceptor(client.cookieJar())); interceptors.add(new CacheInterceptor(client.internalCache())); interceptors.add(new ConnectInterceptor(client)); if (!retryAndFollowUpInterceptor.isForWebSocket()) &#123; interceptors.addAll(client.networkInterceptors()); &#125; interceptors.add(new CallServerInterceptor( retryAndFollowUpInterceptor.isForWebSocket())); Interceptor.Chain chain = new RealInterceptorChain( interceptors, null, null, null, 0, originalRequest); return chain.proceed(originalRequest);&#125; 它把实际的网络请求、缓存、透明压缩等功能都统一了起来，每一个功能都只是一个 Interceptor，它们再连接成一个 Interceptor.Chain，环环相扣，最终圆满完成一次网络请求。 这个责任链机制非常巧妙 先是定义了一串的Interceptor，每个Interceptor处理特定任务。Interceptor是一个接口 看代码就明白了 1234567891011121314151617181920212223242526public interface Interceptor &#123; Response intercept(Interceptor.Chain var1) throws IOException; public interface Chain &#123; Request request(); Response proceed(Request var1) throws IOException; @Nullable Connection connection(); Call call(); int connectTimeoutMillis(); Interceptor.Chain withConnectTimeout(int var1, TimeUnit var2); int readTimeoutMillis(); Interceptor.Chain withReadTimeout(int var1, TimeUnit var2); int writeTimeoutMillis(); Interceptor.Chain withWriteTimeout(int var1, TimeUnit var2); &#125;&#125; chain里提供了我们创建一个网络请求所需要的所有方法。它的唯一实现类是Realchain还记得上面我们开始获取response的方法吗： 123Interceptor.Chain chain = new RealInterceptorChain( interceptors, null, null, null, 0, originalRequest);chain&gt;processed(originRequest) 这里我们构造chain的时候，传入的初始index是0。当调用到processed方法时，会创建一个新的chain并将index+1 取出传入的interceptor列表的第一项。将chain传递给它处理。 123456789101112131415161718192021222324public Response proceed(Request request, StreamAllocation streamAllocation, HttpCodec httpCodec, RealConnection connection) throws IOException &#123; if (this.index &gt;= this.interceptors.size()) &#123; throw new AssertionError(); &#125; else &#123; ++this.calls; if (this.httpCodec != null &amp;&amp; !this.connection.supportsUrl(request.url())) &#123; throw new IllegalStateException(\"network interceptor \" + this.interceptors.get(this.index - 1) + \" must retain the same host and port\"); &#125; else if (this.httpCodec != null &amp;&amp; this.calls &gt; 1) &#123; throw new IllegalStateException(\"network interceptor \" + this.interceptors.get(this.index - 1) + \" must call proceed() exactly once\"); &#125; else &#123; RealInterceptorChain next = new RealInterceptorChain(this.interceptors, streamAllocation, httpCodec, connection, this.index + 1, request, this.call, this.eventListener, this.connectTimeout, this.readTimeout, this.writeTimeout); Interceptor interceptor = (Interceptor)this.interceptors.get(this.index); Response response = interceptor.intercept(next); if (httpCodec != null &amp;&amp; this.index + 1 &lt; this.interceptors.size() &amp;&amp; next.calls != 1) &#123; throw new IllegalStateException(\"network interceptor \" + interceptor + \" must call proceed() exactly once\"); &#125; else if (response == null) &#123; throw new NullPointerException(\"interceptor \" + interceptor + \" returned null\"); &#125; else if (response.body() == null) &#123; throw new IllegalStateException(\"interceptor \" + interceptor + \" returned a response with no body\"); &#125; else &#123; return response; &#125; &#125; &#125; 在interceptor的intercept方法中，又会调用这个chain的processed方法 processed方法又会以旧参数和index+1 再创建新chain。并取出interceptpor链表的第二项来处理chain。一次类推直到链表中没有新的interceptor为止。 这样就串联成了一个调用链。 最终返回response给我们。 总结构造OkHttpClient 并初始化分发器1234OkHttpClient client = new OkHttpClient()&#123; Dispatcher dispatcher = new Dispatcher();构建dispatcher分发器 Long mConnectionTimeout = CONNECTION_TIME_OUT 设置链接超时时间之类的&#125;; 构造Request对象使用建造者模式 构建一个Request对象 1Request request = Requset.Builder().url(\"https://baidu.com\").build(); 分发器决定同步还是异步执行 同步 12client.newCall(request).execute(); 异步 12345client.newCall(request).enqueue(new Callback&#123; void onFailure(Call call,IoException e)&#123;&#125; void onResponse(Call call,Response response)&#123;&#125;) &#125;); 可以看到 首先 构建了一个请求RealCall对象。通过RealCall的execute() 和enqueue(callback)分别实现了同步请求和异步请求。 同步请求和异步请求是由dispatcher实现的。分发器分发见上文。最终是通过getResponseFromInterceptorChain(Request,0,0);来实现网络请求和获取response的。 自定义拦截器请求网络并获取response123456789101112131415161718private Response getResponseWithInterceptorChain() throws IOException &#123; // Build a full stack of interceptors. List&lt;Interceptor&gt; interceptors = new ArrayList&lt;&gt;(); interceptors.addAll(client.interceptors()); interceptors.add(retryAndFollowUpInterceptor); interceptors.add(new BridgeInterceptor(client.cookieJar())); interceptors.add(new CacheInterceptor(client.internalCache())); interceptors.add(new ConnectInterceptor(client)); if (!retryAndFollowUpInterceptor.isForWebSocket()) &#123; interceptors.addAll(client.networkInterceptors()); &#125; interceptors.add(new CallServerInterceptor( retryAndFollowUpInterceptor.isForWebSocket())); Interceptor.Chain chain = new RealInterceptorChain( interceptors, null, null, null, 0, originalRequest); return chain.proceed(originalRequest);&#125; 先把我们创建client的时候，自定义的拦截器加载到拦截器列表中 添加各种必要拦截器 构建RealInterceptorChain() 通过责任链机制，链式处理请求并返回response InterceptorsHttpCodec对http请求过程中的数据流进行读写操作 StreamAllocationnewStream 创建httpCodecrealStream.connection 开启socket链接，返回Connection对象。 注: HttpCodec 用来读写网络请求的输入输出流、 RealCall 代表一次网络请求 对一次网络请求的封装 其实就是请求了一个特定的api StreamAllocation 一次真实网络请求的开销 与RealCall对应 要知道 我们访问一个特定api的时候 可能会出现域名重定向，一次请求会发生多次跳转，每次跳转都对应着一次真实的网络请求的开销。 StreamAllocation就是描述这个开销的。 Connection 对应一个连接。 我们知道http请求 是基于TCP协议的，TCP是面向连接的协议，就是每次请求网络 都必须先建立连接，而建立连接需要三次握手，如果同时请求次数很多，每次都要先建立连接 再去请求网络 会造成很大的网罗开销。 为了复用连接，在Http1.1 协议中 默认打开了keep-alive，这样服务器收到这种请求之后，返回完数据并不会直接关闭连接，而是会等待一段时间，在此之间的请求 可以直接复用这个连接，就达到请求复用的效果。但是http1.1 对同时请求的数量有个最大值限制，超过这个限制的请求会被阻塞。而且 http1.1 并不会对请求首部（请求头）进行压缩，有时候带有多个cookie的情况下 头的大小甚至可以达到kb级，流量开销还是挺大的。 为了解决多路复用和节省流量 出现了新的http2.0协议。Http2.0的主要目标：降低延迟，客户端的单连接单请求，server的FIFO响应队列都是延迟的大头。http最初设计都是客户端发起请求，然后server响应，server无法主动push内容到客户端。压缩http header，http1.x的header越来越膨胀，cookie和user agent很容易让header的size增至1kb大小，甚至更多。而且由于http的无状态特性，header必须每次request都重复携带，很浪费流量。 Okhttp使用链接池 实现了链接的多路复用机制。 RetryAndFollowUpInterceptor获取ConnectPool 连接池 连接池内使用一个双端队列描述链接Deque，同时维护了一个路由黑名单表。每个链接 是一个RealConnect对象，RealConnection对象是对socket链接的封装。链接池主要提供了 提供一个可复用的链接 将链接加入连接池 清除无用链接 清除重复链接等方法。 在重定向拦截器中，我们将请求url封装为一个Address对象。Address对象描述的是服务器地址，将这个Address对象作为参数 构造StreamAllocation对象。 要记住，StreamAllocation代表一次网络请求开销，是一次call的数据流动，他可以复用一个已经建立的链接。 重定向拦截器 构造了一个StreamAllocation，但是并没有开始网络请求。主要是为了创建一个StreamAllocation供后面的拦截器使用。在创建了StreamAllocation之后，调用了1((RealInterceptChain)chain).proceed(request,streamAllocation,null,null); 将request和streamAllocation传递给下一个Inrerceptor去处理了。 后面的拦截器会判断缓存策略，发起网络请求，获取response。 获取response之后，重定向拦截器判断是否需要重新请求或者重定向到其他地址，最大重定向层级30 BridgeInterceptor重定向拦截器下面的拦截器。请求会被发送到BridgeInterceptor。这个拦截器主要是为了完善请求头，如果调用者没有写，就自动帮我们加上对应的Content-Type Content-LengthUser-Agent之类的 CacheInterceptor由桥接拦截器传递过来。主要是实现相应的缓存策略。 根据request的请求头 判断是强制缓存还是对比缓存如果带有max-age = *** 表示使用的是强制缓存如果带有的if-none-match(etag)或者 if-modify-since(last-modify)表示是对比缓存 根据缓存策略 创建 networkRequest 和 cachedResponse对象。 如果是强制缓存，networkRequest就为null 此时分两种情况： a. 无缓存可用 cachedResponse为null 直接构建新的response 返回码是504 报错b. 有缓存 直接返回cacheResponse 如果是非强制缓存 将request交给下游的interceptor去处理 请求网络并获取服务器的返回结果，由服务器的返回结果来判断 是使用缓存 还是再次请求网络从服务器中获取 将服务器返回的数据 赋值给networkResponse 判断返回码是否为304 如果是304 使用cachedResponse 获取缓存的response并返回 否则 再次请求网络 获取数据 将完整的response 缓存在cache文件中 返回此次的response。 cacheWritingResponse（）写入缓存 通过Okio以及DiskLruCache来实现 删除无效缓存。 connectInterceptor由缓存拦截器判断之后，如果缓存失效，则将重新请求网络，此时会将request往下传递给connectInterceptor。 链接拦截器只完成了从连接池中查找是否有可以复用的链接，如果没有 就创建链接并添加到连接池的作用。 查找可用链接的真正实现是有上文的重定向拦截器创建的。 1RealConnection connection = streamAllocation.findConnection(connectionPool,address,null,null); StreamAllocation.findConnection()，使用address来从连接池中获取一个可复用的链接，如果没有就构造一个新的并加入到链接池中， connection描述了请求的地址 Internal.getInstance.get(connectionPool,address)直接根据地址匹配，如果address跟连接池中的adderss完美匹配，直接返回这个链接对象。 地址不匹配，查看有无设置过路由，有的话再尝试从链接池中获取链接对象 Internal.getInstance.get(connectionPool, address,route)。 如果还没有找到可以复用的链接，就直接创建一个新的链接。并将链接的stream计数器+1，添加到连接池。 这里涉及到连接池如何判断链接是否失效的问题。因为每个StreamAllication对应链接上的一个数据流动，如果链接上没有数据流了，那表明当前链接是闲置状态，当闲置超过5分钟，就会被回收。 查看链接池中有无多余重复链接result.isMultiplexed()，有就删除Internal.instance.deduplicate。 connectionInterceptor 获取可用的链接之后，往下传递给CallServerInterceptor CallServerInterceptor这是一个真正发起网络请求的拦截器。所以他也是在拦截器链表的对尾。 建立连接 ConnectInterceptor找到一个可用的 RealConnection，再利用 RealConnection 的输入输出（BufferedSource 和 BufferedSink）创建 HttpCodec 对象，供后续步骤使用。这个HttpCodec 其实使用Okio包 对 Socket 的读写操作进行封装。是对http的抽象。 发送和接收数据：CallServerInterceptor使用上面创建的httpcodec来发起和接收数据：向服务器发送 request header；如果有 request body，就向服务器发送；读取 response header，先构造一个 Response 对象；如果有 response body，就在 3 的基础上加上 body 构造一个新的 Response 对象； okhttp 使用websocketwebsocket 是基于tcp协议基础上的，和http协议类似，是一种新的网络通信协议，是全双工信道，就是服务器可以推数据给客户端，客户端可以发数据给服务器。websocket是按照数据帧来传递数据的 12345OkhttpClinet client = new OkhttpClient();Request request = Request.builder.url(\"ws://fdedee\").build;client.newWebsocket(request,new WebsocketListener&#123;&#125;) apk前签名机制：apk签名签名之后 会生成三个文件\u0016123MANIFEST.MFCERT.SFCERT.RSA 1.MAINFEST.MF逐一遍历里面apk项目中的所有条目，如果是目录就跳过，如果是一个文件，就用SHA1（或者SHA256）消息摘要算法提取出该文件的摘要然后进行BASE64编码后，作为“SHA1-Digest”属性的值写入到MANIFEST.MF文件中的一个块中。该块有一个“Name”属性，其值就是该文件在apk包中的路径。 2. CERT.SF 计算上面MANIFEST.MF文件的整体SHA1值，再经过BASE64编码后，记录在CERT.SF主属性块（在文件头上）的“SHA1-Digest-Manifest”属性值值下 【校验上面文件整体的完整性】 逐条计算MANIFEST.MF文件中每一个块的SHA1，并经过BASE64编码后，记录在CERT.SF中的同名块中，属性的名字是“SHA1-Digest【校验上面文件每个条目的完整性】 主要是为了教研上面生成的CERT.SF 文件的合法性 3. CERT.RSA\u0016这里会把之前生成的 CERT.SF文件， 用私钥计算出签名（算出cret.sf 的sha1值，然后用私钥进行非对称加密）, 然后将签名以及包含公钥信息的数字证书一同写入 CERT.RSA 中保存。CERT.RSA是一个满足PKCS7格式的文件。 首先，如果你改变了apk包中的任何文件，那么在apk安装校验时，改变后的文件摘要信息与MANIFEST.MF的检验信息不同，于是验证失败，程序就不能成功安装。其次，如果你对更改的过的文件相应的算出新的摘要值，然后更改MANIFEST.MF文件里面对应的属性值，那么必定与CERT.SF文件中算出的摘要值不一样，照样验证失败。最后，如果你还不死心，继续计算MANIFEST.MF的摘要值，相应的更改CERT.SF里面的值，那么数字签名值必定与CERT.RSA文件中记录的不一样，还是失败。那么能不能继续伪造数字签名呢？不可能，因为没有数字证书对应的私钥。所以，如果要重新打包后的应用程序能再Android设备上安装，必须对其进行重签名。 安装验证主要看\u0016PackageParser.java 负责解析apk文件的签名信息 验证Apk中的每个文件的算法(数据摘要+Base64编码)和MANIFEST.MF文件中的对应属性块内容是否配对依次遍历每个文件，算出其数据指纹（会先读取MAINFEST.MF文件中的头字段 这里是”SHA1-Digest“），根据对应的加密方法使用对应的加密算法算出数据指纹，并进行base64转换，与MANIFEST.MF 的各个字段值进行验证。如果不通过，会抛出”INSTALL_PARSE_FAILED_NO_CERTIFICATION“异常，应用安装会终止。 \u0016验证CERT.SF文件的签名信息和CERT.RSA中的内容是否一致 主要调用JarUtils.\u0016verifySignature()方法，从rsa文件中获取签名信息，保存在证书数组里，（安卓apk允许对应用进行多次签名）并且验证CERT.SF文件的签名信息和CERT.RSA中的内容是否一致。这个主要是为了保证CERT.SF文件的有效性，好继续进行下一步的动作 MANIFEST.MF整个文件签名在CERT.SF文件中头属性中的值是否匹配以及验证MANIFEST.MF文件中的各个属性块的签名在CERT.SF文件中是否匹配 上面的三个方法 主要是为了保证安装的应用是未经过篡改的，在安装之前，还会再检验一下 已安装应用于即将安装的应用中的签名是否一致。如果不一致 会报错”INSTALL_PARSE_FAILED_INCONSTENT_CERTIFICATIONS“，所谓比对签名，就是比对证书中的公钥信息是否一致 我们的应用安装白名单机制，是需要sdk使用商将签名公钥提供，我们会再次使用一次rsa算法，将公钥信息进行加密后保存在系统证书白名单数据库中，私钥信息我们会写死在packageParser里，因为使用者无法拿到我们的源码，是不可能知道我们的私钥信息的，在第5步插入了自己的判断逻辑，首先获取白名单数据库中的加密签名，用私钥解密，验证应用的签名文件是否与白名单中一致，如果不是就抛出异常。”INSTALL_PARSE_FAILED_BAD_MANIFEST“ java基础：类的初始化 （主动引用 被动引用）什么时候会触发类的初始化： 使用new 关键字创建了一个类的实例 访问类的静态变量 注意 静态常量不会导致类的初始化，是因为jvm将常量当做值而不是域来看待，当用到了静态常量，jvm并不会为此生成字节码从对象中载入域的值，而是直接将该值插入字节码中。这是一种很有用的优化。但是静态常量一旦变化了，所有用到它的地方都需要重新编译。 调用了类的静态方法 反射 当初始化一个类发现父类还没初始化 会先初始化父类 虚拟机启动时，定义了main方法的类会先初始化以上被称之为 主动引用 除上述几种情况外，都属于被动引用被动引用不会触发类的初始化 子类调用父类的静态变量 子类不会初始化 通过数组定义来引用类，不会初始化 SuperClass[] classes = new SupercClass[1];不会触发初始化 访问类的常量（final），不会初始化初始化次序：父类–静态变量父类–静态初始化块子类–静态变量子类–静态初始化块子类main方法父类–变量父类–初始化块父类–构造器i=9, j=0子类–变量子类–初始化块子类–构造器i=9,j=20 class文件从解析到生成对象的全过程：1. java编译器将java文件编译为class文件class文件是一组以8位字节为基础的二进制流，各个数据项严格按照一定的次序和规则排列在class文件中，没有任何的分隔符，所有的内容都是java程序运行时的必要数据项。由上到下依次为： 头四个字节： 魔数 + class文件版本 常量池：字面量（各种字符串，final修饰符修饰的常量值。）和符号引用（类和接口的全限定名，字段的名称和描述符，方法的名称和描述符） 访问标识， 常量池之后的两个字节。标识当前是类还是接口 声明的是public 还是private abstract final之类 类索引（当前类的全限定名） 父类索引（父类的全限定名，除了object没有父类 其他都有） 接口索引（可以多继承接口，所以这是一个数组） 字段表集合： 是类字段还是实例字段（static），public 还是static 是不是volatile 是不是final。 方法表集合 属性表集合 指令码集合2. jvm运行时数据区 java程序运行的时候，jvm会把它管理的内存划分为以下几种数据区 java堆 所有线程共享，所有实例化的对象和数组都会被放在堆中。对象中的内存布局：a. 对象头：对象本身的信息：锁信息 根据是偏向锁 轻量级 重量级锁在该区域存储的数据不同。 gc分代年龄、 哈希码 类型信息： 指向该对象对应的唯一class对象指针。b. 对象数据程序中定义的各种类型的字段内容 指向的是方法区中对应的信息 c. 对其区域不够8个字节要对齐成8个字节。 方法区：类信息，常量，静态变量，jit编译器编译后的代码 常量池也是在方法区中的。对象头和方法区是线程共享的。下面是每创建一个线程 都会创建的数据区 vm栈 每个线程都会创建自己的vm栈。每调用一个方法 都会创建一个方法栈帧加入到vm栈中一个栈帧的数据结构：a. 局部变量表 方法中定义的局部变量数据b. 操作数栈 存放方法执行过程的中间变量c. 动态链接 指向该栈帧对应的常量池地址d. 返回地址 方法调用完需要返回时，需要回到调用它的方法的地址。这个就是存储这种信息的。 native方法栈 程序计数器： 记录下个指令的位置。 java 集合相关：hashMap线程不安全的集合。fail-fast机制，内部有一个volitile类型的变量记录被修改次数，当进行插入操作发现该数据与当前不一致会抛出异常。采用数组+Entry链表实现。默认初始化长度是16，扩容因子是0.75 每次扩容按照2的倍数进行扩容，而且数组长度也是2的倍数。 当查找数据的时候，首先计算插入数据key的hash值，然通过hash值与（length-1）进行与运算，求得在数组中的位置。这样比直接对数组长度求模要高效很多 index = h &amp;(length-1) 当插入数据已存在 直接覆盖插入，否则插入在entry链表表头 注： jdk1.8中 hashMap有了重大更新 为了解决hash碰撞导致的Entry链表过长的情况导致查询效率低，jdk1.8 引入了红黑树。 没有冲突，数据存储在数组中 有冲突 且Entry链表长度不超过8 将数据存储在单链表中 当Entry长度超过8 将吧Enrty单链表转化为 红黑数 红黑树 的查找和插入时间复杂度均为o(ln n) 单链表是n concurrentHashMap线程安全的hashMap 数组部分改由Segment实现，继承自并发包的ReentrainLock，实现了分段锁机制。每个segment维护一个特殊的HashEntry链表，读可以并发读取无需加锁，写是加锁的。 HashEnrty的next是final类型，不能在中间操作成员，每次put只能放在表头。hashEnrty对象的不变性，降低了读对锁的要求 value字段是volitine修饰，是线程可见，每次读取都是最新值。 如果父读的过程中发生了指令重拍现象，则加锁重读。 理想状态的并发级别是16个线程，每个Segment守护大约为总桶数的1/16 hashSet和hashMap基本一样 只不过存的时候我们只需要传key就可以，默认会放一个object对象作为value，本质还是hashMap 实现的，初始还是16 扩容系数0.75. 如果传入的key已经存在 直接返回false。 hashTable线程安全的hashMap 已经淘汰，推荐使用concurrentHashMap。默认长度11 扩容因子0.75 每次扩容 长度为2倍+1。所有的public方法用syncornized包裹，所以线程安全。不推荐使用。 LinkedHashMap非线程安全。排序的HashMap，Entry链表用的是双向链表，每个节点增加了before和after成员，构成双向链。单独增加了一个Header节点，记录链表头。是根据时间排序的。可以设置为 是插入时排序 还是取值时排序。 会将最近使用的元素放在Header节点的后一个节点，这种特性使得linkedHashMap可以作为LruCache的存储数据结构来使用，并且提供了一个eldest()方法获取最不常用的元素。 LinkedHashSet同上 ArrayList数组实现的列表，自动扩容，可被扩容，支持序列化。无参构造方法默认长度为10，扩容倍数为原来一半+1个。 Vector和ArrayList类似 也是基于数组实现的动态可扩容列表=，是线程安全的，每次扩容数据增大为原来的1倍 LinkedList双向链表实现的动态列表，插入 删除比ArrayList快，但是随机访问比Arraylist慢，因为Arraylist是基于数组的， SparseArray用双数组实现，key只能存int类型，key用一个数组存放，value也用一个数组存放，每次put元素都会进行二分法查找，将其排好序再插入，查找的时候，也会使用二分法查找，但是因为其插入，查找 删除都需要进行二分法查找，当数据量很大的时候，效率将低50% 。 因为hasMap每次扩容的时候，都需要将容量扩大一倍，同时对所有数据再hash，这个开销非常大，所以当 数据量低于1000，且key为int类型时，使用SparseArray将获得很好的性能。 CopyOnWriteArrayList读写锁，读不加锁 写加锁 适合多度少写的使用情况。 虚拟机相关 JVM–&gt; Divalk 虚拟机 –&gt; ART虚拟机JVM一个java虚拟机 必须包括 类加载器，解释执行，垃圾回收 三个部分。 1. 编译java代码首先是通过javac java编译器 将java代码编译为信息密度高的java字节码 变成class文件class文件的文件格式: 位 名称 数量 描述 U4 Magic 1 魔数 标识该文件为class文件 U2 minor_version 1 次版本 U2 Major_version 1 主版本 U2 constant_pool_count 1 常量池数量（一个class文件只有一个常量池） cp_info Constant_pool 上面-1 常量池（数据类型有11种，真正只有utf8，其他都是对其的引用） u2 Access_flags 1 类的访问标记 u2 This_class 1 记录当前类的全限定名 u2 super_class 1 父类的全限定名 u2 Interface_count interface_count 接口数量 u2 Interfaces 1 接口全限定名 u2 Fields_count 1 成员数量 field_info Fields fields_count 成员信息 U2 Methods_count 1 方法数量 Methods_info Methods methods_count 方法信息 U2 Attrtibutes_count 1 属性数量 Attrtibutes_info Attrtibutes attr_counts 属性信息 a: 常量池的类型包括： 数据类型 标记 描述 CONSTANT_Utf8 1 UTF-8编码的Unicode字符串 CONSTANT_Integer 3 int类型字面值 CONSTANT_Float 4 float类型字面值 CONSTANT_Long 5 long类型字面值 CONSTANT_Double 6 double类型字面值 CONSTANT_Class 7 对一个类或接口的符号引用 CONSTANT_String 8 String类型字面值 CONSTANT_Fieldref 9 对一个字段的符号引用 CONSTANT_Methodref 10 对一个类中声明的方法的符号引用 CONSTANT_InterfaceMethodref 11 对一个接口中声明的方法的符号引用 CONSTANT_NameAndType 12 对一个字段或方法的部分符号引用 其中 constant_uft8_info 是最基础的类型 会被其他引用 这个类型的数据是utf8格式的字符串常量 基本一个类的全部信息 都可以由字符串常量来表述了： 程序中的字符串常量 常量池所在当前类（包括接口和枚举）的全限定名 常量池所在当前类的直接父类的全限定名 常量池所在当前类型所实现或继承的所有接口的全限定名 常量池所在当前类型中所定义的字段的名称和描述符 常量池所在当前类型中所定义的方法的名称和描述符 由当前类所引用的类型的全限定名 由当前类所引用的其他类中的字段的名称和描述符 由当前类所引用的其他类中的方法的名称和描述符 与当前class文件中的属性相关的字符串， 如属性名等 b:访问标记：总共7项 标记当前类 是 class 是接口 是枚举 还是注解类型 是不是public 是不是final的注意 这是描述类层面的 不是描述方法和字段的访问类型 c：fields counts 和field字段和字段信息字段只包括当前类中定义的字段 不包括父类的字段。字段信息是一个数组 每个字段信息都是一个field_info结构 信息都是对常量池中的数据的引用包括了字段名，字段访问表示 字段类型 指向常量池的索引 以及字段的属性(标识字段是否是静态的 constant，是否过时 deprecated 以及Synthetic) d ：methods存放的是method_info 数组 标识方法信息的 access_flags ， name_index， descriptor_index 。 他们分别描述方法的访问修饰符， 方法名和方法描述符。 method_info中还有attributes_count和attributes 其中attritubes 包括方法执行过程中的所有指令： attribute_name_index指向常量池中的一个CONSTANT_Utf8_info ， 这个CONSTANT_Utf8_info 中存放的是当前属性的名字 “Code” 。 attribute_length给出了当前Code属性的长度（不包括前六字节）。 max_stack 指定当前方法被执行引擎执行的时候， 在栈帧中需要分配的操作数栈的大小。 max_locals指定当前方法被执行引擎执行的时候， 在栈帧中需要分配的局部表量表的大小。注意， 这个数字并不是局部变量的个数， 因为根据局部变量的作用域不同， 在执行到一个局部变量以外时， 下一个局部变量可以重用上一个局部变量的空间（每个局部变量在局部变量表中占用一个或两个Slot）。 方法中的局部变量包括方法的参数， 方法的默认参数this， 方法体中定义的变量， catch语句中的异常对象。 关于执行引擎的相关内容会在后面的博客中讲到。 code_length指定该方法的字节码的长度， class文件中每条字节码占一个字节。 code存放字节码指令本身， 它的长度是code_length个字节。 exception_table_length 指定异常表的大小 exception_table就是所谓的异常表， 它是对方法体中try-catch_finally的描述。 exception_table可以看做是一个数组， 每个数组项是一个exception_info结构， 一般来说每个catch块对应一个exception_info，编译器也可能会为当前方法生成一些exception_info。 exception_info的结构如下（为了直观的显示exception_info， exception_table和Code属性的关系， 画出了Code属性，的话读者就会更清楚各个数据项之间的位置关系和包含关系）： 加载class字节码jvm的内存结构 通过一个类的全限定名来获取其定义的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在 Java 堆中生成一个代表这个类的 java.lang.Class 对象，作为对方法区中这些数据的访问入 为什么用Class.forName(“Test”).getMethod(“void”,int.class) 这样的写法被称之为反射呢。 因为一个类被加载之后，比如上文的Test类，Test.class文件中的常量池 会被加载在运行时数据结构中的方法区中，这些数据是线程共享的。 当类被加载之后，会生成一个Class类型对象，该对象存放在堆中，他对方法区中该类的数据做了映射，就像是一面镜子，反射着这个类的所有信息。 所以通过class对象来获取类信息的方式，被形象的称之为反射。 链接验证准别 为静态类变量分配默认值解析 将符号引用替换为直接引用 （会发生在初始化前 也可能发生在初始化之后）比如静态类变量的引用 会在类被加载的时候就去查找 本类 父类 父接口是否存在 如果存在就将该静态类变量的引用替换为其在内存中的真正地址 与当前类其实已经没有关系了。 所以乳 如果子类引用了父类的静态类变量 并不会触发子类的初始化。 此时链接发生在初始化之前。 初始化开始对成员变量进行初始化并赋值 方法的执行时序 JIT AOT JAVAC 编译器区别javac就是我们常用的将java文件编译为class字节码的 之前的java程序在运行过程中 都是由解释器 一行行解析class字节码 一行行执行 但是这势必会存在效率问题 因为解释运行的速度不高。后来为了优化执行速度，出现了JIT 编译器。JIT JUST in time. 顾名思义 执行器编译。JIT编译器会判断 在程序执行过程中 哪些代码是高频执行的，并将改代码直接翻译成与当前平台相关的机器码。下次再执行到该代码时 会直接执行机器码 速度就快了很多。 在5.0以前 divlik虚拟机 就是JIT 编译器 这个高频代码的判断 被称之为 热点探测 包括 基于采样点探测 基于计数器探测。 AOTAOT ahead of time在程序运行之前 就将class文件直接翻译成对应平台的字节码 这样会加快应用的启动时间，因为直接从字节码开始读取的。但是会带来内存增大的问题。而且在android平台上 还会带来意想不到的坑，比如如果在so文件中引用了libs目录下的其他so库，会爆找不到路径的错误，是因为aot编译器直接将so库与java文件直接打包成了平台对应的机器码文件aot文件。 android 历史各版本的编译器演进： Android 4.x(Interpreter + JIT)原理：平时代码走解释器，但热点trace会执行JIT进行即时编译优点：占用内存少缺点：耗电(退出App下次启动还会重复编译)，卡顿(JIT编译时)Android 5.0/5.1/6.0(interpreter + AOT)原理: 在AOT模式下，App在安装过程时， 就会完成所有编译。优点: 性能好缺点: App安装时间长，占用存储空间多。】 Android 7.0/7.1的ART引入了全新的Hybrid模式(Interpreter + JIT + AOT)原理: App在安装时不编译， 所以安装速度快。在运行App时， 先走解释器， 然后热点函数会被识别，并被JIT进行编译， 存储在jit code cache， 并产生profile文件(记录热点函数信息)。 等手机进入charging和idle状态下， 系统会每隔一段时间扫描App目录下profile文件，并执行AOT编译(Google官方称之为profile-guided compilation)。不论是jit编译的binary code, 还是AOT编译的binary code, 它们之间的性能差别不大， 因为它们使用同一个optimizing compiler进行编译。优点: App安装速度快，占用存储少(只编译热点函数)。缺点: 前几次运行会较慢， 只有用户操作得次数越多，jit 和AOT编译后， 性能才会跟上来dv虚拟机 对比jvm虚拟机jvm 的每一个class文件都对应一个常量池。 但是很多常量池中的信息其实是重复的，dv虚拟机在将class文件编译为dex文件时，将所有class文件的常量池合并为一个，减少了apk的体积。 其次 jvm是基于求职栈的 dvm的指令比jvm长，是基于虚拟寄存器的。dvm的方法栈帧中不存在 求值栈和临时变量，替代的是虚拟寄存器、常用的是v0 -v15 dvm的虚拟寄存器 每个线程都有一个 不用担心多线程 保护寄存器问题。 手画一下Android系统架构图，描述一下各个层次的作用？Android系统架构图 从上到下依次分为六层： 应用框架层 进程通信层 系统服务层 Android运行时层 硬件抽象层 Linux内核层 Activity如与Service通信？可以通过bindService的方式，先在Activity里实现一个ServiceConnection接口，并将该接口传递给bindService()方法，在ServiceConnection接口的onServiceConnected()方法里执行相关操作。 Service的生命周期与启动方法由什么区别？ startService()：开启Service，调用者退出后Service仍然存在。 bindService()：开启Service，调用者退出后Service也随即退出。 Service生命周期： 只是用startService()启动服务：onCreate() -&gt; onStartCommand() -&gt; onDestory 只是用bindService()绑定服务：onCreate() -&gt; onBind() -&gt; onUnBind() -&gt; onDestory 同时使用startService()启动服务与bindService()绑定服务：onCreate() -&gt; onStartCommnad() -&gt; onBind() -&gt; onUnBind() -&gt; onDestory Service先start再bind如何关闭service，为什么bindService可以跟Activity生命周期联动？广播分为哪几种，应用场景是什么？ 普通广播：调用sendBroadcast()发送，最常用的广播。 有序广播：调用sendOrderedBroadcast()，发出去的广播会被广播接受者按照顺序接收，广播接收者按照Priority属性值从大-小排序，Priority属性相同者，动态注册的广播优先，广播接收者还可以选择对广播进行截断和修改。 广播的两种注册方式有什么区别？ 静态注册：常驻系统，不受组件生命周期影响，即便应用退出，广播还是可以被接收，耗电、占内存。 动态注册：非常驻，跟随组件的生命变化，组件结束，广播结束。在组件结束前，需要先移除广播，否则容易造成内存泄漏。 广播发送和接收的原理了解吗？ 继承BroadcastReceiver，重写onReceive()方法。 通过Binder机制向ActivityManagerService注册广播。 通过Binder机制向ActivityMangerService发送广播。 ActivityManagerService查找符合相应条件的广播（IntentFilter/Permission）的BroadcastReceiver，将广播发送到BroadcastReceiver所在的消息队列中。 BroadcastReceiver所在消息队列拿到此广播后，回调它的onReceive()方法。 广播传输的数据是否有限制，是多少，为什么要限制？ContentProvider、ContentResolver与ContentObserver之间的关系是什么？ ContentProvider：管理数据，提供数据的增删改查操作，数据源可以是数据库、文件、XML、网络等，ContentProvider为这些数据的访问提供了统一的接口，可以用来做进程间数据共享。 ContentResolver：ContentResolver可以不同URI操作不同的ContentProvider中的数据，外部进程可以通过ContentResolver与ContentProvider进行交互。 ContentObserver：观察ContentProvider中的数据变化，并将变化通知给外界。 遇到过哪些关于Fragment的问题，如何处理的？ getActivity()空指针：这种情况一般发生在在异步任务里调用getActivity()，而Fragment已经onDetach()，此时就会有空指针，解决方案是在Fragment里使用一个全局变量mActivity，在onAttach()方法里赋值，这样可能会引起内存泄漏，但是异步任务没有停止的情况下本身就已经可能内存泄漏，相比直接crash，这种方式显得更妥当一些。 Fragment视图重叠：在类onCreate()的方法加载Fragment，并且没有判断saveInstanceState==null或if(findFragmentByTag(mFragmentTag) == null)，导致重复加载了同一个Fragment导致重叠。（PS：replace情况下，如果没有加入回退栈，则不判断也不会造成重叠，但建议还是统一判断下） 12345678@Override protected void onCreate(@Nullable Bundle savedInstanceState) &#123;// 在页面重启时，Fragment会被保存恢复，而此时再加载Fragment会重复加载，导致重叠 ; if(saveInstanceState == null)&#123; // 或者 if(findFragmentByTag(mFragmentTag) == null) // 正常情况下去 加载根Fragment &#125; &#125; Android里的Intent传递的数据有大小限制吗，如何解决？Intent传递数据大小的限制大概在1M左右，超过这个限制就会静默崩溃。处理方式如下：因为binder给用户进程就是1m 给系统核心进程是4m 给serviceMnager是128kb 进程内：EventBus，文件缓存、磁盘缓存。 进程间：通过ContentProvider进行款进程数据共享和传递。 描述一下Android的事件分发机制？Android事件分发机制的本质：事件从哪个对象发出，经过哪些对象，最终由哪个对象处理了该事件。此处对象指的是Activity、Window与View。 Android事件的分发顺序：Activity（Window） -&gt; ViewGroup -&gt; View Android事件的分发主要由三个方法来完成，如下所示： 123456789101112131415// 父View调用dispatchTouchEvent()开始分发事件public boolean dispatchTouchEvent(MotionEvent event)&#123; boolean consume = false; // 父View决定是否拦截事件 if(onInterceptTouchEvent(event))&#123; // 父View调用onTouchEvent(event)消费事件，如果该方法返回true，表示 // 该View消费了该事件，后续该事件序列的事件（Down、Move、Up）将不会在传递 // 该其他View。 consume = onTouchEvent(event); &#125;else&#123; // 调用子View的dispatchTouchEvent(event)方法继续分发事件 consume = child.dispatchTouchEvent(event); &#125; return consume;&#125; 伪代码如下 1234567891011121314151617181920212223242526/** * 点击事件产生后 */ // 步骤1：调用dispatchTouchEvent（） public boolean dispatchTouchEvent(MotionEvent ev) &#123; boolean consume = false; //代表 是否会消费事件 // 步骤2：判断是否拦截事件 if (onInterceptTouchEvent(ev)) &#123; // a. 若拦截，则将该事件交给当前View进行处理 // 即调用onTouchEvent (）方法去处理点击事件 consume = onTouchEvent (ev) ; &#125; else &#123; // b. 若不拦截，则将该事件传递到下层 // 即 下层元素的dispatchTouchEvent（）就会被调用，重复上述过程 // 直到点击事件被最终处理为止 consume = child.dispatchTouchEvent (ev) ; &#125; // 步骤3：最终返回通知 该事件是否被消费（接收 &amp; 处理） return consume; &#125; 描述一下View的绘制原理？View的绘制流程主要分为三步： onMeasure：测量视图的大小，从顶层父View到子View递归调用measure()方法，measure()调用onMeasure()方法，onMeasure()方法完成绘制工作。 onLayout：确定视图的位置，从顶层父View到子View递归调用layout()方法，父View将上一步measure()方法得到的子View的布局大小和布局参数，将子View放在合适的位置上。 onDraw：绘制最终的视图，首先ViewRoot创建一个Canvas对象，然后调用onDraw()方法进行绘制。onDraw()方法的绘制流程为：① 绘制视图背景。② 绘制画布的图层。 ③ 绘制View内容。④ 绘制子视图，如果有的话。⑤ 还原图层。⑥ 绘制滚动条。 requestLayout()、invalidate()与postInvalidate()有什么区别？ requestLayout()：该方法会递归调用父窗口的requestLayout()方法，直到触发ViewRootImpl的performTraversals()方法，此时mLayoutRequestede为true，会触发onMesaure()与onLayout()方法，不一定会触发onDraw()方法。 invalidate()：该方法递归调用父View的invalidateChildInParent()方法，直到调用ViewRootImpl的invalidateChildInParent()方法，最终触发ViewRootImpl的performTraversals()方法，此时mLayoutRequestede为false，不会触发onMesaure()与onLayout()方法，当时会触发onDraw()方法。 postInvalidate()：该方法功能和invalidate()一样，只是它可以在非UI线程中调用。 一般说来需要重新布局就调用requestLayout()方法，需要重新绘制就调用invalidate()方法。 Scroller用过吗，了解它的原理吗？了解APK的打包流程吗，描述一下？Android的包文件APK分为两个部分：代码和资源，所以打包方面也分为资源打包和代码打包两个方面，这篇文章就来分析资源和代码的编译打包原理。 APK整体的的打包流程如下图所示：具体说来： 通过AAPT工具进行资源文件（包括AndroidManifest.xml、布局文件、各种xml资源等）的打包，生成R.java文件。 通过AIDL工具处理AIDL文件，生成相应的Java文件。 通过Javac工具编译项目源码，生成Class文件。 通过DX工具将所有的Class文件转换成DEX文件，该过程主要完成Java字节码转换成Dalvik字节码，压缩常量池以及清除冗余信息等工作。 通过ApkBuilder工具将资源文件、DEX文件打包生成APK文件。 利用KeyStore对生成的APK文件进行签名。 如果是正式版的APK，还会利用ZipAlign工具进行对齐处理，对齐的过程就是将APK文件中所有的资源文件举例文件的起始距离都偏移4字节的整数倍，这样通过内存映射访问APK文件的速度会更快。 了解APK的安装流程吗，描述一下？APK的安装流程如下所示： 复制APK到/data/app目录下，解压并扫描安装包。 资源管理器解析APK里的资源文件。 解析AndroidManifest文件，并在/data/data/目录下创建对应的应用数据目录。 然后对dex文件进行优化，并保存在dalvik-cache目录下。 将AndroidManifest文件解析出的四大组件信息注册到PackageManagerService中。 安装完成后，发送广播。 当点击一个应用图标以后，都发生了什么，描述一下这个过程？点击应用图标后会去启动应用的LauncherActivity，如果LancerActivity所在的进程没有创建，还会创建新进程，整体的流程就是一个Activity的启动流程。 Activity的启动流程图（放大可查看）如下所示： 整个流程涉及的主要角色有： Instrumentation: 监控应用与系统相关的交互行为。 AMS：组件管理调度中心，什么都不干，但是什么都管。 ActivityStarter：Activity启动的控制器，处理Intent与Flag对Activity启动的影响，具体说来有：1 寻找符合启动条件的Activity，如果有多个，让用户选择；2 校验启动参数的合法性；3 返回int参数，代表Activity是否启动成功。 ActivityStackSupervisior：这个类的作用你从它的名字就可以看出来，它用来管理任务栈。 ActivityStack：用来管理任务栈里的Activity。 ActivityThread：最终干活的人，是ActivityThread的内部类，Activity、Service、BroadcastReceiver的启动、切换、调度等各种操作都在这个类里完成。 注：这里单独提一下ActivityStackSupervisior，这是高版本才有的类，它用来管理多个ActivityStack，早期的版本只有一个ActivityStack对应着手机屏幕，后来高版本支持多屏以后，就有了多个ActivityStack，于是就引入了ActivityStackSupervisior用来管理多个ActivityStack。 整个流程主要涉及四个进程： 调用者进程，如果是在桌面启动应用就是Launcher应用进程。 ActivityManagerService等所在的System Server进程，该进程主要运行着系统服务组件。 Zygote进程，该进程主要用来fork新进程。 新启动的应用进程，该进程就是用来承载应用运行的进程了，它也是应用的主线程（新创建的进程就是主线程），处理组件生命周期、界面绘制等相关事情。 有了以上的理解，整个流程可以概括如下： 点击桌面应用图标，Launcher进程将启动Activity（MainActivity）的请求以Binder的方式发送给了AMS。 AMS接收到启动请求后，交付ActivityStarter处理Intent和Flag等信息，然后再交给ActivityStackSupervisior/ActivityStack处理Activity进栈相关流程。同时以Socket方式请求Zygote进程fork新进程。 Zygote接收到新进程创建请求后fork出新进程。 在新进程里创建ActivityThread对象，新创建的进程就是应用的主线程，在主线程里开启Looper消息循环，开始处理创建Activity。 ActivityThread利用ClassLoader去加载Activity、创建Activity实例，并回调Activity的onCreate()方法。这样便完成了Activity的启动。 BroadcastReceiver与LocalBroadcastReceiver有什么区别？ BroadcastReceiver 是跨应用广播，利用Binder机制实现。 LocalBroadcastReceiver 是应用内广播，利用Handler实现，利用了IntentFilter的match功能，提供消息的发布与接收功能，实现应用内通信，效率比较高。 Android Handler机制是做什么的，原理了解吗？Android消息循环流程图如下所示： 主要涉及的角色如下所示： Message：消息，分为硬件产生的消息（例如：按钮、触摸）和软件产生的消息。 MessageQueue：消息队列，主要用来向消息池添加消息和取走消息。 Looper：消息循环器，主要用来把消息分发给相应的处理者。 Handler：消息处理器，主要向消息队列发送各种消息以及处理各种消息。 整个消息的循环流程还是比较清晰的，具体说来： Handler通过sendMessage()发送消息Message到消息队列MessageQueue。 Looper通过loop()不断提取触发条件的Message，并将Message交给对应的target handler来处理。 target handler调用自身的handleMessage()方法来处理Message。 事实上，在整个消息循环的流程中，并不只有Java层参与，很多重要的工作都是在C++层来完成的。我们来看下这些类的调用关系。 注：虚线表示关联关系，实线表示调用关系。 在这些类中MessageQueue是Java层与C++层维系的桥梁，MessageQueue与Looper相关功能都通过MessageQueue的Native方法来完成，而其他虚线连接的类只有关联关系，并没有直接调用的关系，它们发生关联的桥梁是MessageQueue。 Android Binder机制是做什么的，为什么选用Binder，原理了解吗？Android Binder是用来做进程通信的，Android的各个应用以及系统服务都运行在独立的进程中，它们的通信都依赖于Binder。 为什么选用Binder，在讨论这个问题之前，我们知道Android也是基于Linux内核，Linux现有的进程通信手段有以下几种： 管道：在创建时分配一个page大小的内存，缓存区大小比较有限； 消息队列：信息复制两次，额外的CPU消耗；不合适频繁或信息量大的通信； 共享内存：无须复制，共享缓冲区直接付附加到进程虚拟地址空间，速度快；但进程间的同步问题操作系统无法实现，必须各进程利用同步工具解决； 套接字：作为更通用的接口，传输效率低，主要用于不通机器或跨网络的通信； 信号量：常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。6. 信号: 不适用于信息交换，更适用于进程中断控制，比如非法内存访问，杀死某个进程等； 既然有现有的IPC方式，为什么重新设计一套Binder机制呢。主要是出于以上三个方面的考量： 高性能：从数据拷贝次数来看Binder只需要进行一次内存拷贝，而管道、消息队列、Socket都需要两次，共享内存不需要拷贝，Binder的性能仅次于共享内存。 稳定性：上面说到共享内存的性能优于Binder，那为什么不适用共享内存呢，因为共享内存需要处理并发同步问题，控制负责，容易出现死锁和资源竞争，稳定性较差。而Binder基于C/S架构，客户端与服务端彼此独立，稳定性较好。 安全性：我们知道Android为每个应用分配了UID，用来作为鉴别进程的重要标志，Android内部也依赖这个UID进行权限管理，包括6.0以前的固定权限和6.0以后的动态权限，传荣IPC只能由用户在数据包里填入UID/PID，这个标记完全是在用户空间控制的，没有放在内核空间，因此有被恶意篡改的可能，因此Binder的安全性更高。 描述一下Activity的生命周期，这些生命周期是如何管理的？Activity与Fragment生命周期如下所示： 读者可以从上图看出，Activity有很多种状态，状态之间的变化也比较复杂，在众多状态中，只有三种是常驻状态： Resumed（运行状态）：Activity处于前台，用户可以与其交互。 Paused（暂停状态）：Activity被其他Activity部分遮挡，无法接受用户的输入。 Stopped（停止状态）：Activity被完全隐藏，对用户不可见，进入后台。 其他的状态都是中间状态。 我们再来看看生命周期变化时的整个调度流程，生命周期调度流程图如下所示： 所以你可以看到，整个流程是这样的： 比方说我们点击跳转一个新Activity，这个时候Activity会入栈，同时它的生命周期也会从onCreate()到onResume()开始变换，这个过程是在ActivityStack里完成的，ActivityStack是运行在Server进程里的，这个时候Server进程就通过ApplicationThread的代理对象ApplicationThreadProxy向运行在app进程ApplicationThread发起操作请求。 ApplicationThread接收到操作请求后，因为它是运行在app进程里的其他线程里，所以ApplicationThread需要通过Handler向主线程ActivityThread发送操作消息。 主线程接收到ApplicationThread发出的消息后，调用主线程ActivityThread执行响应的操作，并回调Activity相应的周期方法。 注：这里提到了主线程ActivityThread，更准确来说ActivityThread不是线程，因为它没有继承Thread类或者实现Runnable接口，它是运行在应用主线程里的对象，那么应用的主线程到底是什么呢？从本质上来讲启动启动时创建的进程就是主线程，线程和进程处理是否共享资源外，没有其他的区别，对于Linux来说，它们都只是一个struct结构体。 Activity的通信方式有哪些？ startActivityForResult EventBus LocalBroadcastReceiver Android应用里有几种Context对象，Context类图如下所示： 可以发现Context是个抽象类，它的具体实现类是ContextImpl，ContextWrapper是个包装类，内部的成员变量mBase指向的也是个ContextImpl对象，ContextImpl完成了实际的功能，Activity、Service与Application都直接或者间接的继承ContextWrapper。 描述一下进程和Application的生命周期？一个安装的应用对应一个LoadedApk对象，对应一个Application对象，对于四大组件，Application的创建和获取方式也是不尽相同的，具体说来： Activity：通过LoadedApk的makeApplication()方法创建。 Service：通过LoadedApk的makeApplication()方法创建。 静态广播：通过其回调方法onReceive()方法的第一个参数指向Application。 ContentProvider：无法获取Application，因此此时Application不一定已经初始化。 Android哪些情况会导致内存泄漏，如何分析内存泄漏？常见的产生内存泄漏的情况如下所示： 持有静态的Context（Activity）引用。 持有静态的View引用， 内部类&amp;匿名内部类实例无法释放（有延迟时间等等），而内部类又持有外部类的强引用，导致外部类无法释放，这种匿名内部类常见于监听器、Handler、Thread、TimerTask 资源使用完成后没有关闭，例如：BraodcastReceiver，ContentObserver，File，Cursor，Stream，Bitmap。 不正确的单例模式，比如单例持有Activity。 集合类内存泄漏，如果一个集合类是静态的（缓存HashMap），只有添加方法，没有对应的删除方法，会导致引用无法被释放，引发内存泄漏。 错误的覆写了finalize()方法，finalize()方法执行执行不确定，可能会导致引用无法被释放。 查找内存泄漏可以使用Android Profiler工具或者利用LeakCanary工具。 Android有哪几种进程，是如何管理的？Android的进程主要分为以下几种： 前台进程 用户当前操作所必需的进程。如果一个进程满足以下任一条件，即视为前台进程： 托管用户正在交互的 Activity（已调用 Activity 的 onResume() 方法） 托管某个 Service，后者绑定到用户正在交互的 Activity 托管正在“前台”运行的 Service（服务已调用 startForeground()） 托管正执行一个生命周期回调的 Service（onCreate()、onStart() 或 onDestroy()） 托管正执行其 onReceive() 方法的 BroadcastReceiver 通常，在任意给定时间前台进程都为数不多。只有在内存不足以支持它们同时继续运行这一万不得已的情况下，系统才会终止它们。 此时，设备往往已达到内存分页状态，因此需要终止一些前台进程来确保用户界面正常响应。 可见进程 没有任何前台组件、但仍会影响用户在屏幕上所见内容的进程。 如果一个进程满足以下任一条件，即视为可见进程： 托管不在前台、但仍对用户可见的 Activity（已调用其 onPause() 方法）。例如，如果前台 Activity 启动了一个对话框，允许在其后显示上一 Activity，则有可能会发生这种情况。 托管绑定到可见（或前台）Activity 的 Service。 可见进程被视为是极其重要的进程，除非为了维持所有前台进程同时运行而必须终止，否则系统不会终止这些进程。 服务进程 正在运行已使用 startService() 方法启动的服务且不属于上述两个更高类别进程的进程。尽管服务进程与用户所见内容没有直接关联，但是它们通常在执行一些用户关心的操作（例如，在后台播放音乐或从网络下载数据）。因此，除非内存不足以维持所有前台进程和可见进程同时运行，否则系统会让服务进程保持运行状态。 后台进程 包含目前对用户不可见的 Activity 的进程（已调用 Activity 的 onStop() 方法）。这些进程对用户体验没有直接影响，系统可能随时终止它们，以回收内存供前台进程、可见进程或服务进程使用。 通常会有很多后台进程在运行，因此它们会保存在 LRU （最近最少使用）列表中，以确保包含用户最近查看的 Activity 的进程最后一个被终止。如果某个 Activity 正确实现了生命周期方法，并保存了其当前状态，则终止其进程不会对用户体验产生明显影响，因为当用户导航回该 Activity 时，Activity 会恢复其所有可见状态。 空进程 不含任何活动应用组件的进程。保留这种进程的的唯一目的是用作缓存，以缩短下次在其中运行组件所需的启动时间。 为使总体系统资源在进程缓存和底层内核缓存之间保持平衡，系统往往会终止这些进程。 ActivityManagerService负责根据各种策略算法计算进程的adj值，然后交由系统内核进行进程的管理。 SharePreference性能优化，可以做进程同步吗？在Android中, SharePreferences是一个轻量级的存储类，特别适合用于保存软件配置参数。使用SharedPreferences保存数据，其背后是用xml文件存放数据，文件存放在/data/data/ &lt; package name &gt; /shared_prefs目录下. 之所以说SharedPreference是一种轻量级的存储方式，是因为它在创建的时候会把整个文件全部加载进内存，如果SharedPreference文件比较大，会带来以下问题： 第一次从sp中获取值的时候，有可能阻塞主线程，使界面卡顿、掉帧。 解析sp的时候会产生大量的临时对象，导致频繁GC，引起界面卡顿。 这些key和value会永远存在于内存之中，占用大量内存。 优化建议 不要存放大的key和value，会引起界面卡、频繁GC、占用内存等等。 毫不相关的配置项就不要放在在一起，文件越大读取越慢。 读取频繁的key和不易变动的key尽量不要放在一起，影响速度，如果整个文件很小，那么忽略吧，为了这点性能添加维护成本得不偿失。 不要乱edit和apply，尽量批量修改一次提交，多次apply会阻塞主线程。 尽量不要存放JSON和HTML，这种场景请直接使用JSON。 SharedPreference无法进行跨进程通信，MODE_MULTI_PROCESS只是保证了在API 11以前的系统上，如果sp已经被读取进内存，再次获取这个SharedPreference的时候，如果有这个flag，会重新读一遍文件，仅此而已。 如何做SQLite升级？数据库升级增加表和删除表都不涉及数据迁移，但是修改表涉及到对原有数据进行迁移。升级的方法如下所示： 将现有表命名为临时表。 创建新表。 将临时表的数据导入新表。 删除临时表。 重写 如果是跨版本数据库升级，可以由两种方式，如下所示： 逐级升级，确定相邻版本与现在版本的差别，V1升级到V2,V2升级到V3，依次类推。 跨级升级，确定每个版本与现在数据库的差别，为每个case编写专门升级大代码。 进程保护如何做，如何唤醒其他进程？进程保活主要有两个思路： 提升进程的优先级，降低进程被杀死的概率。 拉活已经被杀死的进程。 如何提升优先级，如下所示： 监控手机锁屏事件，在屏幕锁屏时启动一个像素的Activity，在用户解锁时将Activity销毁掉，前台Activity可以将进程变成前台进程，优先级升级到最高。 如果拉活 利用广播拉活Activity。 理解序列化吗，Android为什么引入Parcelable？所谓序列化就是将对象变成二进制流，便于存储和传输。 Serializable是java实现的一套序列化方式，可能会触发频繁的IO操作，效率比较低，适合将对象存储到磁盘上的情况。 Parcelable是Android提供一套序列化机制，它将序列化后的字节流写入到一个共性内存中，其他对象可以从这块共享内存中读出字节流，并反序列化成对象。因此效率比较高，适合在对象间或者进程间传递信息。 如何计算一个Bitmap占用内存的大小，怎么保证加载Bitmap不产生内存溢出？Bitamp 占用内存大小 = 宽度像素 x （inTargetDensity / inDensity） x 高度像素 x （inTargetDensity / inDensity）x 一个像素所占的内存 注：这里inDensity表示目标图片的dpi（放在哪个资源文件夹下），inTargetDensity表示目标屏幕的dpi，所以你可以发现inDensity和inTargetDensity会对Bitmap的宽高进行拉伸，进而改变Bitmap占用内存的大小。 在Bitmap里有两个获取内存占用大小的方法。 getByteCount()：API12 加入，代表存储 Bitmap 的像素需要的最少内存。 getAllocationByteCount()：API19 加入，代表在内存中为 Bitmap 分配的内存大小，代替了 getByteCount() 方法。 在不复用 Bitmap 时，getByteCount() 和 getAllocationByteCount 返回的结果是一样的。在通过复用 Bitmap 来解码图片时，那么 getByteCount() 表示新解码图片占用内存的大小，getAllocationByteCount() 表示被复用 Bitmap真实占用的内存大小（即 mBuffer 的长度）。 为了保证在加载Bitmap的时候不产生内存溢出，可以受用BitmapFactory进行图片压缩，主要有以下几个参数： BitmapFactory.Options.inPreferredConfig：将ARGB_8888改为RGB_565，改变编码方式，节约内存。 BitmapFactory.Options.inSampleSize：缩放比例，可以参考Luban那个库，根据图片宽高计算出合适的缩放比例。 BitmapFactory.Options.inPurgeable：让系统可以内存不足时回收内存。 Android如何在不压缩的情况下加载高清大图？使用BitmapRegionDecoder进行布局加载。 Android里的内存缓存和磁盘缓存是怎么实现的。内存缓存基于LruCache实现，磁盘缓存基于DiskLruCache实现。这两个类都基于Lru算法和LinkedHashMap来实现。 LRU算法可以用一句话来描述，如下所示： LRU是Least Recently Used的缩写，最近最久未使用算法，从它的名字就可以看出，它的核心原则是如果一个数据在最近一段时间没有使用到，那么它在将来被访问到的可能性也很小，则这类数据项会被优先淘汰掉。 LruCache的原理是利用LinkedHashMap持有对象的强引用，按照Lru算法进行对象淘汰。具体说来假设我们从表尾访问数据，在表头删除数据，当访问的数据项在链表中存在时，则将该数据项移动到表尾，否则在表尾新建一个数据项。当链表容量超过一定阈值，则移除表头的数据。 为什么会选择LinkedHashMap呢？ 这跟LinkedHashMap的特性有关，LinkedHashMap的构造函数里有个布尔参数accessOrder，当它为true时，LinkedHashMap会以访问顺序为序排列元素，否则以插入顺序为序排序元素。 DiskLruCache与LruCache原理相似，只是多了一个journal文件来做磁盘文件的管理和迎神，如下所示： 12345678libcore.io.DiskLruCache111DIRTY 1517126350519CLEAN 1517126350519 5325928REMOVE 1517126350519 注：这里的缓存目录是应用的缓存目录/data/data/pckagename/cache，未root的手机可以通过以下命令进入到该目录中或者将该目录整体拷贝出来： 12345678//进入/data/data/pckagename/cache目录adb shellrun-as com.your.packagename cp /data/data/com.your.packagename///将/data/data/pckagename目录拷贝出来adb backup -noapk com.your.packagename 我们来分析下这个文件的内容： 第一行：libcore.io.DiskLruCache，固定字符串。 第二行：1，DiskLruCache源码版本号。 第三行：1，App的版本号，通过open()方法传入进去的。 第四行：1，每个key对应几个文件，一般为1. 第五行：空行 第六行及后续行：缓存操作记录。 第六行及后续行表示缓存操作记录，关于操作记录，我们需要了解以下三点： DIRTY 表示一个entry正在被写入。写入分两种情况，如果成功会紧接着写入一行CLEAN的记录；如果失败，会增加一行REMOVE记录。注意单独只有DIRTY状态的记录是非法的。 当手动调用remove(key)方法的时候也会写入一条REMOVE记录。 READ就是说明有一次读取的记录。 CLEAN的后面还记录了文件的长度，注意可能会一个key对应多个文件，那么就会有多个数字。 PathClassLoader与DexClassLoader有什么区别？ PathClassLoader：只能加载已经安装到Android系统的APK文件，即/data/app目录，Android默认的类加载器。 DexClassLoader：可以加载任意目录下的dex、jar、apk、zip文件。 WebView优化了解吗，如何提高WebView的加载速度？为什么WebView加载会慢呢？ 这是因为在客户端中，加载H5页面之前，需要先初始化WebView，在WebView完全初始化完成之前，后续的界面加载过程都是被阻塞的。 优化手段围绕着以下两个点进行： 预加载WebView。 加载WebView的同时，请求H5页面数据。 因此常见的方法是： 全局WebView。 客户端代理页面请求。WebView初始化完成后向客户端请求数据。 asset存放离线包。 除此之外还有一些其他的优化手段： 脚本执行慢，可以让脚本最后运行，不阻塞页面解析。 DNS与链接慢，可以让客户端复用使用的域名与链接。 React框架代码执行慢，可以将这部分代码拆分出来，提前进行解析。 Java和JS的相互调用怎么实现，有做过什么优化吗？jockeyjs：https://github.com/tcoulter/jockeyjs 对协议进行统一的封装和处理。 JNI了解吗，Java与C++如何相互调用？Java调用C++ 在Java中声明Native方法（即需要调用的本地方法） 编译上述 Java源文件javac（得到 .class文件）3。 通过 javah 命令导出JNI的头文件（.h文件） 使用 Java需要交互的本地代码 实现在 Java中声明的Native方法 编译.so库文件 通过Java命令执行 Java程序，最终实现Java调用本地代码 C++调用Java 从classpath路径下搜索ClassMethod这个类，并返回该类的Class对象。 获取类的默认构造方法ID。 查找实例方法的ID。 创建该类的实例。 调用对象的实例方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445JNIEXPORT void JNICALL Java_com_study_jnilearn_AccessMethod_callJavaInstaceMethod (JNIEnv *env, jclass cls) &#123; jclass clazz = NULL; jobject jobj = NULL; jmethodID mid_construct = NULL; jmethodID mid_instance = NULL; jstring str_arg = NULL; // 1、从classpath路径下搜索ClassMethod这个类，并返回该类的Class对象 clazz = (*env)-&gt;FindClass(env, \"com/study/jnilearn/ClassMethod\"); if (clazz == NULL) &#123; printf(\"找不到'com.study.jnilearn.ClassMethod'这个类\"); return; &#125; // 2、获取类的默认构造方法ID mid_construct = (*env)-&gt;GetMethodID(env,clazz, \"&lt;init&gt;\",\"()V\"); if (mid_construct == NULL) &#123; printf(\"找不到默认的构造方法\"); return; &#125; // 3、查找实例方法的ID mid_instance = (*env)-&gt;GetMethodID(env, clazz, \"callInstanceMethod\", \"(Ljava/lang/String;I)V\"); if (mid_instance == NULL) &#123; return; &#125; // 4、创建该类的实例 jobj = (*env)-&gt;NewObject(env,clazz,mid_construct); if (jobj == NULL) &#123; printf(\"在com.study.jnilearn.ClassMethod类中找不到callInstanceMethod方法\"); return; &#125; // 5、调用对象的实例方法 str_arg = (*env)-&gt;NewStringUTF(env,\"我是实例方法\"); (*env)-&gt;CallVoidMethod(env,jobj,mid_instance,str_arg,200); // 删除局部引用 (*env)-&gt;DeleteLocalRef(env,clazz); (*env)-&gt;DeleteLocalRef(env,jobj); (*env)-&gt;DeleteLocalRef(env,str_arg); &#125; 了解插件化和热修复吗，它们有什么区别，理解它们的原理吗？ 插件化：插件化是体现在功能拆分方面的，它将某个功能独立提取出来，独立开发，独立测试，再插入到主应用中。依次来较少主应用的规模。 热修复：热修复是体现在bug修复方面的，它实现的是不需要重新发版和重新安装，就可以去修复已知的bug。 利用PathClassLoader和DexClassLoader去加载与bug类同名的类，替换掉bug类，进而达到修复bug的目的，原理是在app打包的时候阻止类打上CLASS_ISPREVERIFIED标志，然后在热修复的时候动态改变BaseDexClassLoader对象间接引用的dexElements，替换掉旧的类。 目前热修复框架主要分为两大类： Sophix：修改方法指针。 Tinker：修改dex数组元素。 如何做性能优化？ 节制的使用Service，当启动一个Service时，系统总是倾向于保留这个Service依赖的进程，这样会造成系统资源的浪费，可以使用IntentService，执行完成任务后会自动停止。 当界面不可见时释放内存，可以重写Activity的onTrimMemory()方法，然后监听TRIM_MEMORY_UI_HIDDEN这个级别，这个级别说明用户离开了页面，可以考虑释放内存和资源。 避免在Bitmap浪费过多的内存，使用压缩过的图片，也可以使用Fresco等库来优化对Bitmap显示的管理。 使用优化过的数据集合SparseArray代替HashMap，HashMap为每个键值都提供一个对象入口，使用SparseArray可以免去基本对象类型转换为引用数据类想的时间。 如果防止过度绘制，如何做布局优化？ 使用include复用布局文件。 使用merge标签避免嵌套布局。 使用stub标签仅在需要的时候在展示出来。 如何提交代码质量？ 避免创建不必要的对象，尽可能避免频繁的创建临时对象，例如在for循环内，减少GC的次数。 尽量使用基本数据类型代替引用数据类型。 静态方法调用效率高于动态方法，也可以避免创建额外对象。 对于基本数据类型和String类型的常量要使用static final修饰，这样常量会在dex文件的初始化器中进行初始化，使用的时候可以直接使用。 多使用系统API，例如数组拷贝System.arrayCopy()方法，要比我们用for循环效率快9倍以上，因为系统API很多都是通过底层的汇编模式执行的，效率比较高。 有没有遇到64k问题，为什么，如何解决？ 在DEX文件中，method、field、class等的个数使用short类型来做索引，即两个字节（65535），method、field、class等均有此限制。 APK在安装过程中会调用dexopt将DEX文件优化成ODEX文件，dexopt使用LinearAlloc来存储应用信息，关于LinearAlloc缓冲区大小，不同的版本经历了4M/8M/16M的限制，超出缓冲区时就会抛出INSTALL_FAILED_DEXOPT错误。 解决方案是Google的MultiDex方案，具体参见：配置方法数超过 64K 的应用。 MVC、MVP与MVVM之间的对比分析？ MVC：PC时代就有的架构方案，在Android上也是最早的方案，Activity/Fragment这些上帝角色既承担了V的角色，也承担了C的角色，小项目开发起来十分顺手，大项目就会遇到耦合过重，Activity/Fragment类过大等问题。 MVP：为了解决MVC耦合过重的问题，MVP的核心思想就是提供一个Presenter将视图逻辑I和业务逻辑相分离，达到解耦的目的。 MVVM：使用ViewModel代替Presenter，实现数据与View的双向绑定，这套框架最早使用的data-binding将数据绑定到xml里，这么做在大规模应用的时候是不行的，不过数据绑定是一个很有用的概念，后续Google又推出了ViewModel组件与LiveData组件。ViewModel组件规范了ViewModel所处的地位、生命周期、生产方式以及一个Activity下多个Fragment共享ViewModel数据的问题。LiveData组件则提供了在Java层面View订阅ViewModel数据源的实现方案。 网络编程TCP与UDP有什么区别？ TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接 TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付 TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等） 每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信 TCP首部开销20字节;UDP的首部开销小，只有8个字节 TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道 简单介绍一下TCP三次握手与四次分手过程？TCP用三次握手（three-way handshake）过程创建一个连接，使用四次分手关闭一个连接。 三次握手与四次分手的流程如下所示： 三次握手 第一次握手：建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认； 第二次握手：服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态； 第三次握手：客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。完成了三次握手，客户端和服务器端就可以开始传送数据。以上就是TCP三次握手的总体介绍。 四次分手 第一次分手：主机1（可以使客户端，也可以是服务器端），设置Sequence Number和Acknowledgment Number，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态；这表示主机1没有数据要发送给主机2了； 第二次分手：主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我“同意”你的关闭请求； 第三次分手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态； 第四次分手：主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。 三次握手与四次分手也是个老生常谈的概念，举个简单的例子说明一下。 三次握手 例如你小时候出去玩，经常玩忘了回家吃饭。你妈妈也经常过来喊你。如果你没有走远，在门口的小土堆上玩泥巴，你妈妈会喊：”小新，回家吃饭了”。你听到后会回应：”知道了，一会就回去”。妈妈听到你的回应后又说：”快点回来，饭要凉了”。这样你妈妈和你就完成了三次握手的过程。😁说到这里你也可以理解三次握手的必要性，少了其中一个环节，另一方就会陷入等待之中。 三次握手的目的是为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误. 四次分手 例如偶像言情剧干净利落的分手，女主对男主说：我们分手吧🙄，男主说：分就分吧😰。女主说：你果然是不爱我了，你只知道让我多喝热水🙄。男主说：事到如今也没什么好说的了，祝你幸福🙃。四次分手完成。说到这里你可以理解了四次分手的必要性，第一次是女方（客户端）提出分手，第二次是男主（服务端）同意女主分手，第三次是女主确定男主不再爱她，也同意男主分手。第四次两人彻底拜拜（断开连接）。 因为TCP是全双工模式，所以四次分手的目的就是为了可靠地关闭连接。 TCP如何保证数据传输的可靠性？ 确认和重传：接收方收到报文后就会进行确认，发送方一段时间没有收到确认就会重传。 数据校验。 数据合理分片与排序，TCP会对数据进行分片，接收方会缓存为按序到达的数据，重新排序后再提交给应用层。 流程控制：当接收方来不及接收发送的数据时，则会提示发送方降低发送的速度，防止包丢失。发送者的发送速度与接收者的接收能力相关。接收者会把它能接收的最大字节数（未使用的缓冲区大小，又叫接收窗口，receive window）告知发送者。发送者发送的最大字节数与接收者的接收窗口大小一致。 拥塞控制：当网络发生拥塞时，减少数据的发送。阻塞窗口是不同于接收窗口的另一个概念，它通过限制网络中的数据流的体积来防止网络阻塞。类似于接收窗口，发送者通过通过一些算法（例如TCP Vegas，Westwood，BIC，CUBIC）来计算发送对应的接收者的阻塞窗口能容纳的最多的数据。和流量控制不同，阻塞控制只在发送方实现。（译注：发送者类似于通过ack时间之类的算法判断当前网络是否阻塞，从而调节发送速度）HTTP与HTTPS有什么区别？ HTTPS是一种通过计算机网络进行安全通信的传输协议。HTTPS经由HTTP进行通信，但利用SSL/TLS来加密数据包。HTTPS开发的主要目的，是提供对网站服务器的身份认证，保护交换数据的隐私与完整性。 如下图所示，可以很明显的看出两个的区别： 注：TLS是SSL的升级替代版，具体发展历史可以参考传输层安全性协议。 HTTP与HTTPS在写法上的区别也是前缀的不同，客户端处理的方式也不同，具体说来： 如果URL的协议是HTTP，则客户端会打开一条到服务端端口80（默认）的连接，并向其发送老的HTTP请求。 如果URL的协议是HTTPS，则客户端会打开一条到服务端端口443（默认）的连接，然后与服务器握手，以二进制格式与服务器交换一些SSL的安全参数，附上加密的HTTP请求。 所以你可以看到，HTTPS比HTTP多了一层与SSL的连接，这也就是客户端与服务端SSL握手的过程，整个过程主要完成以下工作： 交换协议版本号 选择一个两端都了解的密码 对两端的身份进行认证 生成临时的会话密钥，以便加密信道。 SSL握手是一个相对比较复杂的过程，更多关于SSL握手的过程细节可以参考TLS/SSL握手过程 SSL/TSL的常见开源实现是OpenSSL，OpenSSL是一个开放源代码的软件库包，应用程序可以使用这个包来进行安全通信，避免窃听，同时确认另一端连接者的身份。这个包广泛被应用在互联网的网页服务器上。更多源于OpenSSL的技术细节可以参考OpenSSL。 caflow： https flow 认证服务器。浏览器内置一个受信任的CA机构列表，并保存了这些CA机构的证书。第一阶段服务器会提供经CA机构认证颁发的服务器证书，如果认证该服务器证书的CA机构，存在于浏览器的受信任CA机构列表中，并且服务器证书中的信息与当前正在访问的网站（域名等）一致，那么浏览器就认为服务端是可信的，并从服务器证书中取得服务器公钥，用于后续流程。否则，浏览器将提示用户，根据用户的选择，决定是否继续。当然，我们可以管理这个受信任CA机构列表，添加我们想要信任的CA机构，或者移除我们不信任的CA机构。 协商会话密钥。客户端在认证完服务器，获得服务器的公钥之后，利用该公钥与服务器进行加密通信，协商出两个会话密钥，分别是用于加密客户端往服务端发送数据的客户端会话密钥，用于加密服务端往客户端发送数据的服务端会话密钥。在已有服务器公钥，可以加密通讯的前提下，还要协商两个对称密钥的原因，是因为非对称加密相对复杂度更高，在数据传输过程中，使用对称加密，可以节省计算资源。另外，会话密钥是随机生成，每次协商都会有不一样的结果，所以安全性也比较高。 加密通讯。此时客户端服务器双方都有了本次通讯的会话密钥，之后传输的所有Http数据，都通过会话密钥加密。这样网路上的其它用户，将很难窃取和篡改客户端和服务端之间传输的数据，从而保证了数据的私密性和完整性。 谈一谈对HTTP缓存的理解？HTTP的缓存机制也是依赖于请求和响应header里的参数类实现的，最终响应式从缓存中去，还是从服务端重新拉取，HTTP的缓存机制的流程如下所示： HTTP的缓存可以分为两种： 强制缓存：需要服务端参与判断是否继续使用缓存，当客户端第一次请求数据是，服务端返回了缓存的过期时间（Expires与Cache-Control），没有过期就可以继续使用缓存，否则则不适用，无需再向服务端询问。 对比缓存：需要服务端参与判断是否继续使用缓存，当客户端第一次请求数据时，服务端会将缓存标识（Last-Modified/If-Modified-Since与Etag/If-None-Match）与数据一起返回给客户端，客户端将两者都备份到缓存中 ，再次请求数据时，客户端将上次备份的缓存标识发送给服务端，服务端根据缓存标识进行判断，如果返回304，则表示通知客户端可以继续使用缓存。 强制缓存优先于对比缓存。 上面提到强制缓存使用的的两个标识： Expires：Expires的值为服务端返回的到期时间，即下一次请求时，请求时间小于服务端返回的到期时间，直接使用缓存数据。到期时间是服务端生成的，客户端和服务端的时间可能有误差。 Cache-Control：Expires有个时间校验的问题，所有HTTP1.1采用Cache-Control替代Expires。 Cache-Control的取值有以下几种： private: 客户端可以缓存。 public: 客户端和代理服务器都可缓存。 max-age=xxx: 缓存的内容将在 xxx 秒后失效 no-cache: 需要使用对比缓存来验证缓存数据。 no-store: 所有内容都不会缓存，强制缓存，对比缓存都不会触发。 我们再来看看对比缓存的两个标识： Last-Modified/If-Modified-Since Last-Modified 表示资源上次修改的时间。 当客户端发送第一次请求时，服务端返回资源上次修改的时间： 1Last-Modified: Tue, 12 Jan 2016 09:31:27 GMT 客户端再次发送，会在header里携带If-Modified-Since。将上次服务端返回的资源时间上传给服务端。 1If-Modified-Since: Tue, 12 Jan 2016 09:31:27 GMT 服务端接收到客户端发来的资源修改时间，与自己当前的资源修改时间进行对比，如果自己的资源修改时间大于客户端发来的资源修改时间，则说明资源做过修改，则返回200表示需要重新请求资源，否则返回304表示资源没有被修改，可以继续使用缓存。 上面是一种时间戳标记资源是否修改的方法，还有一种资源标识码ETag的方式来标记是否修改，如果标识码发生改变，则说明资源已经被修改，ETag优先级高于Last-Modified。 Etag/If-None-Match ETag是资源文件的一种标识码，当客户端发送第一次请求时，服务端会返回当前资源的标识码： 1ETag: \"5694c7ef-24dc\" 客户端再次发送，会在header里携带上次服务端返回的资源标识码： 1If-None-Match:\"5694c7ef-24dc\" 服务端接收到客户端发来的资源标识码，则会与自己当前的资源吗进行比较，如果不同，则说明资源已经被修改，则返回200，如果相同则说明资源没有被修改，返回304，客户端可以继续使用缓存。 HTTPS是如何保证安全的，证书如何校验？ HTTP如何实现长连接？1Connection:keep-alive http1.1 之后 默认都是打开长连接的 tcp可靠连接的精髓：TCP连接的一方A，由操作系统动态随机选取一个32位长的序列号（Initial+Sequence+Number），假设A的初始序列号为1000，以该序列号为原点，对自己将要发送的每个字节的数据进行编号，1001，1002，1003…，并把自己的初始序列号ISN告诉B，让B有一个思想准备，什么样编号的数据是合法的，什么编号是非法的，比如编号900就是非法的，同时B还可以对A每一个编号的字节数据进行确认。如果A收到B确认编号为2001，则意味着字节编号为1001-2000，共1000个字节已经安全到达。+同理B也是类似的操作，假设B的初始序列号ISN为2000，以该序列号为原点，对自己将要发送的每个字节的数据进行编号，2001，2002，2003…，并把自己的初始序列号ISN告诉A，以便A可以确认B发送的每一个字节。如果B收到A确认编号为4001，则意味着字节编号为2001-4000，共2000个字节已经安全到达。 一句话概括，TCP连接握手，握的是啥？通信双方数据原点的序列号！以此核心思想我们来分析二、三、四次握手的过程。 AB四次握手的过程：12341. A 发送同步信号SYN A’s Initial sequence number 2. B 确认收到A的同步信号，并记录 A‘s ISN 到本地，命名 B’s ACK sequence number3. B发送同步信号SYN B‘s Initial sequence number 4. A确认收到B的同步信号，并记录 B’s ISN 到本地，命名 A‘s ACK sequence number 很显然1.2和1.3 这两个步骤可以合并，只需要三次握手，可以提高连接的速度与效率。 二次握手的过程：121. A 发送同步信号SYN A’s Initial sequence number2. B发送同步信号SYN B‘s Initial sequence number B’s ACK sequence number 这里有一个问题，A与B就A的初始序列号达成了一致，这里是1000。但是B无法知道A是否已经接收到自己的同步信号，如果这个同步信号丢失了，A和B就B的初始序列号将无法达成一致。于是TCP的设计者将SYN这个同步标志位SYN设计成占用一个字节的编号（FIN标志位也是），既然是一个字节的数据，按照TCP对有数据的TCP+segment+必须确认的原则，所以在这里A必须给B一个确认，以确认A已经接收到B的同步信号。 有童鞋会说，如果A发给B的确认丢了，该如何？ A会超时重传这个ACK吗？不会！TCP不会为没有数据的ACK超时重传。那该如何是好？B如果没有收到A的ACK，会超时重传自己的SYN同步信号，一直到收到A的ACK为止。 补充阅读：第一个包， 即A发给B的SYN 中途被丢，没有到达B A会周期性超时重传，直到收到B的确认 第二个包，即B发给A的SYN BACK 中途被丢，没有到达A B会周期性超时重传，直到收到A的确认 第三个包，即A发给B的ACK 中途被丢，没有到达B A发完ACK，单方面认为TCP为 Established状态，而B显然认为TCP为Active状态： 12345a. 假定此时双方都没有数据发送，B会周期性超时重传，直到收到A的确认，收到之后B的TCP 连接也为 Established状态，双向可以发包。b. 假定此时A有数据发送，B收到A的 Data+ACK，自然会切换为established 状态，并接受A的 Data。C. 假定b有数据发送，数据发送不了，会一直周期性超时重传SYN +ACK，直到收到A的确认才可以发送数据。 应用层的数据不是直接发送给网卡的， linux系统有一个socket缓冲区，是一块物理内存，kernel将该物理地址的fd文件句柄透给用户空间，用户通过write（fd，stream）将二进制数字节流写入到socket缓冲区中，此时该数据片会被插入socket缓冲区的末尾，以保证数据的发送数据是先入先出的。 socket缓冲区会关联一个叫做TCB的结构体，该结构体中存放了TCP链接所需要的全部数据，包括接受窗口，阻塞窗口，发送序号，重发计数器等。 在tcp层，如果满足发射条件，就会创建tcp 分段，（tcp segment）发送出去，但也有可能因为流量控制策略，系统决定不发包，调用就此停止。 进入IP层，在TCP分段中加入了IP信息，并进行IP路由，IP路由的目的是查找为了到达目的IP的要跳转的下一级IP地址。 IP层增加了IP地址信息并进行IP路由之后，将数据发送到数据链路层，此时进行ARP获取目的地的mac地址信息。然后在数据端增加链路头信息。至此 tcp段的数据便是完整的了。 在接收到数据包传输请求之后，NIC把数据包从系统内存中拷贝到它自己的内存中，之后把数据包发送到网络上。在此时，由于要遵守以太网标准（Ethernet standard），NIC会向数据包中增加帧间隙（Inter-Frame Gap，IFG），同步码（preamble）和crc校验 所谓的长连接和短连接 对于HTTP 1.0的http标准而言，默认连接是短连接，啥叫短连接？就是服务器当发送完最后一个字节的数据之后将关闭连接，也就是回收tcp_sock结构，这样，如果客户端再发送数据给服务器，将直接丢弃。即使此时客户端还有这样的结构，但是我们说连接已经关闭或者已经断了。那客户端知不知道啥时候服务器的连接关闭？不知道，双方可以在任何时候来关闭自己的连接而没有必要通知对方。不过，对于短连接而言，通知不通知也没有意义了。 那短连接的弊端，大家可能都已经知道了，如果对一个服务器要连续发送多个请求，还需要为每次请求建立新的连接。 为了降低建立连接的时间，HTTP 1.1引入了长连接的概念，并把它搞成了默认的连接方式。啥叫长连接？就是当完成一个业务之后，socket结构并不回收。这样，只要在socket结构还存在的时候，客户端发送的任何数据，服务器都可以收到，这就是所谓的长连接。 相比短连接而言，长连接并没有什么特别的新的技术，只是维护socket结构时间长了。因为，说http长连接更不如说是tcp长连接。 网卡会自动从该缓冲区取数据，在tcp层，首先通过write函数， websocket2、数据帧格式详解针对前面的格式概览图，这里逐个字段进行讲解，如有不清楚之处，可参考协议规范，或留言交流。 FIN：1个比特。 如果是1，表示这是消息（message）的最后一个分片（fragment），如果是0，表示不是是消息（message）的最后一个分片（fragment）。 RSV1, RSV2, RSV3：各占1个比特。 一般情况下全为0。当客户端、服务端协商采用WebSocket扩展时，这三个标志位可以非0，且值的含义由扩展进行定义。如果出现非零的值，且并没有采用WebSocket扩展，连接出错。 Opcode: 4个比特。 操作代码，Opcode的值决定了应该如何解析后续的数据载荷（data payload）。如果操作代码是不认识的，那么接收端应该断开连接（fail the connection）。可选的操作代码如下： 123456789%x0：表示一个延续帧。当Opcode为0时，表示本次数据传输采用了数据分片，当前收到的数据帧为其中一个数据分片。%x1：表示这是一个文本帧（frame）%x2：表示这是一个二进制帧（frame）%x3-7：保留的操作代码，用于后续定义的非控制帧。%x8：表示连接断开。%x9：表示这是一个ping操作。%xA：表示这是一个pong操作。%xB-F：保留的操作代码，用于后续定义的控制帧。Mask: 1个比特。 表示是否要对数据载荷进行掩码操作。从客户端向服务端发送数据时，需要对数据进行掩码操作；从服务端向客户端发送数据时，不需要对数据进行掩码操作。 如果服务端接收到的数据没有进行过掩码操作，服务端需要断开连接。 如果Mask是1，那么在Masking-key中会定义一个掩码键（masking key），并用这个掩码键来对数据载荷进行反掩码。所有客户端发送到服务端的数据帧，Mask都是1。 掩码的算法、用途在下一小节讲解。 Payload length：数据载荷的长度，单位是字节。为7位，或7+16位，或1+64位。 假设数Payload length === x，如果 x为0~126：数据的长度为x字节。x为126：后续2个字节代表一个16位的无符号整数，该无符号整数的值为数据的长度。x为127：后续8个字节代表一个64位的无符号整数（最高位为0），该无符号整数的值为数据的长度。此外，如果payload length占用了多个字节的话，payload length的二进制表达采用网络序（big endian，重要的位在前）。 Masking-key：0或4字节（32位） 所有从客户端传送到服务端的数据帧，数据载荷都进行了掩码操作，Mask为1，且携带了4字节的Masking-key。如果Mask为0，则没有Masking-key。 备注：载荷数据的长度，不包括mask key的长度。 Payload data：(x+y) 字节 载荷数据：包括了扩展数据、应用数据。其中，扩展数据x字节，应用数据y字节。 扩展数据：如果没有协商使用扩展的话，扩展数据数据为0字节。所有的扩展都必须声明扩展数据的长度，或者可以如何计算出扩展数据的长度。此外，扩展如何使用必须在握手阶段就协商好。如果扩展数据存在，那么载荷数据长度必须将扩展数据的长度包含在内。 应用数据：任意的应用数据，在扩展数据之后（如果存在扩展数据），占据了数据帧剩余的位置。载荷数据长度 减去 扩展数据长度，就得到应用数据的长度。 3、掩码算法掩码键（Masking-key）是由客户端挑选出来的32位的随机数。掩码操作不会影响数据载荷的长度。掩码、反掩码操作都采用如下算法： 首先，假设： original-octet-i：为原始数据的第i字节。transformed-octet-i：为转换后的数据的第i字节。j：为i mod 4的结果。masking-key-octet-j：为mask key第j字节。算法描述为： original-octet-i 与 masking-key-octet-j 异或后，得到 transformed-octet-i。 j = i MOD 4transformed-octet-i = original-octet-i XOR masking-key-octet-j 六、数据传递一旦WebSocket客户端、服务端建立连接后，后续的操作都是基于数据帧的传递。 WebSocket根据opcode来区分操作的类型。比如0x8表示断开连接，0x0-0x2表示数据交互。 1、数据分片WebSocket的每条消息可能被切分成多个数据帧。当WebSocket的接收方收到一个数据帧时，会根据FIN的值来判断，是否已经收到消息的最后一个数据帧。 FIN=1表示当前数据帧为消息的最后一个数据帧，此时接收方已经收到完整的消息，可以对消息进行处理。FIN=0，则接收方还需要继续监听接收其余的数据帧。 此外，opcode在数据交换的场景下，表示的是数据的类型。0x01表示文本，0x02表示二进制。而0x00比较特殊，表示延续帧（continuation frame），顾名思义，就是完整消息对应的数据帧还没接收完。 2、数据分片例子直接看例子更形象些。下面例子来自MDN，可以很好地演示数据的分片。客户端向服务端两次发送消息，服务端收到消息后回应客户端，这里主要看客户端往服务端发送的消息。 第一条消息 FIN=1, 表示是当前消息的最后一个数据帧。服务端收到当前数据帧后，可以处理消息。opcode=0x1，表示客户端发送的是文本类型。 第二条消息 FIN=0，opcode=0x1，表示发送的是文本类型，且消息还没发送完成，还有后续的数据帧。FIN=0，opcode=0x0，表示消息还没发送完成，还有后续的数据帧，当前的数据帧需要接在上一条数据帧之后。FIN=1，opcode=0x0，表示消息已经发送完成，没有后续的数据帧，当前的数据帧需要接在上一条数据帧之后。服务端可以将关联的数据帧组装成完整的消息。Client: FIN=1, opcode=0x1, msg=”hello”Server: (process complete message immediately) Hi.Client: FIN=0, opcode=0x1, msg=”and a”Server: (listening, new message containing text started)Client: FIN=0, opcode=0x0, msg=”happy new”Server: (listening, payload concatenated to previous message)Client: FIN=1, opcode=0x0, msg=”year!”Server: (process complete message) Happy new year to you too! 七、连接保持+心跳WebSocket为了保持客户端、服务端的实时双向通信，需要确保客户端、服务端之间的TCP通道保持连接没有断开。然而，对于长时间没有数据往来的连接，如果依旧长时间保持着，可能会浪费包括的连接资源。 但不排除有些场景，客户端、服务端虽然长时间没有数据往来，但仍需要保持连接。这个时候，可以采用心跳来实现。 发送方-&gt;接收方：ping接收方-&gt;发送方：pongping、pong的操作，对应的是WebSocket的两个控制帧，opcode分别是0x9、0xA。 举例，WebSocket服务端向客户端发送ping，只需要如下代码（采用ws模块） ws.ping(‘’, false, true);","categories":[{"name":"Android","slug":"Android","permalink":"http://wenyiqingnian.xyz/categories/Android/"}],"tags":[{"name":"android","slug":"android","permalink":"http://wenyiqingnian.xyz/tags/android/"}]},{"title":"从一次native端的IPC流程理解binder","slug":"从一次native端的IPC流程理解binder","date":"2018-06-24T11:00:50.000Z","updated":"2018-06-25T15:12:13.000Z","comments":true,"path":"2018/06/24/从一次native端的IPC流程理解binder/","link":"","permalink":"http://wenyiqingnian.xyz/2018/06/24/从一次native端的IPC流程理解binder/","excerpt":"","text":"概述本文是看完邓凡平的《深入理解android卷1》第六章的binder篇后，在此基础上的一些个人理解。上文从驱动角度解释了binder通讯机制的底层运行原理，我们知道android系统中，binder是采用CS架构来设计的，除了binderDriver之外，还需要client server 以及serviceManager 三个角色，才能完整实现一套CS架构的跨进程通讯机制。 从上图可以看到，一次完整的IPC 至少需要这么几个步骤 Server 通过serviceManager 注册服务 Client 通过ServiceManager 查询服务 Client 获取到Server端的服务后，通过binder驱动，完成跨进程对Server端的引用。下面以native层的一次IPC请求流程为例，通过client对MediaServer的调用，了解一下client、server、serviceManager三者之间的通讯过程。 server端：MediaServerMediaServer 是系统主要server之一，它提供了 AudioFlinger AudioPolicyService MediaplayerService CamerService四个重量级服务，查看MediaServer的源码： 1234567891011121314151617181920212223int main(int argc, char** argv)&#123; //①获得一个ProcessState实例 sp&lt;ProcessState&gt;proc(ProcessState::self()); //②MS作为ServiceManager的客户端，需要向ServiceManger注册服务 //调用defaultServiceManager，得到一个IServiceManager。 sp&lt;IServiceManager&gt;sm = defaultServiceManager(); //初始化音频系统的AudioFlinger服务 AudioFlinger::instantiate(); //③多媒体系统的MediaPlayer服务，我们将以它作为主切入点 MediaPlayerService::instantiate(); //CameraService服务 CameraService::instantiate(); //音频系统的AudioPolicy服务 AudioPolicyService::instantiate(); //④新建一个用以处理binder请求的线程 ProcessState::self()-&gt;startThreadPool(); //⑤将主线程也用来处理binder请求 IPCThreadState::self()-&gt;joinThreadPool();&#125; 以代码中标注的1，2，3，4，5为次序，依次讲解每个部分的具体内容。 一、创建ProcessState还是先看代码 12//①获得一个ProcessState实例sp&lt;ProcessState&gt;proc(ProcessState::self()); 创建ProcessState实例 1234567891011sp&lt;ProcessState&gt; ProcessState::self()&#123; //gProcess是在Static.cpp中定义的一个全局变量 //程序刚开始执行，gProcess一定为空 if(gProcess != NULL) return gProcess; AutoMutex_l(gProcessMutex); //创建一个ProcessState对象，并赋值给gProcess if(gProcess == NULL) gProcess = new ProcessState; return gProcess;&#125; 1 processState 的构造函数12345678910111213141516171819202122232425262728293031ProcessState::ProcessState() /* 【笔记一：】 注意 在构造ProcessState时，通过open_driver()函数 打开了binder驱动，并将binder驱动的 fd赋值给了ProcessState的mDriverFD 成员变量。后面我们可以看到一个与ProcessState对应的 IPCThreadState对象（它是线程单例），它的构造函数会以ProcessState做参数，ProcessState持 有Binder驱动的句柄，所以IPCThreadState可以操作Binder驱动，事实上，IPCThread也就是循环 读写binder驱动，从中拿消息并处理消息的。 */ :mDriverFD(open_driver()) ,mVMStart(MAP_FAILED)//映射内存的起始地址 ,mManagesContexts(false) ,mBinderContextCheckFunc(NULL) , mBinderContextUserData(NULL) ,mThreadPoolStarted(false) ,mThreadPoolSeq(1)&#123; if(mDriverFD &gt;= 0) &#123;/* BIDNER_VM_SIZE定义为(1*1024*1024) - (4096 *2) = 1M-8K 【笔记二：】 上文驱动篇讲过，用户空间调用驱动的mmap，实际对应驱动层的binder_mmap()方法， 在该方法里，binder驱动会申请一块用来存储通信数据的内存区域，其实就是binder驱动中一个叫做 binder_buff的结构体。同时会在server进程的用户空间和内核空间做一次虚拟地址映射。这是为什么 binder通讯只进行一次拷贝的原因，上文已讲过这里不再详述。*/ mVMStart = mmap(0, BINDER_VM_SIZE, PROT_READ,MAP_PRIVATE | MAP_NORESERVE, mDriverFD, 0); &#125; ......&#125; processState 是个单例对象，因为它是在程序运行时只初始化一次，所以每个进程只有一个ProcessState对象。在创建ProcessState时，做了这么几件事情 打开binder驱动 映射内存起始地址 为binder驱动分配内存用以接受请求数据2 打开binder驱动（open_driver()）ProcessState.cpp 123456789101112static int open_driver()&#123; int fd =open(\"/dev/binder\", O_RDWR);//打开/dev/binder设备 if (fd&gt;= 0) &#123; ...... size_t maxThreads = 15; //通过ioctl方式告诉binder驱动，这个fd支持的最大线程数是15个 result = ioctl(fd, BINDER_SET_MAX_THREADS, &amp;maxThreads); &#125;return fd;......&#125; 【笔记三：】上文已经说过，open(&#39;dev/binder&#39;,O_RDWR) 其实对应了内核中binder驱动的binder_open（）方法，binder_open()的代码如下： 1234567891011121314151617181920212223242526272829static int binder_open(struct inode *nodp, struct file *filp)&#123; struct binder_proc *proc; // 创建进程对应的binder_proc对象 proc = kzalloc(sizeof(*proc), GFP_KERNEL); if (proc == NULL) return -ENOMEM; get_task_struct(current); proc-&gt;tsk = current; // 初始化binder_proc INIT_LIST_HEAD(&amp;proc-&gt;todo); init_waitqueue_head(&amp;proc-&gt;wait); proc-&gt;default_priority = task_nice(current); // 锁保护 binder_lock(__func__); binder_stats_created(BINDER_STAT_PROC); // 添加到全局列表binder_procs中 hlist_add_head(&amp;proc-&gt;proc_node, &amp;binder_procs); proc-&gt;pid = current-&gt;group_leader-&gt;pid; INIT_LIST_HEAD(&amp;proc-&gt;delivered_death); filp-&gt;private_data = proc; binder_unlock(__func__); return 0;&#125; 可以看到，在打开binder驱动时，binder_procs会将所有打开binder驱动的进程加入到该列表中。同时，通过ioctrl 的方式 告诉了binder 驱动 当前server端线程池支持的最大线程数是15. 所以创建processState的过程 其实做了这么几件事： 打开binder驱动 同时驱动为该进程创建对应的binder_proc 节点 对返回的fd 使用mmap方法，操作binder驱动，binder驱动申请了一块内存来接受通讯数据 因为ProcessState是进程单例的，每个进程只会开启binder驱动一次。 二、 获取servicManagerdefaultServiceManager()方法在IServiceManager.cpp中定义，返回IServiceManager对象，先看一下这个方法的具体实现IServiceManager.cpp 1234567891011121314 sp&lt;IServiceManager&gt; defaultServiceManager() &#123; // 单例实现 if(gDefaultServiceManager != NULL) return gDefaultServiceManager; &#123; AutoMutex _l(gDefaultServiceManagerLock); if(gDefaultServiceManager == NULL) &#123; //真正的gDefaultServiceManager是在这里创建的。 gDefaultServiceManager = interface_cast&lt;IServiceManager&gt;( ProcessState::self()-&gt;getContextObject(NULL)); &#125; &#125; returngDefaultServiceManager;&#125; 可以看到 真正的IServiceManager 是由方法 interface_cast&lt;IServiceManager&gt;（） 传入一个 ProcessState::self()-&gt;getContextObject(NULL)对象实现的。先看一下ProcessState::self()的getContextObject()函数ProcessState.cpp 123456789101112131415sp&lt;IBinder&gt;ProcessState::getContextObject(const sp&lt;IBinder&gt;&amp; caller)&#123; /* caller的值为0！注意，该函数返回的是IBinder。它是什么？我们后面再说。 supportsProcesses函数根据openDriver函数打开设备是否成功来判断是否支持process 真实设备肯定支持process。 */ if(supportsProcesses()) &#123; //真实设备上肯定是支持进程的，所以会调用下面这个函数 //【笔记三：传的参数是null 所以handle号是0】 return getStrongProxyForHandle(0); &#125; else &#123; return getContextObject(String16(\"default\"), caller); &#125;&#125; 继续看getStrongProxyForHandle() ProcessState.cpp 12345678910111213141516171819202122232425sp&lt;IBinder&gt;ProcessState::getStrongProxyForHandle(int32_t handle)&#123; sp&lt;IBinder&gt; result; AutoMutex_l(mLock); /* 根据索引查找对应资源。如果lookupHandleLocked发现没有对应的资源项，则会创建一个新的项并返 回。 这个新项的内容需要填充。 */ handle_entry* e = lookupHandleLocked(handle); if (e !=NULL) &#123; IBinder* b = e-&gt;binder; if (b== NULL || !e-&gt;refs-&gt;attemptIncWeak(this)) &#123; //对于新创建的资源项，它的binder为空，所以走这个分支。注意，handle的值为0 b= new BpBinder(handle); //创建一个BpBinder e-&gt;binder = b; //填充entry的内容 if (b) e-&gt;refs = b-&gt;getWeakRefs(); result = b; &#125;else &#123; result.force_set(b); e-&gt;refs-&gt;decWeak(this); &#125; &#125; returnresult; //返回BpBinder(handle)，注意，handle的值为0&#125; 可以看到 实际返回的对象是一个BpBinder，BpBinder里持有一个handle成员变量。实际上 BpBinder BBinder 都是继承自IBinder的。 从名字也可以看出来，BpBinder ,BProxy（proxy:代理），肯定是与客户端打交道的。如果说Proxy代表客户端，那么BBinder则代表服务端。这里的BpBinder和BBinder是一一对应的，即某个BpBinder只能和对应的BBinder交互。我们当然不希望通过BpBinderA发送的请求，却由BBinderB来处理。刚才我们在defaultServiceManager()函数中创建了这个BpBinder。前面说了，BpBinder和BBinder是一一对应的，那么BpBinder如何标识它所对应的BBinder端呢？答案是Binder系统通过handler来对应BBinder。以后我们会确认这个Handle值的作用。 注：我们给BpBinder构造函数传的参数handle的值是0。这个0在整个Binder系统中有重要含义—因为0代表的就是ServiceManager所对应的BBinder。 详细看一下BpBinder的实现 1. BpBinder.cpp12345678910BpBinder::BpBinder(int32_t handle) :mHandle(handle)//handle是0 ,mAlive(1) ,mObitsSent(0) ,mObituaries(NULL)&#123; extendObjectLifetime(OBJECT_LIFETIME_WEAK); //另一个重要对象是IPCThreadState，我们稍后会详细讲解。 IPCThreadState::self()-&gt;incWeakHandle(handle);&#125; 看上面的代码，会觉得BpBinder确实简单，不过再仔细查看，你或许会发现，BpBinder、BBinder这两个类没有任何地方操作ProcessState打开的那个/dev/binder设备，换言之，这两个Binder类没有和binder设备直接交互。那为什么说BpBinder会与通信相关呢? 我们接着看interface_cast（）函数 我们是从下面这个函数开始分析的： 1gDefaultServiceManager =interface_cast&lt;IServiceManager&gt;( ProcessState::self()-&gt;getContextObject(NULL)); 现在这个函数调用将变成如下所示： 1gDefaultServiceManager =interface_cast&lt;IServiceManager&gt;(new BpBinder(0)); 这里出现了一个interface_cast。它是什么？其实是一个障眼法！下面就来具体分析它。 2. 障眼法——interface_cast看看interface_cast的具体实现，其代码如下所示： 12345678910111213IInterface.htemplate&lt;typename INTERFACE&gt;inline sp&lt;INTERFACE&gt; interface_cast(constsp&lt;IBinder&gt;&amp; obj)&#123; returnINTERFACE::asInterface(obj);&#125;哦，仅仅是一个模板函数，所以interface_cast()等价于：inline sp&lt;IServiceManager&gt;interface_cast(const sp&lt;IBinder&gt;&amp; obj)&#123; return IServiceManager::asInterface(obj);&#125; 又转移到IServiceManager对象中去了，还原完模板函数，可以看到interface_cast（）实际调用的是IServiceManager中的asInterface() 方法，该方法传入了上文所说的BpBinder对象。看一下IServiceManager（）中做了什么操作 3. IServiceManager刚才提到，IBinder家族的BpBinder和BBinder是与通信业务相关的，那么业务层的逻辑又是如何巧妙地架构在Binder机制上的呢？关于这些问题，可以用一个绝好的例子来解释，它就是IServiceManager。 【笔记四：】 IServiceManager对象其实可以当做java中的接口函数来理解。它定义在IServiceManager.h 中，描述了ServiceManager可以提供的服务。 （1）定义业务逻辑先回答第一个问题：如何表述应用的业务层逻辑。可以先分析一下IServiceManager是怎么做的。IServiceManager定义了ServiceManager所提供的服务，看它的定义可知，其中有很多有趣的内容。IServiceManager定义在IServiceManager.h中，代码如下所示：IServiceManager.h 1234567891011121314class IServiceManager : public IInterface&#123; public: //关键无比的宏！ DECLARE_META_INTERFACE(ServiceManager); //下面是ServiceManager所提供的业务函数 virtualsp&lt;IBinder&gt; getService( constString16&amp; name) const = 0; virtualsp&lt;IBinder&gt; checkService( constString16&amp; name) const = 0; virtualstatus_t addService( const String16&amp; name, const sp&lt;IBinder&gt;&amp;service) = 0; virtual Vector&lt;String16&gt; listServices() = 0; ......&#125;; （2）业务与通信的挂钩Android巧妙地通过DECLARE_META_INTERFACE和IMPLENT_META_INTERFACE宏，将业务和通信牢牢地钩在了一起。DECLARE_META_INTERFACE和IMPLEMENT_META_INTERFACE这两个宏都定义在刚才的IInterface.h中。先看DECLARE_META_INTERFACE这个宏，如下所示：IInterface.h::DECLARE_META_INTERFACE 1234567#define DECLARE_META_INTERFACE(INTERFACE) \\ staticconst android::String16 descriptor; \\ staticandroid::sp&lt;I##INTERFACE&gt; asInterface( \\ const android::sp&lt;android::IBinder&gt;&amp; obj); \\ virtualconst android::String16&amp; getInterfaceDescriptor() const; \\ I##INTERFACE(); \\ virtual~I##INTERFACE(); 将IServiceManager的DELCARE宏进行相应的替换后得到的代码如下所示：DECLARE_META_INTERFACE(IServiceManager) 12345678910111213//定义一个描述字符串static const android::String16 descriptor; //定义一个asInterface函数static android::sp&lt; IServiceManager &gt;asInterface(constandroid::sp&lt;android::IBinder&gt;&amp; obj) //定义一个getInterfaceDescriptor函数，估计就是返回descriptor字符串virtual const android::String16&amp;getInterfaceDescriptor() const; //定义IServiceManager的构造函数和析构函数IServiceManager (); virtual ~IServiceManager(); DECLARE宏声明了一些函数和一个变量，那么，IMPLEMENT宏的作用肯定就是定义它们了。IMPLEMENT的定义在IInterface.h中，IServiceManager是如何使用了这个宏呢？只有一行代码，在IServiceManager.cpp中，如下所示： 1234567891011121314151617181920212223242526272829IMPLEMENT_META_INTERFACE(ServiceManager,\"android.os.IServiceManager\");很简单，可直接将IServiceManager中的IMPLEMENT宏的定义展开，如下所示：const android::String16IServiceManager::descriptor(“android.os.IServiceManager”);//实现getInterfaceDescriptor函数const android::String16&amp; IServiceManager::getInterfaceDescriptor()const &#123; //返回字符串descriptor，值是“android.os.IServiceManager” return IServiceManager::descriptor; &#125; //实现asInterface函数 android::sp&lt;IServiceManager&gt; IServiceManager::asInterface(constandroid::sp&lt;android::IBinder&gt;&amp; obj)&#123; android::sp&lt;IServiceManager&gt; intr; if(obj != NULL) &#123; intr = static_cast&lt;IServiceManager *&gt;( obj-&gt;queryLocalInterface(IServiceManager::descriptor).get()); if (intr == NULL) &#123; //obj是我们刚才创建的那个BpBinder(0) intr = new BpServiceManager(obj); &#125; &#125; return intr;&#125;//实现构造函数和析构函数IServiceManager::IServiceManager () &#123; &#125;IServiceManager::~ IServiceManager() &#123; &#125; 我们曾提出过疑问：interface_cast是如何把BpBinder指针转换成一个IServiceManager指针的呢？答案就在asInterface函数的一行代码中，如下所示： intr = new BpServiceManager(obj);明白了！interface_cast不是指针的转换，而是利用BpBinder对象作为参数新建了一个BpServiceManager对象。我们已经知道BpBinder和BBinder与通信有关系，这里怎么突然冒出来一个BpServiceManager？它们之间又有什么关系呢？ 4 IServiceManager家族要搞清这个问题，必须先了解IServiceManager家族之间的关系，先来看图6-3，它展示了IServiceManager的家族图谱。 图6-3 IServiceManager的家族图谱 根据图6-3和相关的代码可知，这里有以下几个重要的点值得注意： IServiceManager、BpServiceManager和BnServiceManager都与业务逻辑相关。BnServiceManager同时从BBinder派生，表示它可以直接参与Binder通信。BpServiceManager虽然从BpInterface中派生，但是这条分支似乎与BpBinder没有关系。BnServiceManager是一个虚类，它的业务函数最终需要子类来实现。重要说明：以上这些关系很复杂，但ServiceManager并没有使用错综复杂的派生关系，它直接打开Binder设备并与之交互。后文，还会详细分析它的实现代码。 图6-3中的BpServiceManager，既然不像它的兄弟BnServiceManager那样直接与Binder有血缘关系，那么它又是如何与Binder交互的呢？简言之，BpRefBase中的mRemote的值就是BpBinder。如果你不相信，仔细看BpServiceManager左边的派生分支树上的一系列代码，它们都在IServiceManager.cpp中，如下所示：IServiceManager.cpp::BpServiceManager类 123456//通过它的参数可得知，impl是IBinder类型，看来与Binder有间接关系,它实际上是BpBinder对象BpServiceManager(const sp&lt;IBinder&gt;&amp; impl) //调用基类BpInterface的构造函数 : BpInterface&lt;IServiceManager&gt;(impl)&#123;&#125; BpInterface的实现代码如下所示： 1234567IInterface.h::BpInterface类template&lt;typename INTERFACE&gt;inlineBpInterface&lt;INTERFACE&gt;::BpInterface(const sp&lt;IBinder&gt;&amp; remote) :BpRefBase(remote)//基类构造函数&#123;&#125; BpRefBase()的实现代码如下所示：Binder.cpp::BpRefBase类 1234567891011BpRefBase::BpRefBase(const sp&lt;IBinder&gt;&amp;o) //mRemote最终等于那个new 出来的BpBinder(0) :mRemote(o.get()), mRefs(NULL), mState(0)&#123; extendObjectLifetime(OBJECT_LIFETIME_WEAK); if(mRemote) &#123; mRemote-&gt;incStrong(this); mRefs= mRemote-&gt;createWeak(this); &#125;&#125; 原来，BpServiceManager的一个变量mRemote是指向了BpBinder。回想一下defaultServiceManager函数，可以得到以下两个关键对象： 有一个BpBinder对象，它的handle值是0。有一个BpServiceManager对象，它的mRemote值是BpBinder。 【笔记五：】在获取ServiceManager的时候，通过传入一个BpBinder（0）对象，调用到IServiceManager的asInterface()函数，这个函数创建了一个BpServiceManger对象，该对象也是定义在IServiceManager.cpp 中的，BpServiceManager对象通过构造函数持有了我们传过去的BpBinder，并实现了IServiceManager的业务函数（其实并没有真正实现，只不过BpServiceManager里有一个IServiceManager的同名方法，在同名方法里，会将客户端调用该函数的一些参数数据进行封装，打包成parcel对象，然后交给自己持有的BpBinder，BpBinder并不会直接与binder驱动进行交互，实际上所有的交互操作都是由IPCTthreadState完成的，后文会讲） 三、 注册MediaPlayerService拿到了BpServiceManager，其实就可以通过这个代理，与server 也就是ServiceManager进行通信了。 现在要想serviceManager 注册MediaPlayerService服务。我们看一下 代码③ 具体做了什么 MediaPlayerService.cpp 1234void MediaPlayerService::instantiate() &#123; defaultServiceManager()-&gt;addService( String16(\"media.player\"), new MediaPlayerService());&#125; 根据前面的分析，defaultServiceManager()实际返回的对象是BpServiceManager，它是IServiceManager的后代，代码如下所示：IServiceManager.cpp::BpServiceManager的addService()函数 1234567891011virtual status_t addService(const String16&amp;name, const sp&lt;IBinder&gt;&amp; service)&#123; //Parcel:就把它当作是一个数据包。 Parceldata, reply; data.writeInterfaceToken(IServiceManager::getInterfaceDescriptor()); data.writeString16(name); data.writeStrongBinder(service); //remote返回的是mRemote，也就是BpBinder对象 status_terr = remote()-&gt;transact(ADD_SERVICE_TRANSACTION, data, &amp;reply); returnerr == NO_ERROR ? reply.readInt32() : err;&#125; 别急着往下走，应先思考以下两个问题： 调用BpServiceManager的addService是不是一个业务层的函数？ addService函数中把请求数据打包成data后，传给了BpBinder的transact函数，这是不是把通信的工作交给了BpBinder？ 两个问题的答案都是肯定的。至此，业务层的工作原理应该是很清晰了，它的作用就是将请求信息打包后，再交给通信层去处理。通信层的工作下面分析BpBinder的transact函数。前面说过，在BpBinder中确实找不到任何与Binder设备交互的地方吗？那它是如何参与通信的呢？原来，秘密就在这个transact函数中，它的实现代码如下所示：BpBinder.cpp 12345678910111213status_t BpBinder::transact(uint32_t code, constParcel&amp; data, Parcel* reply, uint32_tflags)&#123; if(mAlive) &#123; //BpBinder果然是道具，它把transact工作交给了IPCThreadState status_t status = IPCThreadState::self()-&gt;transact( mHandle,code, data, reply, flags);//mHandle也是参数 if(status == DEAD_OBJECT) mAlive = 0; return status; &#125; returnDEAD_OBJECT;&#125; 这里又遇见了IPCThreadState，之前也见过一次。看来，它确实与Binder通信有关，所以必须对其进行深入分析！ 1 “劳者一份”的IPCThreadState谁是“劳者”？线程，是进程中真正干活的伙计，所以它正是劳者。而“劳者一份”，就是每个伙计一份的意思。IPCThreadState的实现代码在IPCThreadState.cpp中，如下所示：IPCThreadState.cpp 12345678910111213141516171819202122232425262728293031IPCThreadState* IPCThreadState::self()&#123; if(gHaveTLS) &#123;//第一次进来为falserestart: constpthread_key_t k = gTLS; /* TLS是Thread Local Storage（线程本地存储空间）的简称。 这里只需知晓：这种空间每个线程都有，而且线程间不共享这些空间。 通过pthread_getspecific/pthread_setspecific函数可以获取/设置这些空间中的内容。 从线程本地存储空间中获得保存在其中的IPCThreadState对象。 有调用pthread_getspecific的地方，肯定也有调用pthread_setspecific的地方 */ IPCThreadState* st = (IPCThreadState*)pthread_getspecific(k); if(st) return st;// new一个对象，构造函数中会调用pthread_setspecific return new IPCThreadState; &#125; if(gShutdown) return NULL; pthread_mutex_lock(&amp;gTLSMutex); if(!gHaveTLS) &#123; if(pthread_key_create(&amp;gTLS, threadDestructor) != 0) &#123; pthread_mutex_unlock(&amp;gTLSMutex); return NULL; &#125; gHaveTLS = true; &#125; pthread_mutex_unlock(&amp;gTLSMutex);//其实goto没有我们说的那么不好，汇编代码也有很多跳转语句（没办法，太低级的语言了），关键是要用好 goto restart;&#125; 接下来，有必要转向分析它的构造函数IPCThreadState()，如下所示：IPCThreadState.cpp 1234567891011IPCThreadState::IPCThreadState() :mProcess(ProcessState::self()), mMyThreadId(androidGetTid())&#123; //在构造函数中，把自己设置到线程本地存储中去。 pthread_setspecific(gTLS, this); clearCaller(); //mIn和mOut是两个Parcel。把它看成是发送和接收命令的缓冲区即可。mIn.setDataCapacity(256); mOut.setDataCapacity(256);&#125; 每个线程都有一个IPCThreadState，每个IPCThreadState中都有一个mIn、一个mOut，其中mIn是用来接收来自Binder设备的数据的，而mOut则是用来存储发往Binder设备的数据的。 2 勤劳的transact传输工作是很辛苦的。我们刚才看到BpBinder的transact调用了IPCThreadState的transact函数，这个函数实际完成了与Binder通信的工作，如下面的代码所示：IPCThreadState.cpp 123456789101112131415161718192021222324//注意，handle的值为0，代表了通信的目的端status_t IPCThreadState::transact(int32_t handle, uint32_tcode, const Parcel&amp; data, Parcel* reply, uint32_t flags)&#123; status_terr = data.errorCheck(); flags |=TF_ACCEPT_FDS; ....../*【笔记六：】 注意这里的第一个参数BC_TRANSACTION，它是应用程序向binder设备发送消息的消息码， 而binder设备向应用程序回复消息的消息码以BR_开头。消息码的定义在binder_module.h中， 请求消息码和回应消息码的对应关系可见上文驱动篇。这里BC_TRANSACTION对应一次binder事务，client 对server的请求 ，这里client是服务端，server是serviceManager、*/ err =writeTransactionData(BC_TRANSACTION, flags, handle, code, data, NULL); ...... err = waitForResponse(reply); ...... returnerr;&#125; 多熟悉的流程：先发数据，然后等结果。再简单不过了！不过，我们有必要确认一下handle这个参数到底起了什么作用。先来看writeTransactionData函数，它的实现如下所示：IPCThreadState.cpp 123456789101112131415161718192021222324252627282930313233status_tIPCThreadState::writeTransactionData(int32_t cmd, uint32_t binderFlags, int32_thandle, uint32_t code, const Parcel&amp; data, status_t* statusBuffer)&#123; //binder_transaction_data 是和binder设备通信的数据结构。 binder_transaction_data tr; //果然，handle的值传递给了target，用来标识目的端，其中0是ServiceManager的标志。 tr.target.handle= handle; //code是消息码，用来switch/case的！ tr.code =code; tr.flags= binderFlags; conststatus_t err = data.errorCheck(); if (err== NO_ERROR) &#123; tr.data_size = data.ipcDataSize(); tr.data.ptr.buffer = data.ipcData(); tr.offsets_size = data.ipcObjectsCount()*sizeof(size_t); tr.data.ptr.offsets = data.ipcObjects(); &#125; else if(statusBuffer) &#123; tr.flags |= TF_STATUS_CODE; *statusBuffer = err; tr.data_size = sizeof(status_t); tr.data.ptr.buffer = statusBuffer; tr.offsets_size = 0; tr.data.ptr.offsets = NULL; &#125; else &#123; return (mLastError = err); &#125; //把命令写到mOut中， 而不是直接发出去 mOut.writeInt32(cmd); mOut.write(&amp;tr, sizeof(tr)); returnNO_ERROR;&#125; 现在，已经把addService的请求信息写到mOut中了。 【笔记七：】注意观察传递数据的变化 在BpServiceManager中还是Parcel，然后BpServiceManager 交给了BpBinder，BpBinder又把数据交给了IPCThreadState， IPCThreadState调用writeTransactionData方法，将数据进一步封装为 binder_transaction_data，并将binder_transaction_data和BC_XXX指令写到IPCThreadState中的mOut中。 · 【笔记八：】可以看到 真正与binder驱动打驱动打交道的是IPCThreadState。与Binder驱动打交道，意味着要往binder驱动写指令和数据，同时要从binder驱动读取返回的结果。writeTranscationData()方法实际上并没有做 往binder里写数据的操作，而是把数据写到自己的mOut成员变量里，那这个成员变量是怎么传给binder驱动的呢？ 其实是在waitForResponse（）函数里，waitForResponse()中的talkWithDriver()会读取mOut的数据并将数据传递给binder驱动，然后从binder驱动中读取返回数据传递给mIn，这样就完成了一次数据交互。 接下来再看发送请求和接收回复部分的实现，代码在waitForResponse函数中，如下所示：IPCThreadState.cpp 12345678910111213141516171819202122232425262728293031323334status_t IPCThreadState::waitForResponse(Parcel*reply, status_t *acquireResult)&#123; int32_tcmd; int32_terr; while (1) &#123; //talkWithDriver 在这里才真正开始与驱动打交道 if((err=talkWithDriver()) &lt; NO_ERROR) break; err =mIn.errorCheck(); if(err &lt; NO_ERROR) break; if(mIn.dataAvail() == 0) continue; cmd =mIn.readInt32(); switch(cmd) &#123; caseBR_TRANSACTION_COMPLETE: if (!reply &amp;&amp; !acquireResult) goto finish; break; ...... default: err = executeCommand(cmd);//看这个！ if (err != NO_ERROR) goto finish; break; &#125; &#125; finish: if (err!= NO_ERROR) &#123; if(acquireResult) *acquireResult = err; if(reply) reply-&gt;setError(err); mLastError = err; &#125; returnerr;&#125; 接下来看看talkWithDriver()函数 3 talkWithDriver（）talkwithDriver函数，如下所示：IPCThreadState.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051status_t IPCThreadState::talkWithDriver(bool doReceive)&#123; // binder_write_read是用来与Binder设备交换数据的结构 binder_write_read bwr; constbool needRead = mIn.dataPosition() &gt;= mIn.dataSize(); constsize_t outAvail = (!doReceive || needRead) ? mOut.dataSize() : 0; //【笔记9】 bwr.write_size = outAvail; bwr.write_buffer = (long unsigned int)mOut.data(); if(doReceive &amp;&amp; needRead) &#123; //接收数据缓冲区信息的填充。如果以后收到数据，就直接填在mIn中了。 bwr.read_size = mIn.dataCapacity(); bwr.read_buffer = (long unsigned int)mIn.data(); &#125; else &#123; bwr.read_size = 0; &#125; if((bwr.write_size == 0) &amp;&amp; (bwr.read_size == 0)) return NO_ERROR; bwr.write_consumed = 0; bwr.read_consumed = 0; status_terr; do &#123; #ifdefined(HAVE_ANDROID_OS) //看来不是read/write调用，而是ioctl方式。 if(ioctl(mProcess-&gt;mDriverFD, BINDER_WRITE_READ, &amp;bwr) &gt;= 0) err = NO_ERROR; else err = -errno;#else err =INVALID_OPERATION;#endif &#125;while (err == -EINTR); if (err&gt;= NO_ERROR) &#123; if(bwr.write_consumed &gt; 0) &#123; if (bwr.write_consumed &lt; (ssize_t)mOut.dataSize()) mOut.remove(0, bwr.write_consumed); else mOut.setDataSize(0); &#125; if(bwr.read_consumed &gt; 0) &#123; mIn.setDataSize(bwr.read_consumed); mIn.setDataPosition(0); &#125; return NO_ERROR; &#125; returnerr;&#125; 图 binder_write_read结构体 【笔记九：】waitForResponse（）是直接参与与binder驱动交互的地方了，首先 它初始化了binder_read_write结构体，将mIn和mOut中的数据读出来（如果有的话，没有就相当于初始化了），继而调用了binder驱动的ioctrl（）方法（对应驱动层的binder_ioctrl()），将这个封装好的binder_read_write结构发送给binder驱动，还记得上文binder驱动篇中的分析吗，binder驱动的binder_ioctrl()逻辑很简单，只是取出BC码和BR码，然后根据码来做对应的操作。这里综述一下framework到驱动层之间的通讯流程，具体如下1.ProcessState::self 打开驱动：binder驱动会为每一个flat_binder_object对象在内核中创建一个唯一的BinderNode与之对应。 同时，每一个打开了binder驱动的进程，在内核中都有一个binder_proc结构体与之对应，该结构体被加载在binder_procs的全局链表上，是全局链表，所以这何一个进程（我们这里是MediaServer）都可以访问到任何进程的binder_proc对象了。同时，binder_node 被加载在binder_proc的nodes红黑树中。..2.mmap()让binder驱动去申请空间并做地址映射：还记得我们MediaServer初始化的时候调用了一个ProcessState::self 方法吗，它除了打开驱动，还调用了mmap()为该进程分配一个buffer，默认是4k ，也就是一个页面，这可以从分配函数看出来 1binder_update_page_range(proc, 1, proc-&gt;buffer, proc-&gt;buffer + PAGE_SIZE, vma)； PAGE_SIZE = 4K，分配完成后 以binder_buffer 的形式 保存在proc的buffers红黑数里，同时进行了用户空间和内核空间的物理地址映射，也就是说现在mediaserver和内核空间映射了同一份物理地址，server端可以直接访问该物理地址而不需要将数据从内核空间往server进程所在的用户空间再拷贝一次了！.. 通过ProcessState的getStrongProxyForHandle方法，创建了一个客户端“信使”BpBinder（0），其中handle = 0，驱动其实正是通过handle值来查找客户端要通信的对端对应的binderNode，这个后面会说。该信使还持有IPCThreadState对象，它才是真正负责与驱动通讯的。..4.创建服务端（这里是serviceManager做特殊的服务端，它提供的服务是注册服务add_service方法）对应的BpServiceManager对象（BpServiceManager对象，它是IServiceManager的儿子，IServiceManager定义了业务函数和interface_cast转换函数，同时继承了BpBinderInterface接口,我们创建服务端的BpServiceManager，其实就是调用了IServiceManager.cpp中的asInterface函数，创建了一个BpServiceManager，同时它还持有我们传进去的信使“BpBinder（0）“的引用，对应mRemote）。现在我们有BpServiceManager了，它也有IserviceMaganer的业务函数，当我们调用对应的业务函数，这里是add_service（）要将我们的服务注册上去时，它会把命令交给mRemote，也就是我们的BpBinder().transact()方法，transact（）会调用IPCThreadState的transact（）方法。.. IPCThreadState.transact(int32_t handle,uint32_t,code, const Parcel&amp; data,Parcel* reply, uint32_t flags)与驱动交流，先写后读。.. 将请求内容写到写缓冲区mOut，通过IPCThreadState::self.writeTransactionData 吧数据封装成binder_transaction_data.. 把请求内容发送给驱动，并等待驱动返回结果，将结果写在mIn缓冲区，读写是通过IPCThreadState的talkWithDriver()方法，该方法进一步封装了要传递给binder驱动的数据，变为binder_read_write，同时把写的数据填入write_buffer里了。在talkWithDriver中，通过系统调用ioctl(mProcess-&gt;mDriverFD, BINDER_WRITE_READ, &amp;bwr)将数据发送给驱动。注意，现在bwr中的指令是BC_TRANSACATION ，并且wirte_size&gt;0,且write_buffer不为空。.. binder_proc对象，再看一下这张图复习一下binder_proc除了图中所画的几个成员之外，还有两个重要成员，都会在创建binder_proc对象的时候一起初始化。分别是struct list_head todo：当进程接收到一个进程间通信请求时，Binder驱动就将该请求封装成一个工作项，并且加入到进程的待处理工作向队列中，该队列使用成员变量todo来描述。wait_queue_head_t wait： 线程池中空闲Binder线程会睡眠在由该成员所描述的等待队列中， 当宿主进程的待处理工作项队列增加新工作项后，驱动会唤醒这些线程，以便处理新的工作项。后面会讲到binder驱动会用他们来构建binder_transaction 结构体。 以我们的例子为例，MediaServer 调用IPCTtreadState，并将mOut通过waitForResponse()里的ioctrl(BINDER_READ_WRITE,&amp;data)发送给驱动的时候，驱动早已经完成步骤1、2了。也就是MediaServer 已经有了一个对应的binder_proc 结构体，而且其携带的的flat_binder_object的handle指向0.注意，这里面的flat_handle_object中的type是handle，同时handle = 0；【注： 见上文 5.通讯过程中的binder实体的传递】并且做了地址映射。..9.调用驱动的ioctrl()方法发送BINDER_WRITE_READ， 在ioctrl()函数的入口处，会执行 thread = binder_get_thread(proc)，该函数首先获取打开驱动的进程的pid号，根据pid号，检查是否可以在threads的红黑树中找到对应的thread对象，有就直接返回，没有就创建对应的Thread对象，加入binder_proc的threads的红黑树中。..10.现在binder驱动已经有了线程的Thread对象，并加入到binder_proc中的threads红黑树中。并且知道了请求码是BINDER_WRITE_READ，驱动篇讲过，ioctrl的功能就是根据不同请求码调用不同的处理方法。如果命令是BINDER_WRITE_READ，并且 bwr.write_size &gt; 0，则调用binder_thread_write。 12345678910111213141516171819202122232425switch (cmd) &#123; case BINDER_WRITE_READ: &#123; struct binder_write_read bwr; ... if (bwr.write_size &gt; 0) &#123; ret = binder_thread_write(proc, thread, (void __user *)bwr.write_buffer, bwr.write_size, &amp;bwr.write_consumed); trace_binder_write_done(ret); if (ret &lt; 0) &#123; bwr.read_consumed = 0; if (copy_to_user(ubuf, &amp;bwr, sizeof(bwr))) ret = -EFAULT; goto err; &#125; &#125; if (bwr.read_size &gt; 0) &#123; ret = binder_thread_read(proc, thread, (void __user *)bwr.read_buffer, bwr.read_size, &amp;bwr.read_consumed, filp-&gt;f_flags &amp; O_NONBLOCK); trace_binder_read_done(ret); if (!list_empty(&amp;proc-&gt;todo)) wake_up_interruptible(&amp;proc-&gt;wait); if (ret &lt; 0) &#123; if (copy_to_user(ubuf, &amp;bwr, sizeof(bwr))) ret = -EFAULT; goto err; &#125; &#125; 当write_buffer存在数据，binder线程的写操作循环执行。这里bwr.write_size&gt;0,故会执行写循环，也就是binder_thread_write()方法。..11.进入binder_thread_write()来处理请求码。首先读取Binder命令，由于buffer里只是指向命令的指针，实际数据还保存在用户空间，因此调用get_user函数从用户空间读取数据（一次拷贝）。取得命令后，先更新命令的状态信息，然后根据不同命令 进行不同的处理。这里的例子中，MediaServer发送的命令是BC_TRANSACTION，对于请求码为BC_TRANSACTION或BC_REPLY时，会执行binder_transaction()方法，这是最为频繁的操作。 123456789101112131415161718192021int binder_thread_write(struct binder_proc *proc, struct binder_thread *thread, void __user *buffer, int size, signed long *consumed)&#123; uint32_t cmd; void __user *ptr = buffer + *consumed; void __user *end = buffer + size; ... switch (cmd) &#123; case BC_TRANSACTION: case BC_REPLY: &#123; struct binder_transaction_data tr; if (copy_from_user(&amp;tr, ptr, sizeof(tr))) return -EFAULT; ptr += sizeof(tr); // 【笔记十：】注意看最后一个参数，因为BC_TRANSACTION 还有BC_REPLY 都会 //调用binder_transaction()，一个函数处理了两个逻辑，所有它用了一个boolean值 //cmd == BC_REPLAY 来决定走哪个流程 binder_transaction(proc, thread, &amp;tr, cmd == BC_REPLY); break; &#125; ..12.binder_transaction内部流程 首先梳理下当前传进来的binder_transaction_data到底包含了哪些数据： 1 根据binder_transaction_data 中的handle,通过映射关系找到对应的binder_node，进而找到目标进程binder_proc 2 根据本次binder_transaction是否是异步，如果不是异步，意味着当前的binder传输流程还没走完，还是同一个transaction流程，从from_parent查找，如果是异步，从binder_proc 回溯查找target_thread。 3 如果找到target_thread，则它就是目标线程，否则binder_proc对应的进程是目标线程。 4 根据用户空间传入的数据和目标，发起事务的线程、进程信息，创建binder_transaction结构体，binder_transaction 其实与一次binder_transaction（）方法对应的，每执行一次，便会在驱动中为其创建一个对应的结构体。这里要解释一下什么是binder_transaction对象。可以这么理解，binder_transaction_data是binder传输对象的外部表示，应用于应用程序的，而binder_transaction是binder传输对象的内部表示，应用于内核binder驱动本身。binder_transaction对象都位于binder_thread的传输栈上，其本身是一个多级链表结构，描述了传输来源和传输目标，也记录了本次传输的信息，如binder_work、binder_buffer、binder命令等。 1234567891011121314151617181920212223struct binder_transaction &#123; int debug_id; // 当驱动为目标进程或线程创建一个事务时，就会将该成员的type置为 // BINDER_WORK_TRANSACTION，并将它添加到目标进程或线程的todo队列，等待处理 struct binder_work work; struct binder_thread *from; // 发起事务的线程 // 事务所依赖的另外一个事务以及目标线程下一个要处理的事务 struct binder_transaction *from_parent; struct binder_proc *to_proc; // 负责处理该事务的进程 struct binder_thread *to_thread; // 负责处理该事务的线程 struct binder_transaction *to_parent; unsigned need_reply:1; // 同步事务为1需要等待对方回复；异步为0 /* unsigned is_dead:1; */ /* not used at the moment */ // 指向驱动为该事务分配的内核缓冲区，保存了进程间通信数据 struct binder_buffer *buffer; unsigned int code; // 直接从进程间通信数据中拷贝过来 unsigned int flags; // 直接从进程间通信数据中拷贝过来 long priority; // 源线程优先级 // 线程在处理事务时，驱动会修改它的优先级以满足源线程和目标Service组建的要求。在修改之 // 前，会将它原来的线程优先级保存在该成员中，以便线程处理完该事务后可以恢复原来的优先级 long saved_priority; uid_t sender_euid; // 源线程用户ID&#125;; 4 根据传输的目标设置本次binder传输的目标等待队列(wait_queue)和本次binder_work需要挂载的列表(list)，也就是target_wait和target_list。其中target_wait中存放的就是本次要唤醒的目标进程/线程。 target_list 就是目标进程中的todo 5 到目前，target_node，target_thread，target_proc，target_wait和target_list都已经找到了。下面就该为此次传输分配新的binder_transaction对象和binder_work对象了，并根据当前的信息填充内容 6 构造一个新的binder_transaction 对象，并为期分配内存，同时修改flat_binder_object,做好handle到binder地址之间的映射。如果发送端发的是binder，驱动会把type 修改为HANDLE_TYPE，同时找到binder_node-&gt;binder_ref 找到索引id，binder_ref-&gt;desc，将改id赋值给handle.如果是handle，吧流程返过来，handle-&gt;binder_ref-&gt;binder_node，将binder_node 赋值给flat_binder_object中的binder，修改type为BINDER_TYPE； 7 新的binder_flat_object修改好了，在此之前，还要根据是同步传输还是异步传输，设置binder_transaction中的replay值，并将binder_transaction插入到target_list也即traget_tread/target_proc的todo队列中。 至此 发送命令算是做完了。可以看到，调用了binder_transcation之后，并没有把数据发送给server，驱动只不过是创建了一个binder_transaction结构，然后把它挂在binder_proc的todo队列中。图：驱动层调用层级 总结： 客户端的每一次请求，驱动最终都会生成换一个binder_transaction结构体，并把这个结构体挂在目标进程target_proc 也就是Server端 ServerManager服务对应的那个binder_proc 中。 8 唤醒等待线程的目标线程 12if (target_wait) wake_up_interruptible(target_wait); 9 server端的目标线程开始进入binder_loop状态，从ServiceManager那端来看，它走的其实和client端发起请求的流程是类似的，只不过此时mOut为空，binder驱动执行binder_thread_read()方法。 10 server端通过ioctrl控制驱动执行binder_thread_read,首先读取todo列表的首节点。这是client端发送请求操作完成之后插进来的。 11 根据todo中的binder_work 找到对应的binder_transaction,有了binder_transaction,便从binder_transaction 和binder_buffer中提取出client端发送的数据，重新组装成binder_transaction_data。 12 将binder_transaction_data结构体通过copy_to_user拷贝到用户空间，由接收端ServiceManager收到 13 server端收到binder驱动转发的客户端数据 进行处理后，再发送回给binder驱动。一次循环往复。完成客户端往服务端发送数据的过程。 总结：客户端的请求，都会被binder驱动创建一个对应的binder_transaction。并将这个transaction挂在目标进程binder_proc的todo链表里，binder驱动再唤醒目标进程，目标进程对驱动执行读取命令，驱动执行binder_thread_read，同时将客户端发送的数据，以查找todo链表 -&gt; 查找binder_transaction-&gt; binder_buffer 的方式，重新包装成binder_transaction_data，拷贝到server端对应的用户空间。同时将改todo列表删除。至此完成客户端-&gt;server端的传输。server的返回数据流程和这个基本一致，只不过server和client的角色需要对调一下。 OK，我们已发送了请求数据，假设马上就收到了回复，后续该怎么处理呢？来看executeCommand函数，如下所示：IPCThreadState.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263status_t IPCThreadState::executeCommand(int32_tcmd)&#123; BBinder*obj; RefBase::weakref_type* refs; status_tresult = NO_ERROR; switch(cmd) &#123; caseBR_ERROR: result = mIn.readInt32(); break; ...... caseBR_TRANSACTION: &#123; binder_transaction_data tr; result = mIn.read(&amp;tr, sizeof(tr)); if (result != NO_ERROR) break; Parcel buffer; Parcel reply; if (tr.target.ptr) &#123; /* 看到了BBinder，想起图6-3了吗？BnServiceXXX从BBinder派生， 这里的b实际上就是实现BnServiceXXX的那个对象，关于它的作用，后文会详述 */ sp&lt;BBinder&gt; b((BBinder*)tr.cookie); const status_t error = b-&gt;transact(tr.code, buffer, &amp;reply, 0); if (error &lt; NO_ERROR)reply.setError(error); &#125; else &#123; /* the_context_object是IPCThreadState.cpp中定义的一个全局变量， 可通过setTheContextObject函数设置 */ const status_t error = the_context_object-&gt;transact(tr.code,buffer, &amp;reply, 0); if (error &lt; NO_ERROR) reply.setError(error); &#125; break; ...... case BR_DEAD_BINDER: &#123; /* 收到binder驱动发来的service死掉的消息，看来只有Bp端能收到了， 后面，我们将会对此进行分析。 */ BpBinder *proxy = (BpBinder*)mIn.readInt32(); proxy-&gt;sendObituary(); mOut.writeInt32(BC_DEAD_BINDER_DONE); mOut.writeInt32((int32_t)proxy); &#125;break; ......case BR_SPAWN_LOOPER: //特别注意，这里将收到来自驱动的指示以创建一个新线程，用于和Binder通信。 mProcess-&gt;spawnPooledThread(false); break; default: result = UNKNOWN_ERROR; break; &#125; ...... if(result != NO_ERROR) &#123; mLastError = result; &#125; returnresult;&#125; 4 StartThread Pool和join Thread Pool1.创造劳动力——startThreadPool()startThreadPool()的实现，如下面的代码所示：ProcessState.cpp//太简单，没什么好说的 1234567891011121314151617181920212223void ProcessState::startThreadPool()&#123;AutoMutex _l(mLock);//如果要是已经startThreadPool的话，这个函数就没有什么实质作用了 if(!mThreadPoolStarted) &#123; mThreadPoolStarted = true; spawnPooledThread(true); //注意，传进去的参数是true &#125;&#125;上面的spawnPooledThread()函数的实现，如下所示：ProcessState.cppvoid ProcessState::spawnPooledThread(bool isMain)&#123; //注意，isMain参数是true。 if(mThreadPoolStarted) &#123; int32_t s = android_atomic_add(1, &amp;mThreadPoolSeq); char buf[32]; sprintf(buf, \"Binder Thread #%d\", s); sp&lt;Thread&gt; t = new PoolThread(isMain); t-&gt;run(buf); &#125;&#125; PoolThread是在IPCThreadState中定义的一个Thread子类，它的实现，如下所示：IPCThreadState.h::PoolThread类 123456789101112131415class PoolThread : public Thread&#123;public: PoolThread(bool isMain) :mIsMain(isMain)&#123;&#125; protected: virtualbool threadLoop() &#123; //线程函数如此简单，不过是在这个新线程中又创建了一个IPCThreadState。 // 你还记得它是每个伙计都有一个的吗？ IPCThreadState::self()-&gt;joinThreadPool(mIsMain); return false; &#125; const boolmIsMain;&#125;; 2万众归一 joinThreadPool还需要看看IPCThreadState的joinThreadPool的实现，因为新创建的线程也会调用这个函数，具体代码如下所示：IPCThreadState.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445void IPCThreadState::joinThreadPool(bool isMain)&#123; //注意，如果isMain为true，我们需要循环处理。把请求信息写到mOut中，待会儿一起发出去 mOut.writeInt32(isMain ? BC_ENTER_LOOPER : BC_REGISTER_LOOPER); androidSetThreadSchedulingGroup(mMyThreadId, ANDROID_TGROUP_DEFAULT); status_tresult; do &#123; int32_t cmd; if(mIn.dataPosition() &gt;= mIn.dataSize()) &#123; size_t numPending = mPendingWeakDerefs.size(); if (numPending &gt; 0) &#123; for (size_t i = 0; i &lt; numPending; i++) &#123; RefBase::weakref_type* refs = mPendingWeakDerefs[i]; refs-&gt;decWeak(mProcess.get()); &#125; mPendingWeakDerefs.clear(); &#125; //处理已经死亡的BBinder对象 numPending = mPendingStrongDerefs.size(); if (numPending &gt; 0) &#123; for (size_t i = 0; i &lt; numPending; i++) &#123; BBinder* obj = mPendingStrongDerefs[i]; obj-&gt;decStrong(mProcess.get()); &#125; mPendingStrongDerefs.clear(); &#125; &#125; // 发送命令，读取请求 result = talkWithDriver(); if(result &gt;= NO_ERROR) &#123; size_t IN = mIn.dataAvail(); if (IN &lt; sizeof(int32_t)) continue; cmd = mIn.readInt32(); result= executeCommand(cmd); //处理消息 &#125; ...... &#125; while(result != -ECONNREFUSED &amp;&amp; result != -EBADF); mOut.writeInt32(BC_EXIT_LOOPER); talkWithDriver(false);&#125; 原来，我们的两个伙计在talkWithDriver，它们希望能从Binder设备那里找到点可做的事情。 3. 有几个线程在服务到底有多少个线程在为Service服务呢？目前看来是两个： startThreadPool中新启动的线程通过joinThreadPool读取Binder设备，查看是否有请求。主线程也调用joinThreadPool读取Binder设备，查看是否有请求。看来，binder设备是支持多线程操作的，其中一定是做了同步方面的工作。mediaserver这个进程一共注册了4个服务，繁忙的时候，两个线程会不会显得有点少呢？另外，如果实现的服务负担不是很重，完全可以不调用startThreadPool创建新的线程，使用主线程即可胜任。 特殊的server端，ServiceManager刚才分析的MediaServer，在跟servicemanager注册服务的时候，其实扮演的是client的角色。serviceManager 是系统所有服务的大管家，提供查询，注册服务等方法。 1. serviceManager 原理前面说过，defaultServiceManager返回的是一个BpServiceManager，通过它可以把命令请求发送给handle值为0的目的端。按照图6-3所示的IServiceManager“家谱”，无论如何也应该有一个类从BnServiceManager派生出来并处理这些来自远方的请求吧？很可惜，源码中竟然没有这样的一个类存在！但确实又有这么一个程序完成了BnServiceManager未尽的工作，这个程序就是servicemanager，它的代码在Service_manager.c中，如下所示： 注意：通过这件事情是否能感悟到什么？嗯，我们确实可以抛开前面所有的那些封装，直接与Binder设备打交道。 下面来看ServiceManager是怎么放弃华丽的封装去做Manager的。 1 ServiceManager的入口函数ServiceManager的入口函数如下所示。ServiceManager.c 12345678910111213int main(int argc, char **argv)&#123; structbinder_state *bs; //BINDER_SERVICE_MANAGER的值为NULL，是一个magic number。 void*svcmgr = BINDER_SERVICE_MANAGER; //①应该是打开binder设备吧？ bs = binder_open(128*1024); //②成为manager，是不是把自己的handle置为0？ binder_become_context_manager(bs) svcmgr_handle= svcmgr; //③处理客户端发过来的请求。 binder_loop(bs, svcmgr_handler);&#125; 这里，一共有三个重要关键点。必须对其逐一地进行分析。 注意：有一些函数是在Binder.c中实现的，此Binder.c不是前面碰到的那个Binder.cpp。 2 打开Binder设备binder_open函数用于打开Binder设备，它的实现如下所示：Binder.c 123456789101112131415/* 这里的binder_open应该与我们之前在ProcessState中看到的一样： 1）打开Binder设备 2）内存映射*/struct binder_state *binder_open(unsigned mapsize)&#123; structbinder_state *bs; bs =malloc(sizeof(*bs)); .... bs-&gt;fd= open(\"/dev/binder\", O_RDWR); .... bs-&gt;mapsize = mapsize; bs-&gt;mapped = mmap(NULL, mapsize, PROT_READ, MAP_PRIVATE, bs-&gt;fd,0); &#125; 果然如此，有了之前所学习掌握的知识，这里真的就不难理解了。 3. 成为老大怎么才成为系统中独一无二的manager了呢？manger的实现，如下面的代码所示：Binder.c 12345int binder_become_context_manager(structbinder_state *bs)&#123; //实现太简单了！这个0是否就是设置自己的handle呢？ returnioctl(bs-&gt;fd, BINDER_SET_CONTEXT_MGR, 0);&#125; 4.死磕Binderbinder_loop是一个很尽责的函数。为什么这么说呢？因为它老是围绕着Binder设备转悠，实现代码如下所示：Binder.c 12345678910111213141516171819/* 注意binder_handler参数，它是一个函数指针，binder_loop读取请求后将解析 这些请求，最后调用binder_handler完成最终的处理。*/void binder_loop(struct binder_state *bs,binder_handler func)&#123; int res; structbinder_write_read bwr; readbuf[0] = BC_ENTER_LOOPER; binder_write(bs, readbuf, sizeof(unsigned)); for (;;)&#123;//果然是循环 bwr.read_size = sizeof(readbuf); bwr.read_consumed = 0; bwr.read_buffer = (unsigned) readbuf; res =ioctl(bs-&gt;fd, BINDER_WRITE_READ, &amp;bwr); //接收到请求，交给binder_parse，最终会调用func来处理这些请求。 res = binder_parse(bs, 0, readbuf,bwr.read_consumed, func); &#125; 5 集中处理往binder_loop中传的那个函数指针是svcmgr_handler，它的代码如下所示：Service_manager.c 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051int svcmgr_handler(struct binder_state *bs,structbinder_txn *txn, struct binder_io *msg,structbinder_io *reply)&#123; structsvcinfo *si; uint16_t*s; unsignedlen; void*ptr; // svcmgr_handle就是前面说的那个magic number，值为NULL。 //这里要比较target是不是自己。 if(txn-&gt;target != svcmgr_handle) return -1; s =bio_get_string16(msg, &amp;len); if ((len!= (sizeof(svcmgr_id) / 2)) || memcmp(svcmgr_id, s, sizeof(svcmgr_id))) &#123; return-1; &#125; switch(txn-&gt;code) &#123; caseSVC_MGR_GET_SERVICE://得到某个service的信息，service用字符串表示。 caseSVC_MGR_CHECK_SERVICE: s = bio_get_string16(msg, &amp;len);//s是字符串表示的service名称。 ptr =do_find_service(bs, s, len); if(!ptr) break; bio_put_ref(reply, ptr); return 0; caseSVC_MGR_ADD_SERVICE://对应addService请求 s =bio_get_string16(msg, &amp;len); ptr =bio_get_ref(msg); if(do_add_service(bs, s, len, ptr, txn-&gt;sender_euid)) return -1; break; //得到当前系统已经注册的所有service的名字。 caseSVC_MGR_LIST_SERVICES: &#123; unsigned n = bio_get_uint32(msg); si =svclist; while((n-- &gt; 0) &amp;&amp; si) si = si-&gt;next; if(si) &#123; bio_put_string16(reply, si-&gt;name); return 0; &#125; return -1; &#125; default: return-1; &#125; bio_put_uint32(reply,0); return 0;&#125; 2 服务的注册上面提到的switch/case语句，将实现IServiceManager中定义的各个业务函数，我们重点看do_add_service这个函数，它最终完成了对addService请求的处理实现，代码如下所示：Service_manager.c 12345678910int do_add_service(struct binder_state *bs,uint16_t*s, unsigned len, void*ptr, unsigned uid)&#123; structsvcinfo *si; if (!ptr|| (len == 0) || (len &gt; 127)) return -1; //svc_can_register函数比较注册进程的uid和名字。 if(!svc_can_register(uid, s)) &#123; return -1; ...... 将上面的函数暂时放一下，先介绍svc_can_register函数。 1不是什么都可以注册的do_add_service函数中的svc_can_register，是用来判断注册服务的进程是否有权限的，代码如下所示：Service_manager.c 12345678910111213int svc_can_register(unsigned uid, uint16_t *name)&#123; unsignedn; //如果用户组是root用户或者system用户，则权限够高，允许注册 if ((uid== 0) || (uid == AID_SYSTEM)) return 1; for (n =0; n &lt; sizeof(allowed) / sizeof(allowed[0]); n++) if((uid == allowed[n].uid) &amp;&amp; str16eq(name, allowed[n].name)) return 1; return 0;&#125; allowed结构数组，控制那些权限达不到root和system的进程，它的定义如下所示： 1234567891011121314151617181920static struct &#123; unsigneduid; constchar *name;&#125; allowed[] = &#123;#ifdef LVMX &#123;AID_MEDIA, \"com.lifevibes.mx.ipc\" &#125;,#endif &#123;AID_MEDIA, \"media.audio_flinger\" &#125;, &#123;AID_MEDIA, \"media.player\" &#125;, &#123;AID_MEDIA, \"media.camera\" &#125;, &#123;AID_MEDIA, \"media.audio_policy\" &#125;, &#123;AID_RADIO, \"radio.phone\" &#125;, &#123;AID_RADIO, \"radio.sms\" &#125;, &#123;AID_RADIO, \"radio.phonesubinfo\" &#125;, &#123;AID_RADIO, \"radio.simphonebook\" &#125;, &#123;AID_RADIO, \"phone\" &#125;, &#123;AID_RADIO, \"isms\" &#125;, &#123;AID_RADIO, \"iphonesubinfo\" &#125;, &#123;AID_RADIO, \"simphonebook\" &#125;,&#125;; 所以，如果Server进程权限不够root和system，那么请记住要在allowed中添加相应的项。 2. 添加服务项再回到我们的do_add_service，如下所示：Service_manager.c 123456789101112131415161718192021222324252627282930313233343536int do_add_service(struct binder_state *bs,uint16_t*s, unsigned len, void *ptr, unsigned uid)&#123; ...... //接前面的代码 si =find_svc(s, len); if (si) &#123; if(si-&gt;ptr) &#123; return -1; &#125; si-&gt;ptr = ptr; &#125; else &#123; si =malloc(sizeof(*si) + (len + 1) * sizeof(uint16_t)); if(!si) &#123; return -1; &#125; //ptr是关键数据，可惜为void*类型。只有分析驱动的实现才能知道它的真实含义了。 si-&gt;ptr = ptr; si-&gt;len = len; memcpy(si-&gt;name, s, (len + 1) * sizeof(uint16_t)); si-&gt;name[len] = '\\0'; si-&gt;death.func = svcinfo_death;//service退出的通知函数 si-&gt;death.ptr = si; //这个svclist是一个list，保存了当前注册到ServiceManager中的信息。 si-&gt;next = svclist; svclist = si; &#125; binder_acquire(bs,ptr); /*我们希望当服务进程退出后，ServiceManager能有机会做一些清理工作，例如释放前面malloc出来的si。binder_link_to_death完成这项工作，每当有服务进程退出时，ServiceManager都会得到来自Binder设备的通知。*/ binder_link_to_death(bs, ptr, &amp;si-&gt;death); return 0;&#125; 至此，服务注册分析完毕。可以知道，ServiceManager不过就是保存了一些服务的信息。那么，这样做又有什么意义呢？ ServiceManger能集中管理系统内的所有服务，它能施加权限控制，并不是任何进程都能注册服务。 ServiceManager支持通过字符串名称来查找对应的Service。这个功能很像DNS。 由于各种原因，Server进程可能生死无常。如果让每个Client都去检测，压力实在太大。现在有了统一的管理机构，Client只需要查询ServiceManager，就能把握动向，得到最新信息。这可能正是ServiceManager存在的最大意义吧。 MediaPlayerService和它的Client前面，一直在讨论ServiceManager和它的Client，现在我们以MediaPlayerService的Client换换口味吧。由于ServiceManager不是从BnServiceManager中派生的，所以之前没有讲述请求数据是如何从通讯层传递到业务层来处理的过程。本节，我们以MediaPlayerService和它的Client做为分析对象，试解决这些遗留问题。 查询ServiceManager前文曾分析过ServiceManager的作用，一个Client想要得到某个Service的信息，就必须先和ServiceManager打交道，通过调用getService函数来获取对应Service的信息。请看来源于IMediaDeathNotifier.cpp中的例子getMediaPlayerService()，它的代码如下所示：IMediaDeathNotifier.cpp 123456789101112131415161718192021222324252627/* 这个函数通过与ServiceManager通信，获得一个能够与MediaPlayerService通信的BpBinder， 然后再通过障眼法interface_cast，转换成一个BpMediaPlayerService。*/IMediaDeathNotifier::getMediaPlayerService()&#123; sp&lt;IServiceManager&gt; sm = defaultServiceManager(); sp&lt;IBinder&gt; binder; do &#123; //向ServiceManager查询对应服务的信息，返回BpBinder。 binder = sm-&gt;getService(String16(\"media.player\")); if(binder != 0) &#123; break; &#125; //如果ServiceManager上还没有注册对应的服务，则需要等待，直到对应服务注册//到ServiceManager中为止。 usleep(500000); &#125;while(true); /* 通过interface_cast，将这个binder转化成BpMediaPlayerService， binder中的handle标识的一定是目的端MediaPlayerService。 */ sMediaPlayerService = interface_cast&lt;IMediaPlayerService&gt;(binder); &#125; returnsMediaPlayerService;&#125; 有了BpMediaPlayerService，就能够使用任何IMediaPlayerService提供的业务逻辑函数了。例如createMediaRecorder和createMetadataRetriever等。显而易见的是，调用的这些函数都将把请求数据打包发送给Binder驱动，由BpBinder中的handle值找到对应端的处理者来处理。这中间经历过如下的过程： （1）通讯层接收到请求。 （2）递交给业务层处理。 ##子承父业根据前面的分析可知，MediaPlayerService驻留在MediaServer进程中，这个进程有两个线程在talkWithDriver。假设其中有一个线程收到了请求，它最终会通过executeCommand调用来处理这个请求，实现代码如下所示：IPCThreadState.cpp 12345678910111213141516171819202122232425262728293031323334353637status_t IPCThreadState::executeCommand(int32_tcmd)&#123; BBinder*obj; RefBase::weakref_type* refs; status_tresult = NO_ERROR; switch(cmd) &#123; case BR_ERROR: result = mIn.readInt32(); break; ...... caseBR_TRANSACTION: &#123; binder_transaction_data tr; result = mIn.read(&amp;tr, sizeof(tr)); if (result != NO_ERROR) break; Parcel buffer; Parcel reply; if (tr.target.ptr) &#123; /* 看到BBinder，想起图6-3了吗？ BnServiceXXX从BBinder派生， 这里的b实际就是实现BnServiceXXX的那个对象，这样就直接定位到了业务层的对象。 */ sp&lt;BBinder&gt; b((BBinder*)tr.cookie); const status_t error = b-&gt;transact(tr.code, buffer, &amp;reply, 0); if (error &lt; NO_ERROR) reply.setError(error); &#125; else &#123; /* the_context_object是IPCThreadState.cpp中定义的一个全局变量。可通过 setTheContextObject函数设置。 */ const status_t error = the_context_object-&gt;transact(tr.code,buffer, &amp;reply, 0); if (error &lt; NO_ERROR) reply.setError(error); &#125; break; ...... BBinder和业务层有什么关系？还记得图6-3吗？我们以MediaPlayerService为例，来梳理一下其派生关系，如图6-5所示： 图6-5 MediaPlayerService家谱 BnMediaPlayerService实现了onTransact函数，它将根据消息码调用对应的业务逻辑函数，这些业务逻辑函数由MediaPlayerService来实现。这一路的历程，如下面的代码所示：Binder.cpp 12345678910111213141516171819status_t BBinder::transact( uint32_tcode, const Parcel&amp; data, Parcel* reply, uint32_t flags)&#123; data.setDataPosition(0); status_terr = NO_ERROR; switch(code) &#123; casePING_TRANSACTION: reply-&gt;writeInt32(pingBinder()); break; default: //调用子类的onTransact，这是一个虚函数。 err = onTransact(code, data, reply, flags); break; &#125; if (reply!= NULL) &#123; reply-&gt;setDataPosition(0); &#125; returnerr;&#125; IMediaPlayerService.cpp 1234567891011121314151617181920212223242526status_t BnMediaPlayerService::onTransact(uint32_tcode, const Parcel&amp; data, Parcel* reply, uint32_t flags)&#123; switch(code) &#123; ...... caseCREATE_MEDIA_RECORDER: &#123; CHECK_INTERFACE(IMediaPlayerService, data, reply); //从请求数据中解析对应的参数 pid_t pid = data.readInt32(); //子类要实现createMediaRecorder函数。 sp&lt;IMediaRecorder&gt; recorder = createMediaRecorder(pid); reply-&gt;writeStrongBinder(recorder-&gt;asBinder()); return NO_ERROR; &#125;break; caseCREATE_METADATA_RETRIEVER: &#123; CHECK_INTERFACE(IMediaPlayerService, data, reply); pid_t pid = data.readInt32(); //子类要实现createMetadataRetriever函数 sp&lt;IMediaMetadataRetriever&gt; retriever =createMetadataRetriever(pid); reply-&gt;writeStrongBinder(retriever-&gt;asBinder()); return NO_ERROR; &#125;break; default: return BBinder::onTransact(code, data, reply, flags); &#125;&#125;","categories":[{"name":"Android","slug":"Android","permalink":"http://wenyiqingnian.xyz/categories/Android/"}],"tags":[{"name":"android","slug":"android","permalink":"http://wenyiqingnian.xyz/tags/android/"},{"name":"Binder","slug":"Binder","permalink":"http://wenyiqingnian.xyz/tags/Binder/"}]},{"title":"《现代艺术150年》未影印作品2","slug":"《现代艺术150年》未影印作品2","date":"2018-06-16T06:00:50.000Z","updated":"2018-06-17T06:54:19.000Z","comments":true,"path":"2018/06/16/《现代艺术150年》未影印作品2/","link":"","permalink":"http://wenyiqingnian.xyz/2018/06/16/《现代艺术150年》未影印作品2/","excerpt":"","text":"51.The Kiss (French: Le Baiser) 吻 1882（Auguste Rodin, 奥古斯特·罗丹）https://en.wikipedia.org/wiki/The_Kiss_(Rodin_sculpture) 52.The Kiss 吻 1907-1908（Constantin Brâncuși, 康斯坦丁·布朗库西）https://en.wikipedia.org/wiki/The_Kiss_(Br%C3%A2ncu%C8%99i_sculpture) 53.Sleeping Muse, 沉睡的缪斯 1910 （Constantin Brâncuși, 康斯坦丁·布朗库西）http://www.artic.edu/aic/collections/artwork/9024 54.Head 头 1911-1912（Amedeo Modigliani, 阿梅代奥·莫迪利亚尼）https://www.wikiart.org/en/amedeo-modigliani/head 55.Walking Man I 行走的人1 1960（Alberto Giacometti， 阿尔伯托·贾科梅蒂）https://www.artsy.net/artwork/alberto-giacometti-walking-man-i 56.Spoon Woman勺形女人 1927 （Alberto Giacometti， 阿尔伯托·贾科梅蒂）http://www.artic.edu/aic/collections/artwork/37761 57.Pierced Form 穿孔之形 1963-1964（Barbara Hepworth, 芭芭拉·赫普沃斯）http://www.tate.org.uk/art/artworks/hepworth-pierced-form-t00704 58.Pelagos 海洋生物 1946 （Barbara Hepworth, 芭芭拉·赫普沃斯）http://www.tate.org.uk/art/artworks/hepworth-pelagos-t00699 59.Single Form 单一的形式 1961 （Barbara Hepworth, 芭芭拉·赫普沃斯）http://www.tate.org.uk/art/artworks/hepworth-single-form-september-t03143 SEVEN60.Opening of the Fifth Seal 揭开第五印 1608（El Greco, 埃尔·格列柯）https://en.wikipedia.org/wiki/Opening_of_the_Fifth_Seal 61.Houses at l’Estaque 埃斯塔克的房子 1908（Georges Braque, 乔治·布拉克）https://en.wikipedia.org/wiki/Houses_at_l%27Estaque 62.Violin and Palette 小提琴与调色板 1909（Georges Braque, 乔治·布拉克）https://www.wikiart.org/en/georges-braque/violin-and-palette-1909 63.Still Life with Flowers 静物花卉 1912（Juan Gris, 胡安·格里斯）https://www.wikiart.org/en/juan-gris/still-life-with-flowers-1912 64.Ma Jolie 我的美人 1912（Pablo Picasso, 巴勃罗·毕加索）https://www.moma.org/collection/works/79051 65.Still-Life with Chair Caning有藤椅的静物 1912（Pablo Picasso, 巴勃罗·毕加索）http://www.pablo-ruiz-picasso.net/work-88.php 66.Fruit Dish and Glass 水果盘与玻璃杯 1912 （Georges Braque, 乔治·布拉克）https://en.wikipedia.org/wiki/Fruit_Dish_and_Glass 67.The Little Fourteen-Year-Old Dancer (French: La Petite Danseuse de Quatorze Ans) 小舞女 1880-1881 （Edgar Degas 埃德加·德加）https://en.wikipedia.org/wiki/Little_Dancer_of_Fourteen_Years 68.Guitar 吉他 1912（Pablo Picasso, 巴勃罗·毕加索）https://www.wikiart.org/en/pablo-picasso/guitar-1912 EIGHT69.Dynamism of a Dog on a Leash (Italian: Dinamismo di un cane al guinzaglio)拴着皮带的狗的动态 1912（Giacomo Balla, 贾科莫·巴拉）https://en.wikipedia.org/wiki/Dynamism_of_a_Dog_on_a_Leash 70.Unique Forms of Continuity in Space 空间中连续的唯一形体 1913（UmbertoBoccioni, 翁贝托·薄丘尼） https://en.wikipedia.org/wiki/Unique_Forms_of_Continuity_in_Space 71.States of Mind I: The Farewells 心境I 告别 1911 States of Mind II: Those Who Go 心境II 离开的人 1911 States of Mind III: Those Who Stay 心境III 留下的人 1911 （UmbertoBoccioni, 翁贝托·薄丘尼）https://www.wikiart.org/en/umberto-boccioni/states-of-mind-i-the-farewells-1911https://www.wikiart.org/en/umberto-boccioni/states-of-mind-ii-those-who-go-1911https://www.wikiart.org/en/umberto-boccioni/states-of-mind-iii-those-who-stay-1911-1 72.L’Équipe de Cardiff 加迪夫队 1913（Robert Delaunay, 罗伯特·德劳内）https://fr.wikipedia.org/wiki/L%27%C3%89quipe_de_Cardiff 73.Rock Drill 凿岩机 1913（Jacob Epstein, 雅各·爱泼斯坦）https://en.wikipedia.org/wiki/Rock_Drill_(Jacob_Epstein) NINE74.The First Step 第一步 1910（František Kupka, 弗朗齐歇克·库普卡）https://www.moma.org/collection/works/79969 75.Disque simultané（Simultaneous Disc）共时的圆盘 1912（Robert Delaunay, 罗伯特·德劳内）https://fr.wikipedia.org/wiki/Disque_simultan%C3%A9 76.München - Planegg I 慕尼黑-普拉内格 1 1901（Wassily Kandinsky, 瓦西里·康定斯基）https://www.akg-images.de/archive/Munchen-%25E2%2580%2593-Planegg-I-2UMDHUORFRFR.html 77.Murnau, Dorfstrasse (A Village Street) 穆尔瑙，乡村道路 1908 （Wassily Kandinsky, 瓦西里·康定斯基）https://commons.wikimedia.org/wiki/File:Vassily_Kandinsky,_1908,_Murnau,_Dorfstrasse.jpg 78.Kochel - Straight Road 科黑尔，笔直的路 1909（Wassily Kandinsky, 瓦西里·康定斯基）http://www.the-athenaeum.org/art/detail.php?ID=116422 79.Improvisation 4 即兴 4 1909（Wassily Kandinsky, 瓦西里·康定斯基）https://www.wikiart.org/en/wassily-kandinsky/improvisation-4-1909 80.Impression III (Concert) 印象3（音乐会） 1911 （Wassily Kandinsky, 瓦西里·康定斯基）https://www.wikiart.org/en/wassily-kandinsky/impression-iii-concert-1911 81.Picture with a Circle 带圆的画 1911 （Wassily Kandinsky, 瓦西里·康定斯基）http://www.wassilykandinsky.net/work-432.php 82.Composition IV 作曲 4 1911（Wassily Kandinsky, 瓦西里·康定斯基）https://www.wikiart.org/en/wassily-kandinsky/composition-iv-1911 83.Composition VII 作曲 7 1913（Wassily Kandinsky, 瓦西里·康定斯基）http://www.wassilykandinsky.net/work-36.php 84.Hammamet with mosque 哈马马特的清真寺 1914（Paul Klee, 保罗·克利）https://www.wikiart.org/en/paul-klee/hammamet-with-mosque-1914 TEN85.Cow And Violin 奶牛和小提琴 1913（Kazimir Malevich, 卡济米尔·马列维奇）http://russianartgallery.org/famous/malevich_cow.htm 86.Black Square 黑色正方形 1915 （Kazimir Malevich, 卡济米尔·马列维奇）https://en.wikipedia.org/wiki/Black_Square_(painting) 87.Suprematist Painting 至上主义 1915 （Kazimir Malevich, 卡济米尔·马列维奇）http://www.ibiblio.org/eldritch/el/mpix.html 88.Corner Counter-Relief 1914 角落的反浮雕（Vladimir Tatlin, 弗拉基米尔·塔特林）http://rusmuseumvrm.ru/data/collections/sculpture/20/tatlin_ve_uglovoy_kontrrelef_1914/index.php?lang=en 89.Monument to the Third International 第三国际的纪念塔 1919-1920（Vladimir Tatlin, 弗拉基米尔·塔特林） https://en.wikipedia.org/wiki/Tatlin%27s_Tower 90.Pure Red Color, Pure Yellow Color, Pure Blue Color 纯红、纯黄和纯蓝 1921（Alexander Rodchenko, 亚历山大·罗琴科） 91.Beat the Whites with the Red Wedge 以红锲攻打白军 1919（El Lissitzky, 埃尔·利西茨基）https://en.wikipedia.org/wiki/Beat_the_Whites_with_the_Red_Wedge ELEVEN92.Composition C (No.III) with Red, Yellow and Blue构成C（第 3号），红黄蓝 1935（Piet Mondrian, 皮埃特·蒙特里安）https://theartstack.com/artist/piet-mondrian/composition-c-no-iii-with-red-yellow-and-blue# 93.Evening; Red Tree 夜晚，红树 1908 （Piet Mondrian, 皮埃特·蒙特里安）https://en.wikipedia.org/wiki/Evening;_Red_Tree 94.Gray Tree 灰色的树 1912 （Piet Mondrian, 皮埃特·蒙特里安）https://en.wikipedia.org/wiki/Gray_Tree 95.Blossoming Apple Tree 开花的苹果树 1912 （Piet Mondrian, 皮埃特·蒙特里安）https://en.wikipedia.org/wiki/Evening;_Red_Tree#/media/File:Blossoming_apple_tree,_by_Piet_Mondriaan.jpg 96.Tableau No. 2/Composition No. VII 画面 2/构成 7 1913 （Piet Mondrian, 皮埃特·蒙特里安）https://theartstack.com/artist/piet-mondrian/tableau-no-2-compositio 97.Composition No VI 构成 6 1914 （Piet Mondrian, 皮埃特·蒙特里安） 98.Red and Blue Chair 红蓝椅 1923 （Gerrit Rietveld, 赫里特·里特费尔德）http://www.theartstory.org/movement-de-stijl-artworks.htm 99.Rietveld Schröder House 施罗德住宅 1924 （Gerrit Rietveld, 赫里特·里特费尔德）https://en.wikipedia.org/wiki/Rietveld_Schr%C3%B6der_House 100.Composition No.1 构成第一号 1920 （Piet Mondrian, 皮埃特·蒙特里安） TWELVE101.Wainwright Building 温赖特大厦 1891（ Dankmar Adler and Louis Sullivan, 阿德勒和路易斯·沙利文）https://en.wikipedia.org/wiki/Wainwright_Building 102.AEG turbine factory 通用电气涡轮机工厂 1909 （Peter Behrens, 彼特·贝伦斯）https://en.wikipedia.org/wiki/AEG_turbine_factory 103.Fagus Factory (German:Fagus-Werk）法古斯工厂 1911-1913 （ Walter Gropius and Adolf Meyer, 沃尔特·格罗佩斯，阿道夫·梅耶）https://en.wikipedia.org/wiki/Fagus_Factory 104.Self-Portrait as a Soldier 作为一个军人的自画像 1915（Ernst Ludwig Kirchner, 恩斯特·路德维希·凯尔希纳）https://www.wikiart.org/en/ernst-ludwig-kirchner/self-portrait-as-a-soldier-1915 105.Hot-Water Jug 1924（Marianne Brandt, 玛丽安·布兰德）https://www.moma.org/collection/works/2440 106.Table Lamp 华根菲尔德台灯 1924（Wilhelm Wagenfeld &amp; Carl Jakob Jucker, 威尔赫姆·华根菲尔德，卡尔·朱克）https://www.moma.org/collection/works/4056?locale=en 107.EM 1 (Telephone Picture) 电话图 EM1 1923 （László Moholy-Nagy, 莫霍利·纳吉）https://www.moma.org/collection/works/147626 108.NESTING TABLES 嵌套桌组 1927 （Josef Albers, 约瑟夫·亚伯斯）https://blog.timelesswroughtiron.com/2014/09/modern-history-bauhaus-nesting-tables/ 109.Wassily Chair 瓦西里椅 1925（Marcel Lajos Breuer, 马塞尔·布劳耶）https://en.wikipedia.org/wiki/Wassily_Chair 110.Barcelona Pavilion 巴塞罗那世博会德国馆 1929 （Ludwig Mies van der Rohe, 路德维希·密斯·凡德罗）https://en.wikipedia.org/wiki/Barcelona_Pavilion 111.Barcelona Chair 巴塞罗那椅 1929 （Ludwig Mies van der Rohe, 路德维希·密斯·凡德罗）https://www.moma.org/collection/works/4369?locale=en THIRTEEN112.La Nona Ora (The Ninth Hour) 第九时辰 1999（Maurizio Cattelan, 莫瑞吉奥·卡特兰）https://farticulate.wordpress.com/2010/10/21/la-nona-ora-the-ninth-hour-1999/ 113.Collage with Squares Arranged according to the Laws of Chance 根据随机法则排布的正方形的拼贴画 1916-1917 （Jean （Hans）Arp, 让·阿尔普（汉斯·阿尔普））https://www.moma.org/collection/works/37013?locale=en 114.Revolving 旋转 1919 （Kurt Schwitters, 库尔特·施维特斯）https://www.moma.org/collection/works/79211?locale=en 115.Merzbau 梅尔兹堡 1933 （Kurt Schwitters, 库尔特·施维特斯）https://www.moma.org/explore/inside_out/2012/07/09/in-search-of-lost-art-kurt-schwitterss-merzbau/ 116.3 Standard Stoppages 三个标准的终止 1913-1914（Marcel Duchamp, 马塞尔·杜尚）https://www.moma.org/collection/works/78990?locale=en 117.L.H.O.O.Q. 1919 （Marcel Duchamp, 马塞尔·杜尚）https://en.wikipedia.org/wiki/L.H.O.O.Q. 118.Beautiful Breath: Veil Water 美丽气息 1921 （Marcel Duchamp, 马塞尔·杜尚）http://www.toutfait.com/unmaking_the_museum/Belle%20Haleine.html","categories":[{"name":"备忘录","slug":"备忘录","permalink":"http://wenyiqingnian.xyz/categories/备忘录/"}],"tags":[{"name":"现代艺术150年","slug":"现代艺术150年","permalink":"http://wenyiqingnian.xyz/tags/现代艺术150年/"},{"name":"备忘录","slug":"备忘录","permalink":"http://wenyiqingnian.xyz/tags/备忘录/"}]},{"title":"深度学习1-反向传播","slug":"深度学习1-反向传播","date":"2018-06-08T09:33:50.000Z","updated":"2018-06-10T10:09:02.000Z","comments":true,"path":"2018/06/08/深度学习1-反向传播/","link":"","permalink":"http://wenyiqingnian.xyz/2018/06/08/深度学习1-反向传播/","excerpt":"","text":"机器学习算法中的数学思想一、 机器学习的过程是在学习什么以MNIST手写数字识别为例 MNIST是一个手写数字数据库，它是以一个28*28像素的图片以及一个对应的数字标签作为键值对的数据库。 为了更好的将这个识别过程数学化，先将输入的图形像素化，每一个数字图形可以按照各像素的明度值 转化为一个784个参数的列向量。[0.1,0.3,0.4 ...... 0.0,0.8] 其中每个向量值代表一个像素对应的明度值。假设学习模型为一个有两个隐藏层的全连接层。 可以看到 每个神经元与神经元之间都由一根线连接着，这根线其实指代的是两个神经元之间的关系，用数学方式来说，可以称之为 权重值。 我们希望找到每根线所代表的权重，当输入一个手写数字图片的时候，通过第一层的权重值，点亮部分第一个隐藏层的神经元【注1】 注释1： 可以假设 最后一层隐藏的神经元所代表的是类似人类识别数字那样，指代组成数字的一些笔画，比如说圆圈或者竖线，那么第一层隐藏的神经元可能指代的是 组成哪些笔画的更细微一些的笔画，比如一个左上角的圆弧，一个左下角的圆弧之类，但其实机器学习的过程并非我们想象的那样，每一层代表的可能是一些我们人类都看不懂的信息，我们称之为features，或者说是特征。为了更好理解机器学习的数学原理，我们暂且这么认为。 那么 拿最后输出层的一个神经元 a2 来说，它就等于上一层神经元与权重值的求和$sum = \\sum_j W_{i,j}x_j$但只求和是不行的，因为对于输出端 a2来说，它的值必须在[0,1]范围内，这里就要用到sigmoid() 压缩函数。【注2】 注2： sigmoid 函数 是一个压缩函数 $ S(x) = \\frac{1}{1+e_{-x}}$，sigmoid函数连续，光滑，严格单调，以(0,0.5)中心对称，是一个非常良好的阈值函数。当x趋近负无穷时，y趋近于0；趋近于正无穷时，y趋近于1；x=0时，y=0.5。当然，在x超出[-6,6]的范围后，函数值基本上没有变化，值非常接近，在应用中一般不考虑。 在机器学习中，常常使用sigmoid函数 将相似率控制在0-1 范围内。 当然，神经元的触发难易程度也不应该是一样的，我们在求和函数$sum = \\sum_j W_{i,j}x_j$中增加一个偏置值$ b_i$，用来控制神经元激活的难易程度。$sum = \\sum_j W_{i,j}x_j+b_i$那么 输出结果ai 就可以用公式表示为$ a_i = sigmoid（\\sum{w^{i-1}_j a_j^{l-1}+b_i}）$所谓机器学习，就是找到上述有着无比复杂参数（偏置b和权重w）的函数funa（），求出其正确的偏置和权重值,使得我们每次输入一个手写图片向量，该函数都能在最后点亮输出向量中的某个神经节点。所以： 机器学习的核心，就是使用合适的方法 去找到学习的数学模型里，所有的 偏置和 权重 反向传播这是机器学习的核心，就是找到一个合适的方法，去调整偏置和权重，使输出层的结果尽可能的与我们期望的结果一致。就以前面说到的识别mnist手写数字识别算法为例。当输入一个手写数字 2 的时候 当模型还未完全训练完毕，输入的结果和输出的结果看起来应该是没有什么关联的。 可以看到，尚未完成训练的模型，它的识别结果是很混乱的，同时点亮了好几个数字。 我们的期望： 是让数字2 对应的节点 值变得更大，让其他的节点 对应的结果值变得更小。同时 该变化应该和节点当前对应的值与期望值的差距成正比。 比如说 节点2 当前激活的值为0.2 我们期望的值是1，那么节点2变大 对于我们预测模型来说就比让节点8变为0要来的更重要，因为节点8 当前的数值0.2 已经和我们期望的0 差距不大了，而2对应的0.2 与我们当前期望的1差距显然要更大。 见下图： 我们知道，数字2 对应的值0.2 是将输入的748列向量的值，与对应的偏置和权重相乘之后求和，再通过sigmoid()函数 将其结果约束在[0,1]之间的 注： w0 w1 w2…. 为上一层（该例子中为第二个隐藏层）对应的每个神经元的权重，b为偏置向量。如果要让0.2（即节点2对应的输出）变大，有三个途径 增大权重wi 增大偏置b 修改ai的值 我们目前只关注如何修改权重 使得输出节点2 对应的结果变大。 可以看到上一个链接层对应的激活情况如图。如果我们要更改权重值， 那么1，6，7，9对应的神经节点的参数更改会更有意义，因为预测结果是上层神经元与权重乘积求和的，因为1678 对应的节点更亮，那么增大他们之间的权重值会更有意义。同样，如果如果我们更改节点的值，那么1，6，7，9对应的节点更应该增大，但现在我们无法更改节点值，只能通过更改权重和偏置的值来修改最终的计算结果。 这只是当只有一个输入的时候，输出结果告诉我们它对上个节点权重值变化的诉求，以这个例子为例，就代表当输入一个手写数字2 的时候，为了使输出结果更接近为2，结果神经元要求上一个隐藏层中 第 1，6，7，9对应的节点的权重应该更大，那么当吧全部训练数据输入进来的时候，所有的输出结果对上一个神经元 权重的诉求就都可以获取到了，那么将全部的诉求求和求均，就得到整个样本对该模型 第二个隐藏层 权重变化的诉求。 损失函数当学习模型尚未训练好，它给出的结果可以说是相当随机的，那么有必要告诉模型，当前的输出结果与预期结果偏差有多大。 这里便引申出损失函数的概念。 损失函数（loss function）是用来估量模型的预测值f(x)与真实值Y不一致的程度，它是一个非负实数值函数，通常使用L(Y,f(x))来表示，损失函数越小，模型稳健性越好。 在机器学习里 我们的损失函数一般是 预测结果和期望结果的平方差之和。我们训练模型，就是为了是损失函数最小。机器学习的损失函数可以表示为【注3】 参数解释：$a^j$：机器学习预测出的结果值$b^j$： 目标期望值$C_0$： 表示输入一个样本的损失值 其中 $a^j$ 又可以表示 上一层神经元与权重和偏置的加权和，我们记为z，对z进行sigmoid压缩得到的结果。 用公式可以表述如下： 那么 可以看到 最终的损失值$C_0$ 可以表示为 反向传播算法正向传播过程当我们输入随机的一组权重和偏置，以及一张手写数字数组之后，将其按照求和公式求和，可得到一组预测值。这叫正向传播 正向传播： 根据输入的一组数据，计算出输出值 反向传播 概念： 当计算出预测值之后，因为它必定跟我们的期望结果有偏差，所以就需要将偏差值计算出来，将偏差反向传播，计算每个权重的偏导值，然后以一定的步长更新权重，减小误差，这叫反向传播。 上面说过，我们判断上个神经元层与输出结果的神经元之间的权重变化，他们不仅与当前计算结果和预期结果的偏差相关（表现在数学上，就是输出向量与预期向量$y = [0,0,1,0,0,0,0,0,0]$ 之间的求和平均数），还与当前神经元的数值相关。 对于上文中 我们说过的损失函数C，机器学习的目的就是通过改变对应的偏置b和权重w 使该函数最小，那么我们只需要求出 损失函数对每一个偏置和每一个权重的偏导数即可，知道了偏导数，我们就知道权重应该以什么样的方式，以多大的数量，增加还是减少，来影响最终的预测结果从而是损失函数降低到最小。一般的处理是，算出权重的梯度值之后，如果梯度为正，就意味着这里涉及到梯度下降算法的一些知识，可以详细的看一下梯度下降的维基百科，讲的很好 剩下的就是求偏导数的知识了，$C_0$ 对$ w_{l}^j$ 的敏感度，也就是偏导数，根据链式法则，可以求得为： 其中 每一项，抛去数学含义，它都是代表了一定意义的 $C_0$ 对$a_j^{L}$ 的偏导数： 因为平方差函数（损失函数c0）的偏导数斜率一般为正，所以该函数意味着 目标函数与预测函数之间的差距越大，偏置w的改变对该偏差值的影响就越大，与上文所讲的吻合，就是预测值和期望值之间的差距，也会对权重的改变产生影响。偏差越大的，他们的权重改变对偏差值的影响会更大。（就是改变这些偏差大的神经元他们链接的权重会更有性价比一些） a对z求导：就是你所选的非线性激活函数对z的偏导数 $z^{L}j$对$w{jk}^{L}$ 的偏导数： 偏导结果其实是$f(a^{L-1})$ ，意味着 L层的权重$w^{L}_{jk}$ 对偏差值的影响 受到它上一层的神经元的影响。也就是一同激活的神经元联系在一起这句话的由来 说到这里，我们有必要看一下 $C_0$ 对$a_j^{L-1}$（L1层的神经元）的敏偏导数。这是理解反向传播算法的核心虽然上文说过 我们无法改变$a_{L-1}$层神经元的值，只能改变他们的权重和偏置，但是看一下 $a^(L-1)$ 与$z^{L-1}$ 、$w^{L-1}$、$a^{L-2}$ 、$b^{L-1}$是直接相关联的，那么如果知道$C_0$ 对$a_j^{L-1}$的偏导数，那么反过来用求导公式 （将公式中的L 替换为L-1，同时左边的移动到右边，也就知道了代价函数对之前偏置和权重的偏导数了。对上一层神经元的的偏导数： 这里也可以看出，上一层神经元对代价函数的影响是同时通过下一层神经元的共同作用而影响的（因为偏导数是下一层神经元的偏导数乘积之和 ） 将上式展开，可得偏差函数对L层每一个权重的偏导数为： 当求出$w_jk^{(L)}$的偏导数，下一步只需要采用合适的最优化方法，更新该偏导数的值，就可以使误差逐步减小。 关于反向传播算法的具体例子，可以参考这篇博客，以具体的例子展示了反向传播的过程中 权重值是如何变化的。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://wenyiqingnian.xyz/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://wenyiqingnian.xyz/tags/机器学习/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://wenyiqingnian.xyz/tags/Tensorflow/"}]},{"title":"《现代艺术150年》未影印作品1","slug":"《现代艺术150年》未影印作品1","date":"2018-06-02T14:00:50.000Z","updated":"2018-06-17T06:35:07.000Z","comments":true,"path":"2018/06/02/《现代艺术150年》未影印作品1/","link":"","permalink":"http://wenyiqingnian.xyz/2018/06/02/《现代艺术150年》未影印作品1/","excerpt":"","text":"以书中提到的艺术品先后为时序，罗列出书中未影印出的作品。 ZERO1.Equivalent VIII 等价物 8 1966 （ Carl Andre 卡尔·安德烈） http://www.tate.org.uk/art/artworks/andre-equivalent-viii-t01534 2.Puppy 小狗 1992 （Jeff Koons，杰夫·昆斯） https://www.guggenheim.org/artwork/48 ONE3.Fountain 泉 1917 （Marcel Duchamp, 马塞尔·杜尚）https://en.wikipedia.org/wiki/Fountain_(Duchamp) TWO4.睡莲 Reflections of Clouds on the Water-Lily Pond，1920 （Claude Monet 克劳德·莫奈）https://en.wikipedia.org/wiki/Water_Lilies_(Monet_series) 5.The Dance Class (La Classe de Danse) 舞蹈课 1874（Edgar Degas 埃德加·德加）https://en.wikipedia.org/wiki/The_Ballet_Class_(Degas,_Mus%C3%A9e_d%27Orsay) 6.Hoar Frost, the Old Road to Ennery 白霜，通往埃纳里的老路 1873（Camille Pissarro , 米耶·毕沙罗）https://artbookannex.com/tag/ennery/ 7.The Raft of the Medusa 美杜莎之筏 1818-1819（Théodore Géricault, 泰奥多尔·席里柯）https://en.wikipedia.org/wiki/The_Raft_of_the_Medusa 8.Liberty Leading the People 自由引导人民 1830 （Eugène Delacroix, 欧仁·德拉克罗瓦）https://en.wikipedia.org/wiki/Liberty_Leading_the_People 9.L’Origine du monde (“The Origin of the World”) 世界的起源 1866 （Gustave Courbet, 古斯塔夫·库尔贝 ）https://en.wikipedia.org/wiki/L%27Origine_du_monde 10.The Absinthe Drinker (French: Le Buveur d’absinthe) 喝苦艾酒的人 1859 （Édouard Manet, 爱德华·马奈）https://en.wikipedia.org/wiki/The_Absinthe_Drinker_(Manet_painting) 11.Le Déjeuner sur l’herbe (English: The Luncheon on the Grass) 草地上的午餐 1863 （Édouard Manet, 爱德华·马奈）https://en.wikipedia.org/wiki/Le_D%C3%A9jeuner_sur_l%E2%80%99herbe 12.Olympia 奥林匹亚 1863 （Édouard Manet, 爱德华·马奈）https://en.wikipedia.org/wiki/Olympia_(Manet) THREE13.Impression, Sunrise (French: Impression, soleil levant) 1872（Claude Monet 克劳德·莫奈） https://en.wikipedia.org/wiki/Impression,_Sunrise 14.A Modern Olympia 现代奥林匹亚 1870（Paul Cézanne, 保罗·塞尚）http://www.paulcezanne.org/a-modern-olympia.jsp#prettyPhoto 15.Bain à la Grenouillère 青蛙塘 1869 （Claude Monet 克劳德·莫奈）https://en.wikipedia.org/wiki/Bain_%C3%A0_la_Grenouill%C3%A8re 16.La Grenouillère 青蛙塘 1869 （Pierre-Auguste Renoir, 皮埃尔-奥古斯特·雷诺阿）https://en.wikipedia.org/wiki/Pierre-Auguste_Renoir 17.Rain, Steam and Speed – The Great Western Railway 雨、蒸汽和速度 1844 （ J. M. W. Turner, J.M.W 特纳）https://en.wikipedia.org/wiki/Rain,_Steam_and_Speed_%E2%80%93_The_Great_Western_Railway 18.The Thames below Westminster 威斯敏斯特下的泰晤士河 1871 （Claude Monet 克劳德·莫奈）https://artuk.org/discover/artworks/the-thames-below-westminster-115865 19.神奈川沖浪裏 The Great Wave off Kanagawa 神奈川巨浪 1829-1833 （葛飾北斎，Katsushika Hokusai, 葛饰北斋）https://en.wikipedia.org/wiki/The_Great_Wave_off_Kanagawa 20.大津駅 Station of Otsu 大津站 1840（安藤 広重, Ando Hiroshige, 安藤广重（后改名 歌川 広重, Utagawa Hiroshige, 歌川广重））https://www.metmuseum.org/toah/works-of-art/JP804/ 21.A Carriage at The Races 赛马场上的马车 1870 （Edgar Degas 埃德加·德加）https://www.wikiart.org/en/edgar-degas/a-carriage-at-the-races-1872 FOUR22.The Potato Eaters 吃土豆的人 1885（Vincent Willem van Gogh, 文森特·梵高）https://en.wikipedia.org/wiki/The_Potato_Eaters 23.The Yellow House 黄房子 1888 （Vincent Willem van Gogh, 文森特·梵高）https://en.wikipedia.org/wiki/The_Yellow_House 24.Still Life With a Plate of Onions 静物：一盘洋葱 1889 （Vincent Willem van Gogh, 文森特·梵高）https://commons.wikimedia.org/wiki/File:Still_life_with_a_plate_of_onions.jpg 25.The Sower 播种者 1888（Vincent Willem van Gogh, 文森特·梵高）https://en.wikipedia.org/wiki/Vincent_van_Gogh#/media/File:The_Sower.jpg 26.The Night Café 夜间咖啡馆 1888（Vincent Willem van Gogh, 文森特·梵高）https://en.wikipedia.org/wiki/The_Night_Caf%C3%A9 27.Sunflowers 向日葵 1888（Vincent Willem van Gogh, 文森特·梵高）https://en.wikipedia.org/wiki/Sunflowers_(Van_Gogh_series) 28.Starry Night Over the Rhône 满天星斗下的罗纳河 1888 （Vincent Willem van Gogh, 文森特·梵高）https://en.wikipedia.org/wiki/Starry_Night_Over_the_Rh%C3%B4ne 29.Bedroom in Arles 寝室 1888（Vincent Willem van Gogh, 文森特·梵高）https://en.wikipedia.org/wiki/Bedroom_in_Arles 30.The Scream 呐喊 1893 （Edvard Munch, 爱德华·蒙克）https://en.wikipedia.org/wiki/The_Scream 31.Study after Velázquez’s Portrait of Pope Innocent X 临摹委拉斯开兹的《教皇英诺森十世肖像》1953（Francis Bacon, 弗朗西斯·培根）https://en.wikipedia.org/wiki/Study_after_Vel%C3%A1zquez%27s_Portrait_of_Pope_Innocent_X 32.Homage to Van Gogh 向梵高致敬 1960 （Francis Bacon, 弗朗西斯·培根）https://www.artimage.org.uk/3087/francis-bacon/homage-to-van-gogh--1960 33.Painter on the Road to Tarascon, August 1888 (destroyed by fire in the Second World War) 去往塔拉斯孔路上的画家 1888 （Vincent Willem van Gogh, 文森特·梵高）https://en.wikipedia.org/wiki/Vincent_van_Gogh#/media/File:Vincent_Van_Gogh_0013.jpg 34.Vision after the Sermon (Jacob Wrestling with the Angel) 布道后的幻象（雅各与天使搏斗） 1888（Paul Gauguin, 保罗·高更）https://en.wikipedia.org/wiki/Vision_After_the_Sermon 35.No te aha oe riri (Why Are You Angry?), 你为何生气 1896（Paul Gauguin, 保罗·高更）http://www.artic.edu/aic/collections/artwork/16496 36.Bathers at Asnières (French: Une Baignade, Asnières) 阿尼埃尔的浴场 1884（Georges Seurat, 乔治·修拉）https://en.wikipedia.org/wiki/Bathers_at_Asni%C3%A8res 37.A Sunday Afternoon on the Island of La Grande Jatte 大碗岛的星期天下午 1884-1886（Georges Seurat, 乔治·修拉）https://en.wikipedia.org/wiki/A_Sunday_Afternoon_on_the_Island_of_La_Grande_Jatte FIVE38.Still Life with Apples and Peaches 有苹果和桃子的静物 1905（Paul Cézanne, 保罗·塞尚）https://www.nga.gov/Collection/art-object-page.45986.html 39.Mont Sainte-Victoire with Large Pine 圣维克多山 1887 （Paul Cézanne, 保罗·塞尚）https://en.wikipedia.org/wiki/Mont_Sainte-Victoire_with_Large_Pine SIX40.The Kiss 吻 1907-1908 （Gustav Klimt, 古斯塔夫·克里姆特）https://en.wikipedia.org/wiki/The_Kiss_(Klimt) 41.Boats in the Harbour at Collioure 科利乌尔港的船 1905 （André Derain, 安德烈·德兰） 42.Restaurant de la Machine at Bougival 布吉瓦尔的餐馆 1905（Maurice de Vlaminck, 莫里斯·德·弗拉芒克） 43.Woman with a Hat 戴帽子的妇人 1905 （Henri Matisse, 亨利·马蒂斯）https://en.wikipedia.org/wiki/Woman_with_a_Hat 44.Le bonheur de vivre (The Joy of Life) 生之欢乐 1905-1906 （Henri Matisse, 亨利·马蒂斯）https://en.wikipedia.org/wiki/Le_bonheur_de_vivre 45.Reciproco Amore 互爱 1589-1595（Agostino Carracci, 阿戈斯蒂诺·卡拉奇） 46.Portrait of Gertrude Stein 格特鲁德·斯泰因肖像 1905-1906 （Pablo Picasso, 巴勃罗·毕加索）https://en.wikipedia.org/wiki/Portrait_of_Gertrude_Stein 47.Les Demoiselles d’Avignon (The Young Ladies of Avignon, and originally titled The Brothel of Avignon) 亚维农少女 1907 （Pablo Picasso, 巴勃罗·毕加索）https://en.wikipedia.org/wiki/Les_Demoiselles_d%27Avignon 48.A Carnival Evening 狂欢节之夜 1886（Henri Rousseau, 亨利·卢梭） 49.The Hungry Lion Throws Itself on the Antelope (Le lion ayant faim se jette sur l’antilope) 饿狮猛扑羚羊 1905（Henri Rousseau, 亨利·卢梭）https://en.wikipedia.org/wiki/The_Hungry_Lion_Throws_Itself_on_the_Antelope Portrait of a Woman 一个女人的肖像 1895 （Henri Rousseau, 亨利·卢梭）https://commons.wikimedia.org/wiki/File:Henri_Rousseau__Portrait_of_a_Woman_(1895).jpg","categories":[{"name":"备忘录","slug":"备忘录","permalink":"http://wenyiqingnian.xyz/categories/备忘录/"}],"tags":[{"name":"现代艺术150年","slug":"现代艺术150年","permalink":"http://wenyiqingnian.xyz/tags/现代艺术150年/"},{"name":"备忘录","slug":"备忘录","permalink":"http://wenyiqingnian.xyz/tags/备忘录/"}]},{"title":"从驱动角度理解binder","slug":"从驱动角度理解binder","date":"2018-06-02T11:00:50.000Z","updated":"2018-06-25T04:26:04.000Z","comments":true,"path":"2018/06/02/从驱动角度理解binder/","link":"","permalink":"http://wenyiqingnian.xyz/2018/06/02/从驱动角度理解binder/","excerpt":"","text":"一次binder通讯建立的大致流程我们已经了解了，首先是要注册一个serviceManager，server端创建实名binder，向smg注册自己可以提供的服务，以及该实名binder的标签，smg会在svcinfo 链表中缓存该server提供的binder信息，当client需要使用该服务时，只需要向smg中查询服务，获取server端binder的引用就可以了，这其中所有的通讯细节，全部需要binder驱动来实现。 本文主要总结一下对binder驱动的理解，了解驱动设计的细节，以及binder通讯过程中驱动主要做了哪些事情。 Binder驱动的定义Binder驱动其实是一种特殊的字符型驱动，实现方式类似硬件驱动，工作在内核态。如果了解过linux驱动相关知识，应该知道file_operations 结构体的重要性，linux 使用该结构体访问驱动程序的函数，这个结构体的每一个成员的名字都对应一个内核调用。当用户进程利用设备文件（binder对应的设备文件为/dev/test）对文件进行类似read()/write() 操作的时候，系统调用通过设备文件的主设备号找到对应的设备驱动程序，每一个驱动程序在内核中是由一个cdev结构体描述，cdev结构体中又包括一个成员fops结构体，fops便是file_operations类型的，然后读取file_operations 结构体相应的函数指针，接着把控制权交给该函数的linux 设备驱动程序工作。 下面以binder驱动在内核中的注册流程来分析binder驱动为用户空间定义了哪些可用来调用的函数。 注册Binder 在binder驱动源码中（kernel/drivers/staging/android/binder.c），通过调用 ret = misc_register(&amp;binder_msicdev)函数完成向内核注册binder驱动，主设备号为10，次设备号动态分配， 其中传入的参数便是一个miscdev的结构体， 它的定义如下 12345static struct miscdevice binder_miscdev = &#123; .minor = MISC_DYNAMIC_MINOR, .name = \"binder\", .fops = &amp;binder_fops&#125;; 可以看到cdev文件中标注了binder设备的设备名”binder”，以及fops结构体，fops结构体如下： 123456789static const struct file_operations binder_fops = &#123; .owner = THIS_MODULE, .poll = binder_poll, .unlocked_ioctl = binder_ioctl, .mmap = binder_mmap, .open = binder_open, .flush = binder_flush, .release = binder_release,&#125;; 可以看到binder驱动为应用层提供了open(),mmap(),poll(),ioctl()等标准的文件操作【注1】，open()负责打开驱动，mmap()负责对binder做内核空间向用户空间的地址映射，ioctl()负责binder协议的通信。 我们知道，用户态的引用程序调用kernel驱动程序是会陷入内核态的，进行系统调用，比如我使用 fd = open(&quot;dev/binder&quot;,O_RDWR)，开打开binder驱动时，它会先通过通过系统调用_open()【注1】，通过主次设备号来找到对应的binder驱动程序，即在 cdev 链表中找到binder驱动对应的binder_miscdev，找到 binder_fops结构体，找到open()方法对应的 binder_open()函数，实际执行到的便是binder_open（）函数。那么其他的 比如 mmap(),ioctl()方法，他们的执行流程也是类似的。 参考下图 注释1： open()为用户空间的方法，_open()为系统调用中对应的处理方法。 打开一次binder通讯，大致分为以下流程： 1 调用open()方法打开binder驱动 2 调用 mmap()方法申请一块内存用来接受通信中的数据，并进行内存映射（binder机制为什么只进行一次拷贝，这里有文章）， 3 调用 ioctl()方法 开启binder通讯。这里每一步中具体都做了些什么，下文会有详细描述，但为了更好理解，需要先要搞清楚binder驱动中的几个关键的数据结构和binder的通讯协议。 Binder驱动中的结构体驱动中的结构体分为两部分，一部分与用户空间共用，这些结构体在Binder通信协议中会用到，被定义在binder.h 头文件中。具体内容见下表： 结构体名 说明 flat_binder_object binder通讯过程中在client-binderDriver-server之间传递的实际内容，所谓跨进程传递的binder对象，其实传递的就是这个 binder_wirte_read 存储对binder驱动进行读写操作的数据，当为写的时候，结构体中的write_size非空，当为读的时候，read_size不为空 binder_version 存储binder的版本号 transaction_flags 描述一次binder事务的flag，比如是同步还是异步请求 binder_transcation_data 存储一次事务的数据 binder_handle_cookie 包含一个句柄和一个cookie binder_ptr_cookie 包含一个指针和一个cookie binder_pri_dest 暂未用到 binder_pri_ptr_cookie 暂未用到 另一部分定义在binder驱动中，是驱动特有的结构体 结构体名 描述 binder_node 描述binder的实体节点，对应一个server，当server通过binder驱动向smg注册时，binder驱动便会在内核中为其创建一个binder实体节点，该实体节点即为binder_node，同时驱动会为server与该节点创建引用关系 binder_ref 描述对binder实体节点的引用 binder_buffer 描述binder通讯过程中存储数据的buffer binder_proc 描述使用binder的进程 binder_thread 描述使用binder的线程 binder_work 描述通信过程中的一项任务 binder_transcation 描述一次事务的相关信息 binder_deferred_state 藐视延迟任务 binder_ref_death 描述binder实体的死亡信息 binder_transcation_log debugfs 日志 binder_transcation_log_entry debugfs 日志条目 binder协议Binder协议 可以分为 控制协议和驱动协议两部分。 1.控制协议控制协议是进程(client 或server端)通过系统调用（syscall）直接操作binder设备文件，使用ioctl(&#39;dev/binder&#39;)控制binder驱动的协议，该协议包含以下几种命令 命令 含义 参数 BINDER_WRITE_READ 该命令想binder写入或者读出数据，参数分为两段，写和度部分，如果write_size不为零，就先将write_buffer中的数据写入binder； 如果read_size不为零，就先从binder中取出数据，写入read_buffer中。 write_consumed和read_consumed 表示操作完成时驱动实际写入和读出的数据个数。 struct binder_wirte_read{ Singned long write_size;Signed long write_consumed;unsigend long write_buffer;signed long read_size;signed long read_consumed;Unsigned long read_buffer} BINDER_SET_MAX_THREADS 告知binder驱动接收方(server端)，线程池中最大的线程数。（详见下文 驱动线程管理） int max_threads BINDER_SET_CONEXT_MGR 将当前进程注册为smg，系统同时只可以出现一个smg，只要当前smg没有调用close关闭binder驱动，就不可能有别的进程可以成为smg BINDER_THREAD_EXIT 通知binder驱动当前线程退出了，binder会为所有参与binder通信的线程（包括server端线程池中的线程以及client端发出请求的线程）建立相应的数据结构，这些线程在退出时必须显示通知binder释放相应的数据。详见下文 binder驱动的线程控制 2. 驱动协议驱动协议根据具体使用过程，又分为发送和返回协议。发送协议 定义在binder.c 中的 1enum binder_driver_command_protocol ，返回协议 定义在1enum binder_driver_return_protocol 根据协议不同，存放的位置也不相同。驱动协议都是封装在控制协议 BINDER_WRITE_READ 命令参数 binder_wirte_read 结构体中，根据发送和返回类型，分别存放在 write_buffer和 read_buffer域所指向的内存空间中。binder_write_read结构体的数据结构见下图： 它们的数据格式都是命令 + 数据 的格式，多条命令可以连续存放。数据紧接着放在命令的后面，根据命令不同，执行的操作也不同。 发送协议： 命令 说明 参数 BC_TRANSCATION binder事务，client对server的请求 binder_transction_data BC_REPLAY 事务的回答，server对client的回复 Binder_transctin_data BC_FREE_BUFFER 通知驱动释放buffer Binder_uinptr_t BC_ACQUIRE 强引用计数+1 _u32 BC_RELEASE 强引用计数-1 _u32 BC_INCREFS 弱引用计数+1 _u32 BC_DECREFS 弱引用计数-1 _u32 BC_ACQUIRE_DODE acquire指令的回复 Binder_ptr_cookie BC_INCREFS_DONE increfs指令的回复 Binder_prt_cookie BC_ENTER_LOOPER 通知驱动主线程ready Void BC_REGISTER_LOOPER 通知驱动子线程ready Void BC_EXIT_LOOPER 通知驱动线程已退出 Void BC_REQUEST_DEATH_NOTIFICATION 请求接受死亡通知 Binder_handle_cookie BC_CLEAR_DEATH_NOTIFICATION 去除接受死亡通知 Binder_handle_cookie BC_DEAD_BINDER_DONE 已经处理完死亡通知 Binder_uinptr_t BC_ATTEMPT_ACQUIRE 暂未实现 - BC_ACQUIRE_RESULT 暂为实现 - 返回协议： 命令 说明 参数 BR_OK 操作完成 void BR_NOOP 操作完成 void BR_ERROR 发生错误 _s32 BR_TRANSCATION 进程收到一次binder请求 （server端） binder_transcation_data BR_REPLAY 进程收到binder请求的回复（client） binder_transtaction_data BR_TRANSCATION_COMPLETED 驱动对于接收请求的确认回复 void BR_FAILED_REPLAY 告知发送方 通信目标不存在 void BR_SPAWN_LOOPER 通server端创建一个新的进程 void BR_ACQUIRE 强用用计数+1 Binder_prt_cookie BR_RELEASE 强引用计数-1 Binder_prt_cookie BR_INCREFS 弱引用计数+1 Binder_prt_cookie BR_DECREFS 弱引用计数-1 Binder_prt_cookie BR_DEAD_BINDER 发送死亡通知 binder_uintptr_t BR_CLEAR_DEATH_NOTIFICATION_DONE 清除死亡通知完成 binder_uintptr_t BR_DEAD_REPLAY 改制发送方对方已死亡 void BR_ATTEMPT_ACQUIRE 暂未实现 - BR_ACQUIRE_RESULT 暂为实现 - BR_FINISHED 暂未实现 - binder 请求的过程见下图： 通过上面的Binder协议的说明中我们看到，Binder协议的通信过程中，不仅仅是发送请求和接受数据这些命令。同时包括了对于引用计数的管理和对于死亡通知的管理（告知一方，通讯的另外一方已经死亡）等功能。 这些功能的通信过程和上面这幅图是类似的：一方发送BC_XXX，然后由驱动控制通信过程，接着发送对应的BR_XXX命令给通信的另外一方。因为这种相似性，对于这些内容就不再赘述了。 由驱动角度理解 Binder通讯建立的过程1 打开驱动（open(“dev/binder”)）任何进程在使用Binder之前，都需要先通过open(&quot;/dev/binder&quot;)打开Binder设备。上文已经提到，用户空间的open系统调用对应了驱动中的binder_open函数。在这个函数，Binder驱动会为调用的进程做一些初始化工作。binder_open函数代码如下所示 1234567891011121314151617181920212223242526272829static int binder_open(struct inode *nodp, struct file *filp)&#123; struct binder_proc *proc; // 创建进程对应的binder_proc对象 proc = kzalloc(sizeof(*proc), GFP_KERNEL); if (proc == NULL) return -ENOMEM; get_task_struct(current); proc-&gt;tsk = current; // 初始化binder_proc INIT_LIST_HEAD(&amp;proc-&gt;todo); init_waitqueue_head(&amp;proc-&gt;wait); proc-&gt;default_priority = task_nice(current); // 锁保护 binder_lock(__func__); binder_stats_created(BINDER_STAT_PROC); // 添加到全局列表binder_procs中 hlist_add_head(&amp;proc-&gt;proc_node, &amp;binder_procs); proc-&gt;pid = current-&gt;group_leader-&gt;pid; INIT_LIST_HEAD(&amp;proc-&gt;delivered_death); filp-&gt;private_data = proc; binder_unlock(__func__); return 0;&#125; 可以看到，在打开binder驱动时，binder_procs会将所有打开binder驱动的进程加入到该列表中，上文中提到binder中的几个主要结构体，其实都是通过binder_procs结构体链接在一起的。 2. 创建内存空间并实现用户空间 内核空间的映射（mmap）打开binder驱动之后，进程会通过mmap()方法进行内存空间的映射。 上文描述过，mmap()对应的binder_mmap()函数，它会先申请一份物理内存，默认PAGE_SIZE 是4k，然后会同时在 用户空间和 内核空间映射该物理内存。当client 发送数据给server的时候，只需要将client端的数据，拷贝到server端所指向的 内核中的地址即可，因为server的用户空间和binder对应的内核空间映射的是同一份物理内存，当server取数据的时候，就无需再从内科中拷贝了，server可以直接使用。 这幅图的说明如下： Server在启动之后，对/dev/binder设备调用mmap内核中的binder_mmap函数进行对应的处理：申请一块物理内存，然后在用户空间和内核空间同时进行映射 Client通过BINDER_WRITE_READ命令发送请求，这个请求将先到驱动中，同时需要将数据从Client进程的用户空间拷贝到内核空间驱动通过BR_TRANSACTION通知Server有人发出请求，Server进行处理。由于这块内存也在用户空间进行了映射，因此Server进程的代码可以直接访问 3. 内存管理（非重点）上文中，我们看到binder_mmap的时候，会申请一个PAGE_SIZE通常是4K的内存。而实际使用过程中，一个PAGE_SIZE的大小通常是不够的。 在驱动中，会根据实际的使用情况进行内存的分配。有内存的分配，当然也需要内存的释放。这里我们就来看看Binder驱动中是如何进行内存的管理的。 首先，我们还是从一次IPC请求说起。 当一个Client想要对Server发出请求时，它首先将请求发送到Binder设备上，由Binder驱动根据请求的信息找到对应的目标节点，然后将请求数据传递过去。 进程通过ioctl系统调用来发出请求：ioctl(mProcess-&gt;mDriverFD, BINDER_WRITE_READ, &amp;bwr) PS：这行代码来自于Framework层的IPCThreadState类。在后文中，我们将看到，IPCThreadState类专门负责与驱动进行通信。 这里的mProcess-&gt;mDriverFD对应了打开Binder设备时的fd。BINDER_WRITE_READ对应了具体要做的操作码，这个操作码将由Binder驱动解析。bwr存储了请求数据，其类型是binder_write_read。 binder_write_read其实是一个相对外层的数据结构，其内部会包含一个binder_transaction_data结构的数据。binder_transaction_data包含了发出请求者的标识，请求的目标对象以及请求所需要的参数。它们的关系如下图所示： binder_ioctl函数对应了ioctl系统调用的处理。这个函数的逻辑比较简单，就是根据ioctl的命令来确定进一步处理的逻辑，具体如下: 如果命令是BINDER_WRITE_READ，并且如果 bwr.write_size &gt; 0，则调用binder_thread_write该方法用于处理Binder协议中的请求码。当binder_buffer存在数据，binder线程的写操作循环执行。对于请求码为BC_TRANSACTION或BC_REPLY时，会执行binder_transaction()方法，这是最为频繁的操作。 对于其他命令则不同。 如果 bwr.read_size &gt; 0，则调用binder_thread_read，该方法用以处理响应过程，根据不同的binder_work-&gt;type以及不同状态，生成相应的响应码。 如果命令是BINDER_SET_MAX_THREADS，则设置进程的max_threads，即进程支持的最大线程数如果命令是BINDER_SET_CONTEXT_MGR，则设置当前进程为ServiceManager，见下文如果命令是BINDER_THREAD_EXIT，则调用binder_free_thread，释放binder_thread如果命令是BINDER_VERSION，则返回当前的Binder版本号这其中，最关键的就是binder_thread_write方法。当Client请求Server的时候，便会发送一个BINDER_WRITE_READ命令，同时框架会将将实际的数据包装好。此时，binder_transaction_data中的code将是BC_TRANSACTION，由此便会调用到binder_transaction方法，这个方法是对一次Binder事务的处理，这其中会调用binder_alloc_buf函数为此次事务申请一个缓存。调用关系见下图 binder_update_page_range这个函数在上文中，我们已经看到过了。其作用就是：进行内存分配并且完成内存的映射。而binder_alloc_buf函数，正如其名称那样的：完成缓存的分配。 在驱动中，通过binder_buffer结构体描述缓存。一次Binder事务就会对应一个binder_buffer，进程在mmap时，会设定支持的总缓存大小的上限。而进程每当收到BC_TRANSACTION，就会判断已使用缓存加本次申请的和有没有超过上限。如果没有，就考虑进行内存的分配。 进程的空闲缓存记录在binder_proc的free_buffers中，这是一个以红黑树形式存储的结构。每次尝试分配缓存的时候，会从这里面按大小顺序进行查找，找到最接近需要的一块缓存。找到之后，还要对binder_proc的字段进行更新。 BC_FREE_BUFFER命令是通知驱动进行内存的释放，binder_free_buf函数是真正实现的逻辑，这个函数与binder_alloc_buf是刚好对应的。在这个函数中，所做的事情包括： 重新计算进程的空闲缓存大小 通过binder_update_page_range释放内存 更新binder_proc的buffers，free_buffers，allocated_buffers字段 4 通讯过程BINDER_COMMAND_PROTOCOL：binder请求码，以”BC_“开头，简称BC码，用于从IPC层传递到Binder Driver层；BINDER_RETURN_PROTOCOL ：binder响应码，以”BR_“开头，简称BR码，用于从Binder Driver层传递到IPC层； 一次完整的binder通讯流程：Binder IPC通信至少是两个进程的交互： client进程执行binder_thread_write，thread_write根据BC_XXX命令，生成相应的binder_work； server进程执行binder_thread_read，thread_read根据binder_work.type类型，生成BR_XXX，发送到用户空间处理。 binder_work.type ：123456BINDER_WORK_TRANSACTION //最常见类型BINDER_WORK_TRANSACTION_COMPLETEBINDER_WORK_NODEBINDER_WORK_DEAD_BINDERBINDER_WORK_DEAD_BINDER_AND_CLEARBINDER_WORK_CLEAR_DEATH_NOTIFICATION 可以知道，上述通信流程涉及到三种状态码的转换：BR_CODE BC_CODE BW_CODE,他们之间的转换图如下： 图解：(以BC_TRANSACTION为例) 发起端进程：binder_transaction()过程将BC_TRANSACTION转换为BW_TRANSACTION；接收端进程：binder_thread_read()过程，将BW_TRANSACTION转换为BR_TRANSACTION;接收端进程：IPC.execute()过程，处理BR_TRANSACTION命令 以gityuan的一张图来总结binder通信的全过程 5 通讯过程中 binder实体的传递Binder机制淡化了进程的边界，使得跨越进程也能够调用到指定服务的方法，其原因是因为Binder机制在底层处理了在进程间的“对象”传递。 在Binder驱动中，并不是真的将对象在进程间来回序列化，而是通过特定的标识来进行对象的传递。Binder驱动中，通过flat_binder_object来描述需要跨越进程传递的对象。其定义如下：12345678910struct flat_binder_object &#123; __u32 type; __u32 flags; union &#123; binder_uintptr_t binder; /* local object */ __u32 handle; /* remote object */ &#125;; binder_uintptr_t cookie;&#125;; 这其中，type有如下5种类型。1234567enum &#123; BINDER_TYPE_BINDER = B_PACK_CHARS('s', 'b', '*', B_TYPE_LARGE), BINDER_TYPE_WEAK_BINDER = B_PACK_CHARS('w', 'b', '*', B_TYPE_LARGE), BINDER_TYPE_HANDLE = B_PACK_CHARS('s', 'h', '*', B_TYPE_LARGE), BINDER_TYPE_WEAK_HANDLE = B_PACK_CHARS('w', 'h', '*', B_TYPE_LARGE), BINDER_TYPE_FD = B_PACK_CHARS('f', 'd', '*', B_TYPE_LARGE),&#125;; 当对象传递到Binder驱动中的时候，由驱动来进行翻译和解释，然后传递到接收的进程。 例如当Server把Binder实体传递给Client时，在发送数据流中，flat_binder_object中的type是BINDER_TYPE_BINDER，同时binder字段指向Server进程用户空间地址。但这个地址对于Client进程是没有意义的（Linux中，每个进程的地址空间是互相隔离的），驱动必须对数据流中的flat_binder_object做相应的翻译：将type该成BINDER_TYPE_HANDLE；为这个Binder在接收进程中创建位于内核中的引用并将引用号填入handle中。对于发生数据流中引用类型的Binder也要做同样转换。经过处理后接收进程从数据流中取得的Binder引用才是有效的，才可以将其填入数据包binder_transaction_data的target.handle域，向Binder实体发送请求。图 binder对象索引和映射关系flat_binder_object就是进程间传递的Binder对象，每一个flat_binder_object对象内核都有一个唯一的binder_node对象，这个对象挂接在binder_proc的一颗二叉树上。对于一个binder_node对象，内核也会有一个唯一的binder_ref对象，可以这么理解，binder_ref的desc唯一的映射到binder_node的ptr和cookie上，同时也唯一的映射到了flat_binder_object的handler上。而binder_ref又按照node和desc两种方式映射到binder_proc对象上，也就是可以通过binder_node对象或者desc两种方式在binder_proc上查找到binder_ref或binder_node。所以，对于flat_binder_object对象来说，它的binder+cookie和handler指向了同一个binder_node对象上，即同一个binder对象。 由于每个请求和请求的返回都会经历内核的翻译，因此这个过程从进程的角度来看是完全透明的。进程完全不用感知这个过程，就好像对象真的在进程间来回传递一样。 6 驱动层的线程管理上文多次提到，Binder本身是C/S架构。由Server提供服务，被Client使用。既然是C/S架构，就可能存在多个Client会同时访问Server的情况。 在这种情况下，如果Server只有一个线程处理响应，就会导致客户端的请求可能需要排队而导致响应过慢的现象发生。解决这个问题的方法就是引入多线程。 Binder机制的设计从最底层–驱动层，就考虑到了对于多线程的支持。具体内容如下： 使用Binder的进程在启动之后，通过BINDER_SET_MAX_THREADS告知驱动其支持的最大线程数量 驱动会对线程进行管理。在binder_proc结构中，这些字段记录了进程中线程的信息：max_threads，requested_threads，requested_threads_started，ready_threads binder_thread结构对应了Binder进程中的线程 驱动通过BR_SPAWN_LOOPER命令告知进程需要创建一个新的线程 进程通过BC_ENTER_LOOPER命令告知驱动其主线程已经ready 进程通过BC_REGISTER_LOOPER命令告知驱动其子线程（非主线程）已经ready 进程通过BC_EXIT_LOOPER命令告知驱动其线程将要退出 在线程退出之后，通过BINDER_THREAD_EXIT告知Binder驱动。驱动将对应的binder_thread对象销毁","categories":[{"name":"Android","slug":"Android","permalink":"http://wenyiqingnian.xyz/categories/Android/"}],"tags":[{"name":"android","slug":"android","permalink":"http://wenyiqingnian.xyz/tags/android/"},{"name":"Binder","slug":"Binder","permalink":"http://wenyiqingnian.xyz/tags/Binder/"}]},{"title":"理解Linux的FD与Inode","slug":"理解Liunx的FD与Inode","date":"2018-06-02T08:30:15.000Z","updated":"2018-06-02T08:22:05.000Z","comments":true,"path":"2018/06/02/理解Liunx的FD与Inode/","link":"","permalink":"http://wenyiqingnian.xyz/2018/06/02/理解Liunx的FD与Inode/","excerpt":"","text":"FD 文件描述符一、概念 Linux 系统中，把一切都看做是文件，当进程打开现有文件或创建新文件时，内核向进程返回一个文件描述符，文件描述符就是内核为了高效管理已被打开的文件所创建的索引，用来指向被打开的文件，所有执行I/O操作的系统调用都会通过文件描述符。 二、文件描述符、文件、进程间的关系1.描述：我们可以通过linux的几个基本的I/O操作函数来理解什么是文件操作符。 123456fd = open(pathname, flags, mode)// 返回了该文件的fdrlen = read(fd, buf, count)// IO操作均需要传入该文件的fd值wlen = write(fd, buf, count)status = close(fd) 每当进程用open（）函数打开一个文件，内核便会返回该文件的文件操作符（一个非负的整形值），此后所有对该文件的操作，都会以返回的fd文件操作符为参数。【注1】 注1： 文件描述符可以理解为进程文件描述表这个表的索引，或者把文件描述表看做一个数组的话，文件描述符可以看做是数组的下标。当需要进行I/O操作的时候，会传入fd作为参数，先从进程文件描述符表查找该fd对应的那个条目，取出对应的那个已经打开的文件的句柄，根据文件句柄指向，去系统fd表中查找到该文件指向的inode，从而定位到该文件的真正位置，从而进行I/O操作。 每个文件描述符会与一个打开的文件相对应 不同的文件描述符也可能指向同一个文件 相同的文件可以被不同的进程打开，也可以在同一个进程被多次打开 2.系统为维护文件描述符，建立了三个表 进程级的文件描述符表 系统级的文件描述符表 文件系统的i-node表 (inode 见下文) 进程级别的文件描述表：linux内核会为每一个进程创建一个task_truct结构体来维护进程信息，称之为 进程描述符，该结构体中 指针 1struct files_struct *files 指向一个名称为file_struct的结构体，该结构体即 进程级别的文件描述表。 它的每一个条目记录的是单个文件描述符的相关信息 fd控制标志，前内核仅定义了一个，即close-on-exec 文件描述符所打开的文件句柄的引用【注2】 [注释2]：文件句柄这里可以理解为文件名，或者文件的全路径名，因为linux文件系统文件名和文件是独立的，以此与inode区分 系统级别的文件描述符表内核对系统中所有打开的文件维护了一个描述符表，也被称之为 【打开文件表】，表格中的每一项被称之为 【打开文件句柄】，一个【打开文件句柄】 描述了一个打开文件的全部信息。主要包括： 当前文件偏移量（调用read()和write()时更新，或使用lseek()直接修改） 打开文件时所使用的状态标识（即，open()的flags参数） 文件访问模式（如调用open()时所设置的只读模式、只写模式或读写模式） 与信号驱动相关的设置 对该文件i-node对象的引用 文件类型（例如：常规文件、套接字或FIFO）和访问权限 一个指针，指向该文件所持有的锁列表 文件的各种属性，包括文件大小以及与不同类型操作相关的时间戳 Inode表 每个文件系统会为存储于其上的所有文件(包括目录)维护一个i-node表，单个i-node包含以下信息： 文件类型(file type)，可以是常规文件、目录、套接字或FIFO 访问权限 文件锁列表(file locks) 文件大小等等i-node存储在磁盘设备上，内核在内存中维护了一个副本，这里的i-node表为后者。副本除了原有信息，还包括：引用计数(从打开文件描述体)、所在设备号以及一些临时属性，例如文件锁。 注：进程A的fd表中，左边fd0，fd1，fd2… 就是各个文件描述符，它是fd表的索引，fd不是表里那个fd flags！这里不要搞混淆了，fd flags 目前只有一个取值。 在进程A中，文件描述符1和30都指向了同一个打开的文件句柄（标号23）。这可能是通过调用dup()、dup2()、fcntl()或者对同一个文件多次调用了open()函数而形成的。dup（），也称之为文件描述符复制函数，在某些场景下非常有用，比如：标准输入/输出重定向。在shell下，完成这个操作非常简单，大部分人都会，但是极少人思考过背后的原理。 大概描述一下需要的几个步骤，以标准输出(文件描述符为1)重定向为例： 打开目标文件，返回文件描述符n； 关闭文件描述符1； 调用dup将文件描述符n复制到1； 关闭文件描述符n； 进程A的文件描述符2和进程B的文件描述符2都指向了同一个打开的文件句柄（标号73）。这种情形可能是在调用fork()后出现的（即，进程A、B是父子进程关系）【注3】，或者当某进程通过UNIX域套接字将一个打开的文件描述符传递给另一个进程时，也会发生。再者是不同的进程独自去调用open函数打开了同一个文件，此时进程内部的描述符正好分配到与其他进程打开该文件的描述符一样。 注3： 子进程会继承父进程的文件描述符表，也就是子进程继承父进程打开的文件 这句话的由来。 此外，进程A的描述符0和进程B的描述符3分别指向不同的打开文件句柄，但这些句柄均指向i-node表的相同条目（1976），换言之，指向同一个文件。发生这种情况是因为每个进程各自对同一个文件发起了open()调用。同一个进程两次打开同一个文件，也会发生类似情况。 三、文件描述符限制 有资源的地方就有战争，“文件描述符”也是一种资源，系统中的每个进程都需要有“文件描述符”才能进行改变世界的宏图霸业。世界需要秩序，于是就有了“文件描述符限制”的规定。 如下表： 永久修改用户级限制时有三种设置类型： soft 指的是当前系统生效的设置值 hard 指的是系统中所能设定的最大值 “-” 指的是同时设置了 soft 和 hard 的值 Inode 文件节点一、inode是什么？理解inode，要从文件储存说起。 文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。 操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个 sector组成一个 block。 文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。 每一个文件都有对应的inode，里面包含了与该文件有关的一些信息。 二、inode的内容inode包含文件的元信息，具体来说有以下内容： 文件的字节数 文件拥有者的User ID 文件的Group ID 文件的读、写、执行权限 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。 链接数，即有多少文件名指向这个inode 文件数据block的位置 可以用stat命令，查看某个文件的inode信息： stat 233.txt 总之，除了文件名以外的所有文件信息，都存在inode之中。至于为什么没有文件名，下文会有详细解释。 三、inode的大小inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。 每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。 查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令。 df -i 查看每个inode节点的大小，可以用如下命令： sudo dumpe2fs -h /dev/hda | grep &quot;Inode size&quot; 由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。 四、inode号码每个inode都有一个号码，操作系统用inode号码来识别不同的文件。 这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。 表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。 使用ls -i命令，可以看到文件名对应的inode号码： ls -i 233.txt 五、目录文件 Unix/Linux系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。 目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。 ls命令只列出目录文件中的所有文件名： ls /etc ls -i命令列出整个目录文件，即文件名和inode号码： ls -i /etc 如果要查看文件的详细信息，就必须根据inode号码，访问inode节点，读取信息。ls -l命令列出文件的详细信息。 ls -l /etc 理解了上面这些知识，就能理解目录的权限。目录文件的读权限（r）和写权限（w），都是针对目录文件本身。由于目录文件内只有文件名和inode号码，所以如果只有读权限，只能获取文件名，无法获取其他信息，因为其他信息都储存在inode节点中，而读取inode节点内的信息需要目录文件的执行权限（x）。 六、硬链接一般情况下，文件名和inode号码是”一一对应”关系，每个inode号码对应一个文件名。但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。 这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为”硬链接”（hard link）。 ln命令可以创建硬链接： ln 源文件 目标文件 运行上面这条命令以后，源文件与目标文件的inode号码相同，都指向同一个inode。inode信息中有一项叫做”链接数”，记录指向该inode的文件名总数，这时就会增加1。 反过来，删除一个文件名，就会使得inode节点中的”链接数”减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。 这里顺便说一下目录文件的”链接数”。创建目录时，默认会生成两个目录项：”.”和”..”。前者的inode号码就是当前目录的inode号码，等同于当前目录的”硬链接”；后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的”硬链接”。所以，任何一个目录的”硬链接”总数，总是等于2加上它的子目录总数（含隐藏目录）。 七、软链接除了硬链接以外，还有一种特殊情况。 文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的”软链接”（soft link）或者”符号链接（symbolic link）。 这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：”No such file or directory”。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode”链接数”不会因此发生变化。 ln -s命令可以创建软链接。 ln -s 源文文件或目录 目标文件或目录 八、inode的特殊作用由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。 移动文件或重命名文件，只是改变文件名，不影响inode号码。 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。 第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wenyiqingnian.xyz/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://wenyiqingnian.xyz/tags/linux/"}]},{"title":"Docker入门","slug":"Docker入门","date":"2018-05-30T07:56:50.000Z","updated":"2018-06-02T08:22:02.000Z","comments":true,"path":"2018/05/30/Docker入门/","link":"","permalink":"http://wenyiqingnian.xyz/2018/05/30/Docker入门/","excerpt":"","text":"Docker是目前最火的Linux容器解决方案，真正做到一劳永逸的解决环境配置和依赖问题，而且可以方便的修改、分享，版本管理，本篇文章摘选自 阮一峰的博客：Docker 入门教程 一、环境配置的难题软件开发最大的麻烦事之一，就是环境配置。用户计算机的环境都不相同，你怎么知道自家的软件，能在那些机器跑起来？ 用户必须保证两件事：操作系统的设置，各种库和组件的安装。只有它们都正确，软件才能运行。举例来说，安装一个 Python 应用，计算机必须有 Python 引擎，还必须有各种依赖，可能还要配置环境变量。 如果某些老旧的模块与当前环境不兼容，那就麻烦了。开发者常常会说：”它在我的机器可以跑了”（It works on my machine），言下之意就是，其他机器很可能跑不了。 环境配置如此麻烦，换一台机器，就要重来一次，旷日费时。很多人想到，能不能从根本上解决问题，软件可以带环境安装？也就是说，安装的时候，把原始环境一模一样地复制过来。 二、虚拟机虚拟机（virtual machine）就是带环境安装的一种解决方案。它可以在一种操作系统里面运行另一种操作系统，比如在 Windows 系统里面运行 Linux 系统。应用程序对此毫无感知，因为虚拟机看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件，不需要了就删掉，对其他部分毫无影响。 虽然用户可以通过虚拟机还原软件的原始环境。但是，这个方案有几个缺点。 （1）资源占用多 虚拟机会独占一部分内存和硬盘空间。它运行的时候，其他程序就不能使用这些资源了。哪怕虚拟机里面的应用程序，真正使用的内存只有 1MB，虚拟机依然需要几百 MB 的内存才能运行。 （2）冗余步骤多 虚拟机是完整的操作系统，一些系统级别的操作步骤，往往无法跳过，比如用户登录。 （3）启动慢 启动操作系统需要多久，启动虚拟机就需要多久。可能要等几分钟，应用程序才能真正运行。 三、Linux 容器由于虚拟机存在这些缺点，Linux 发展出了另一种虚拟化技术：Linux 容器（Linux Containers，缩写为 LXC）。 Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。或者说，在正常进程的外面套了一个保护层。对于容器里面的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离。 由于容器是进程级别的，相比虚拟机有很多优势。 （1）启动快 容器里面的应用，直接就是底层系统的一个进程，而不是虚拟机内部的进程。所以，启动容器相当于启动本机的一个进程，而不是启动一个操作系统，速度就快很多。 （2）资源占用少 容器只占用需要的资源，不占用那些没有用到的资源；虚拟机由于是完整的操作系统，不可避免要占用所有资源。另外，多个容器可以共享资源，虚拟机都是独享资源。 （3）体积小 容器只要包含用到的组件即可，而虚拟机是整个操作系统的打包，所以容器文件比虚拟机文件要小很多。 总之，容器有点像轻量级的虚拟机，能够提供虚拟化的环境，但是成本开销小得多。 四、Docker 是什么？Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。 Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。 总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 五、Docker 的用途Docker 的主要用途，目前有三大类。 （1）提供一次性的环境。比如，本地测试他人的软件、持续集成的时候提供单元测试和构建的环境。 （2）提供弹性的云服务。因为 Docker 容器可以随开随关，很适合动态扩容和缩容。 （3）组建微服务架构。通过多个容器，一台机器可以跑多个服务，因此在本机就可以模拟出微服务架构。 六、Docker 的安装Docker 是一个开源的商业产品，有两个版本：社区版（Community Edition，缩写为 CE）和企业版（Enterprise Edition，缩写为 EE）。企业版包含了一些收费服务，个人开发者一般用不到。下面的介绍都针对社区版。 Docker CE 的安装请参考官方文档。 MacWindowsUbuntu其他 Linux 发行版安装完成后，运行下面的命令，验证是否安装成功。 123$ docker version# 或者$ docker info Docker 需要用户具有 sudo 权限，为了避免每次命令都输入sudo，可以把用户加入 Docker 用户组（官方文档）。 1$ sudo usermod -aG docker $USER Docker 是服务器—-客户端架构。命令行运行docker命令的时候，需要本机有 Docker 服务。如果这项服务没有启动，可以用下面的命令启动（官方文档）。 12345# service 命令的用法$ sudo service docker start# systemctl 命令的用法$ sudo systemctl start docker 六、image 文件Docker 把应用程序及其依赖，打包在 image 文件里面。只有通过这个文件，才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。 image 是二进制文件。实际开发中，一个 image 文件往往通过继承另一个 image 文件，加上一些个性化设置而生成。举例来说，你可以在 Ubuntu 的 image 基础上，往里面加入 Apache 服务器，形成你的 image。 12345# 列出本机的所有 image 文件。$ docker image ls# 删除 image 文件$ docker image rm [imageName] image 文件是通用的，一台机器的 image 文件拷贝到另一台机器，照样可以使用。一般来说，为了节省时间，我们应该尽量使用别人制作好的 image 文件，而不是自己制作。即使要定制，也应该基于别人的 image 文件进行加工，而不是从零开始制作。 为了方便共享，image 文件制作完成后，可以上传到网上的仓库。Docker 的官方仓库 Docker Hub 是最重要、最常用的 image 仓库。此外，出售自己制作的 image 文件也是可以的。 七、实例：hello world下面，我们通过最简单的 image 文件”hello world”，感受一下 Docker。 需要说明的是，国内连接 Docker 的官方仓库很慢，还会断线，需要将默认仓库改成国内的镜像网站，具体的修改方法在下一篇文章的第一节。有需要的朋友，可以先看一下。 首先，运行下面的命令，将 image 文件从仓库抓取到本地。 $ docker image pull library/hello-world上面代码中，docker image pull是抓取 image 文件的命令。library/hello-world是 image 文件在仓库里面的位置，其中library是 image 文件所在的组，hello-world是 image 文件的名字。 由于 Docker 官方提供的 image 文件，都放在library组里面，所以它的是默认组，可以省略。因此，上面的命令可以写成下面这样。 $ docker image pull hello-world抓取成功以后，就可以在本机看到这个 image 文件了。 $ docker image ls现在，运行这个 image 文件。 $ docker container run hello-worlddocker container run命令会从 image 文件，生成一个正在运行的容器实例。 注意，docker container run命令具有自动抓取 image 文件的功能。如果发现本地没有指定的 image 文件，就会从仓库自动抓取。因此，前面的docker image pull命令并不是必需的步骤。 如果运行成功，你会在屏幕上读到下面的输出。 123456$ docker container run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.... ... 输出这段提示以后，hello world就会停止运行，容器自动终止。 有些容器不会自动终止，因为提供的是服务。比如，安装运行 Ubuntu 的 image，就可以在命令行体验 Ubuntu 系统。 $ docker container run -it ubuntu bash对于那些不会自动终止的容器，必须使用docker container kill 命令手动终止。 $ docker container kill [containID] 八、容器文件image 文件生成的容器实例，本身也是一个文件，称为容器文件。也就是说，一旦容器生成，就会同时存在两个文件： image 文件和容器文件。而且关闭容器并不会删除容器文件，只是容器停止运行而已。 12345# 列出本机正在运行的容器$ docker container ls# 列出本机所有容器，包括终止运行的容器$ docker container ls --all 上面命令的输出结果之中，包括容器的 ID。很多地方都需要提供这个 ID，比如上一节终止容器运行的docker container kill命令。 终止运行的容器文件，依然会占据硬盘空间，可以使用docker container rm命令删除。 $ docker container rm [containerID]运行上面的命令之后，再使用docker container ls --all命令，就会发现被删除的容器文件已经消失了。 九、Dockerfile 文件学会使用 image 文件以后，接下来的问题就是，如何可以生成 image 文件？如果你要推广自己的软件，势必要自己制作 image 文件。 这就需要用到 Dockerfile 文件。它是一个文本文件，用来配置 image。Docker 根据 该文件生成二进制的 image 文件。 下面通过一个实例，演示如何编写 Dockerfile 文件。 十、实例：制作自己的 Docker 容器下面我以 koa-demos 项目为例，介绍怎么写 Dockerfile 文件，实现让用户在 Docker 容器里面运行 Koa 框架。 作为准备工作，请先下载源码。 12$ git clone https://github.com/ruanyf/koa-demos.git$ cd koa-demos 10.1 编写 Dockerfile 文件首先，在项目的根目录下，新建一个文本文件.dockerignore，写入下面的内容。 123.gitnode_modulesnpm-debug.log 上面代码表示，这三个路径要排除，不要打包进入 image 文件。如果你没有路径要排除，这个文件可以不新建。 然后，在项目的根目录下，新建一个文本文件 Dockerfile，写入下面的内容。 12345FROM node:8.4COPY . /appWORKDIR /appRUN npm install --registry=https://registry.npm.taobao.orgEXPOSE 3000 上面代码一共五行，含义如下。 FROM node:8.4:该 image 文件继承官方的 node image，冒号表示标签，这里标签是8.4，即8.4版本的 node。 COPY . /app：将当前目录下的所有文件（除了.dockerignore排除的路径），都拷贝进入 image 文件的/app目录。 WORKDIR /app：指定接下来的工作路径为/app。 RUN npm install：在/app目录下，运行npm install命令安装依赖。注意，安装后所有的依赖，都将打包进入 image 文件。EXPOSE 3000：将容器 3000 端口暴露出来， 允许外部连接这个端口。 10.2 创建 image 文件有了 Dockerfile 文件以后，就可以使用docker image build命令创建 image 文件了。 123$ docker image build -t koa-demo # 或者$ docker image build -t koa-demo:0.0.1 . 上面代码中，-t参数用来指定 image 文件的名字，后面还可以用冒号指定标签。如果不指定，默认的标签就是latest。最后的那个点表示 Dockerfile 文件所在的路径，上例是当前路径，所以是一个点。 如果运行成功，就可以看到新生成的 image 文件koa-demo了。 $ docker image ls 10.3 生成容器docker container run命令会从 image 文件生成容器。 123$ docker container run -p 8000:3000 -it koa-demo /bin/bash# 或者$ docker container run -p 8000:3000 -it koa-demo:0.0.1 /bin/bash 上面命令的各个参数含义如下： -p参数：容器的 3000 端口映射到本机的 8000 端口。 -it参数：容器的 Shell 映射到当前的 Shell，然后你在本机窗口输入的命令，就会传入容器。 koa-demo:0.0.1：image 文件的名字（如果有标签，还需要提供标签，默认是 latest 标签）。 /bin/bash：容器启动以后，内部第一个执行的命令。这里是启动 Bash，保证用户可以使用 Shell。如果一切正常，运行上面的命令以后，就会返回一个命令行提示符。 root@66d80f4aaf1e:/app#这表示你已经在容器里面了，返回的提示符就是容器内部的 Shell 提示符。执行下面的命令。 root@66d80f4aaf1e:/app# node demos/01.js这时，Koa 框架已经运行起来了。打开本机的浏览器，访问 http://127.0.0.1:8000，网页显示&quot;Not Found”，这是因为这个 demo 没有写路由。 这个例子中，Node 进程运行在 Docker 容器的虚拟环境里面，进程接触到的文件系统和网络接口都是虚拟的，与本机的文件系统和网络接口是隔离的，因此需要定义容器与物理机的端口映射（map）。 现在，在容器的命令行，按下 Ctrl + c 停止 Node 进程，然后按下 Ctrl + d （或者输入 exit）退出容器。此外，也可以用docker container kill终止容器运行。 12345678910111213# 在本机的另一个终端窗口，查出容器的 ID$ docker container ls# 停止指定的容器运行$ docker container kill [containerID]容器停止运行之后，并不会消失，用下面的命令删除容器文件。# 查出容器的 ID$ docker container ls --all# 删除指定的容器文件$ docker container rm [containerID] 也可以使用docker container run命令的--rm参数，在容器终止运行后自动删除容器文件。 1$ docker container run --rm -p 8000:3000 -it koa-demo /bin/bash 10.4 CMD 命令上一节的例子里面，容器启动以后，需要手动输入命令node demos/01.js。我们可以把这个命令写在 Dockerfile 里面，这样容器启动以后，这个命令就已经执行了，不用再手动输入了。 123456FROM node:8.4COPY . /appWORKDIR /appRUN npm install --registry=https://registry.npm.taobao.orgEXPOSE 3000CMD node demos/01.js 上面的 Dockerfile 里面，多了最后一行CMD node demos/01.js，它表示容器启动后自动执行node demos/01.js。 你可能会问，RUN命令与CMD命令的区别在哪里？简单说，RUN命令在 image 文件的构建阶段执行，执行结果都会打包进入 image 文件；CMD命令则是在容器启动后执行。另外，一个 Dockerfile 可以包含多个RUN命令，但是只能有一个CMD命令。 注意，指定了CMD命令以后，docker container run命令就不能附加命令了（比如前面的/bin/bash），否则它会覆盖CMD命令。现在，启动容器可以使用下面的命令。 1$ docker container run --rm -p 8000:3000 -it koa-demo:0.0.1 10.5 发布 image 文件容器运行成功后，就确认了 image 文件的有效性。这时，我们就可以考虑把 image 文件分享到网上，让其他人使用。 首先，去 cloud.docker.com 或 cloud.docker.com 注册一个账户。然后，用下面的命令登录。 $ docker login接着，为本地的 image 标注用户名和版本。 123$ docker image tag [imageName] [username]/[repository]:[tag]# 实例$ docker image tag koa-demos:0.0.1 ruanyf/koa-demos:0.0.1 也可以不标注用户名，重新构建一下 image 文件。 1$ docker image build -t [username]/[repository]:[tag] . 最后，发布 image 文件。 1$ docker image push [username]/[repository]:[tag] 发布成功以后，登录 hub.docker.com，就可以看到已经发布的 image 文件。 十一、其他有用的命令docker 的主要用法就是上面这些，此外还有几个命令，也非常有用。 （1）docker container start 前面的docker container run命令是新建容器，每运行一次，就会新建一个容器。同样的命令运行两次，就会生成两个一模一样的容器文件。如果希望重复使用容器，就要使用docker container start命令，它用来启动已经生成、已经停止运行的容器文件。 $ docker container start [containerID] （2）docker container stop 前面的docker container kill命令终止容器运行，相当于向容器里面的主进程发出 SIGKILL 信号。而docker container stop命令也是用来终止容器运行，相当于向容器里面的主进程发出 SIGTERM 信号，然后过一段时间再发出 SIGKILL 信号。 $ bash container stop [containerID]这两个信号的差别是，应用程序收到 SIGTERM 信号以后，可以自行进行收尾清理工作，但也可以不理会这个信号。如果收到 SIGKILL 信号，就会强行立即终止，那些正在进行中的操作会全部丢失。 （3）docker container logs docker container logs命令用来查看 docker 容器的输出，即容器里面 Shell 的标准输出。如果docker run命令运行容器的时候，没有使用-it参数，就要用这个命令查看输出。 $ docker container logs [containerID] （4）docker container exec docker container exec命令用于进入一个正在运行的 docker 容器。如果docker run命令运行容器的时候，没有使用-it参数，就要用这个命令进入容器。一旦进入了容器，就可以在容器的 Shell 执行命令了。 1$ docker container exec -it [containerID] /bin/bash （5）docker container cp docker container cp命令用于从正在运行的 Docker 容器里面，将文件拷贝到本机。下面是拷贝到当前目录的写法。 1$ docker container cp [containID]:[/path/to/file] .","categories":[{"name":"容器技术","slug":"容器技术","permalink":"http://wenyiqingnian.xyz/categories/容器技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://wenyiqingnian.xyz/tags/docker/"},{"name":"容器","slug":"容器","permalink":"http://wenyiqingnian.xyz/tags/容器/"}]},{"title":"Binder的设计架构","slug":"Binder的设计架构","date":"2018-05-29T11:20:50.000Z","updated":"2018-06-03T04:49:58.000Z","comments":true,"path":"2018/05/29/Binder的设计架构/","link":"","permalink":"http://wenyiqingnian.xyz/2018/05/29/Binder的设计架构/","excerpt":"","text":"一、为什么选择Binderandroid 是基于Linux开发的移动端操作系统，而传统的Linux已有的IPC机制，包括管道，消息队列、共享内存、信号量、socket为什么不适合安卓，而非要采用Binder？ 1.拷贝次数SocketLinux中除了Binder之外唯一一个C/S架构的IPC，为了兼容本地操作系统中的进程间通讯和互联网中的远程主机之间的通讯，Socket采用的是更加通用型的架构，一般的socket通讯流程如下 客户端通过 int socket(int domain, int type, int protocol); 函数创建了一个socket，返回了该套接字的文件描述符 通过bind函数 绑定了该socket的端口号，监听该端口 循环检查该端口是否有消息，如果有消息则fork出子进程去处理 使用read（）读取客户端发送的消息数据，通过write（）处理消息并发送给客户端 客户端也要创建socket 客户端连接到制定IP和端口的服务端socket 使用write向服务端写数据，用read 从服务端度数据可以看到，一次标准的socket通讯步骤繁琐，计算机内的进程间通讯，如果采用socket，不可避免的会先write()将文件写到内核缓冲区，再read() 将文件读取到用户缓冲区，涉及两次拷贝。如果是网络传输，一次通讯过程可能会涉及三到四次拷贝，多次切换上下文。匿名管道 半双工，数据流动方向是单向的，读写端都是固定的 只能用于父子进程间的通讯 属于一种特殊的文件，只存在内存中 数据传递方式仍然采用read 和 write ，先从发送方缓冲区拷贝到内核，再从内核缓冲区拷贝到接收方 拷贝次数 两次 命名管道可以在无关进程之间交流数据，它有些类似用文件的方式在进城之间传递数据，但该文件又同时具有管道的特点，它允许所有知道其FIFO接口的进程参与读写，遵循先入先出的原则。 拷贝次数 2次拷贝 消息队列 面向记录，消息队列中的消息具有特定格式和优先级 独立于进程，就算进程被杀死，队列中的消息也不会被清除 可以实现消息的独立查询 消息队列同样需要两次拷贝，进程A 拷贝消息到消息队列，消息队列从队列中取消息 将其拷贝到进程B共享内存指的是两个或以上进程共享的一块内存区域 速度最快 因为是直接读取，不涉及拷贝 多个进程需要同时读取，所以需要同步机制，一般配合信号量使用 BinderBinder是Android系统中广泛采用的C/S架构IPC通讯方式，它只需要一次内存拷贝。Binder的一次通讯过程：通过 BinderProxy 将我们的请求参数发送给 ServiceManager，通过共享内存的方式使用内核方法 copy_from_user() 将我们的参数先拷贝到内核空间，这时我们的客户端进入等待状态，然后 Binder 驱动向服务端的 todo 队列里面插入一条事务，执行完之后把执行结果通过 copy_to_user()将内核的结果拷贝到用户空间（这里只是执行了拷贝命令，并没有拷贝数据，binder只进行一次拷贝），唤醒等待的客户端并把结果响应回来，这样就完成了一次通讯。 关于消息传递效率 参考下表 IPC 特征 拷贝次数 特点 共享内存 速度快，但是控制复杂，要解决同步问题 0 极少用 Binder 简单 通用 安全 1 Android常用、性能高 Socket A缓冲区-&gt;内核缓冲区-&gt;B缓冲区 2 Socket作为通用接口，开销大，传输性能低，一般用作跨网络或者进程间的低速IPC 2.安全性Android作为一个开放式，拥有众多开发者的的平台，应用程序的来源广泛，确保智能终端的安全是非常重要的。终端用户不希望从网上下载的程序在不知情的情况下偷窥隐私数据，连接无线网络，长期操作底层设备导致电池很快耗尽等等。传统IPC没有任何安全措施，完全依赖上层协议来确保。 传统IPC的接收方无法获得对方进程可靠的UID/PID（用户ID/进程ID），从而无法鉴别对方身份。Android为每个安装好的应用程序分配了自己的UID，故进程的UID是鉴别进程身份的重要标志。 使用传统IPC只能由用户在数据包里填入UID/PID，但这样不可靠，容易被恶意程序利用。可靠的身份标记只有由IPC机制本身在内核中添加。其次传统IPC访问接入点是开放的，无法建立私有通道。比如命名管道的名称，system V的键值，socket的ip地址或文件名都是开放的，只要知道这些接入点的程序都可以和对端建立连接，不管怎样都无法阻止恶意程序通过猜测接收方地址获得连接。 基于以上原因，Android需要建立一套新的IPC机制来满足系统对通信方式，传输性能和安全性的要求，这就是Binder。Binder基于Client-Server通信模式，传输过程只需一次拷贝，为发送发添加UID/PID身份，既支持实名Binder也支持匿名Binder，安全性高。 二、 Binder 的面向对象思想Binder可以看做是server端提供某个功能的访问接入点，client通过访问该接入点获得server的服务，但和其他ipc不同的是，binder采用一种面向对象的思想来设计该入口。 Binder的实体是位于server中的对象，它实现了一系列方法用以访问server的服务，有点类似于类中的成员函数，而client中拿到的其实是该binder对象的引用 client —&gt; binder引用—-&gt;Binder—-&gt;server 面向对象思想的引入将进程间通信转化为通过对某个Binder对象的引用调用该对象的方法，而其独特之处在于Binder对象是一个可以跨进程引用的对象，它的实体位于一个进程中，而它的引用却遍布于系统的各个进程之中。这个引用和java里引用一样既可以是强类型，也可以是弱类型，而且可以从一个进程传给其它进程，让大家都能访问同一Server，就象将一个对象或引用赋值给另一个引用一样。Binder模糊了进程边界，淡化了进程间通信过程，整个系统仿佛运行于同一个面向对象的程序之中。形形色色的Binder对象以及星罗棋布的引用仿佛粘接各个应用程序的胶水，这也是Binder在英文里的原意。 当然面向对象只是针对应用程序而言，对于Binder驱动和内核其它模块一样使用C语言实现，没有类和对象的概念。Binder驱动为面向对象的进程间通信提供底层支持。 三、Binder的通讯模型一个完整的Binder驱动包含四个角色 Server、Client、ServiceManager、Binder驱动。 server client smg 运行在用户空间，Binder驱动运行在内和空间。 1.Binder驱动实现方式类似硬件驱动，工作在内核态123456789static const struct file_operations binder_fops = &#123; .owner = THIS_MODULE, .poll = binder_poll, .unlocked_ioctl = binder_ioctl, .mmap = binder_mmap, .open = binder_open, .flush = binder_flush, .release = binder_release,&#125;; 这是binder驱动的file_operation结构体，可以看到binder驱动为应用层提供了open(),mmap(),poll(),ioctl()等标准的文件操作【注1】，open()负责打开驱动，mmap()负责对binder做内核空间向用户空间的地址映射，ioctl()负责binder协议的通信。Binder驱动负责在内核中创建对应的Binder实体节点，为client或者server进程创建对该实体节点的引用，负责进程之间Binder通信的建立，Binder在进程之间传递，Binder引用计数管理，数据包在进程之间的传递等一系列操作的底层支持，驱动和应用程序之间定义了一套标准的接口协议，主要功能由ioctl()【注2】来实现，不提供read（），write接口。（因为ioctl是更为高灵活的操作文件的接口，自动遵循先写后读的顺序，可以满足同步请求） 注释1：设备驱动程序是操作系统内核和机器硬件之间的接口。设备驱动程序为应用程序屏蔽了硬件的细节，这样在应用程序看来，硬件设备只是一个设备文件，应用程序可以象操作普通文件一样对硬件设备进行操作。设备驱动程序是内核的一部分，它完成以下的功能:1、对设备初始化和释放；2、把数据从内核传送到硬件和从硬件读取数据；3、读取应用程序传送给设备文件的数据和回送应用程序请求的数据；4、检测和处理设备出现的错误。 注释2： ioctl()函数是驱动中对设备的I/O通道进行管理的函数，ioctl函数里面都实现了多个的对硬件的操作步骤，将他们综合起来完成一个任务，而不是单一的某个write/read操作，通过应用层传入的命令来调用相应的操作。 ServiceManagerServiceManger有点类似于路由器，使得client端可以通过字符串形式的binder名来获取server端binder的引用，它提供注册和查询服务。server端像smg注册服务，client从smg获取服务。 server创建了一个binder实体，为其取一个容易记住的名字，然后将这个binder实体 连同名字通过binder驱动发送给smg，通知smg注册一个服务，以及该服务的名字，binder驱动会为这个穿过进程边际的binder创建一个位于内核的实体节点，以及smg对该实体节点的引用，然后将名字以及新建的引用打包发送给serviceManager，smg会在它的svcinfo表中添加该信息。该svcinfo便是服务查询表。","categories":[{"name":"Android","slug":"Android","permalink":"http://wenyiqingnian.xyz/categories/Android/"}],"tags":[{"name":"android","slug":"android","permalink":"http://wenyiqingnian.xyz/tags/android/"},{"name":"Binder","slug":"Binder","permalink":"http://wenyiqingnian.xyz/tags/Binder/"}]},{"title":"JAVA的垃圾回收策略（二）","slug":"JAVA的垃圾回收策略（二）","date":"2018-05-23T08:56:50.000Z","updated":"2018-06-02T08:11:08.000Z","comments":true,"path":"2018/05/23/JAVA的垃圾回收策略（二）/","link":"","permalink":"http://wenyiqingnian.xyz/2018/05/23/JAVA的垃圾回收策略（二）/","excerpt":"","text":"上文说到了一个java对象的生命周期以及生存位置本文主要讲 jvm虚拟机如何判定一个对象是否是垃圾，以及以何种算法回收垃圾。 GC的工作流程1. 判定那些对象已成为垃圾jvm一般有两种方法判断对象是否成为垃圾 1. 引用标记算法1.流程 给每一个对象都增加一个引用计数器 每次对象新增一个引用的时候，该计数器+1 当该引用对象失效（比如超出了作用域）==【注1】==，该引用计数器-1 当该对象的引用计数器为1时，表明该对象不可用，可作为垃圾回收了。 注1：作用域的概念，上文其实已经说过了，见JAVA垃圾回收机制。当在方法内创建了一个引用变量并指向它引用的对象的时候，引用的对象会在方法执行完后仍然存活在堆内存上，只是引用变量会随方法一起出栈销毁而已，见下面的例子。 123456789void fun()&#123;...Persion p = new Person();&#125;/***方法之外，引用变量P就消失了，因为引用变量是存放在*方法栈中的，所以方法执行完毕，p便随着方法栈一起出*栈，但是因为这中间调用了new 关键字,其创建的person对象会一直存放在堆内存中等待**被GC，此时person对象，就是超出了作用域的对象。*/ 123graph LRCLASS_A--&gt;CLASS_BCLASS_B--&gt;CLASS_A 2. 引用标记算法的优缺点 优点：算法简单，执行速度快，不需要长时间中断应用程序的执行 缺陷：无法解决循环引用问题（A引用B，B引用A，此时引用计数器永远无法置0）。2. GC_ROOT 可达性算法1. 原理 以GC root作为根节点 ==（gcroot具体包含那些对象下面会详细解释）==,向下搜寻所有对象 如果可以走到该对象，就建立一个该对象和GCTROOT之间的引用链。 从根节点开始，生成对象引用树，不可达的对象，会被判断为垃圾由GC判断是否回收 123456789101112graph LRGCROOT--&gt;CLASS_AGCROOT--&gt;CLASS_BGCROOT--&gt;CLASS_CGCROOT--&gt;CLASS_ECLASS_A--&gt;CLASS_DCLASS_A--&gt;CLASS_FCLASS_B--&gt;CLASS_FCLASS_B--&gt;CLASS_GCLASS_H--&gt;CLASS_JCLASS_J--&gt;CLASS_HCLASS_E--&gt;CLASS_K 上图的对象h和对象j 就是不可达的引用，但是彼此持有对方的引用，如果用引用计数算法，该对象是无法被回收的，gcroot算法，他们是不可达的，会随时被gc回收。 3.关于回收的一些其他问题当对象被标记为不可达的时候，gc并不会立刻启动回收程序，而是再使用两次标记算法来区分何时回收。在GC启动回收程序的时候，为了保证引用状态不变，系统会暂停所有应用进程（stopt the world ），这个时间很短，反应在UI上就是UI卡顿了一下，所以安卓应用要十分注意合理控制好内存回收，不要频繁处罚GC，不然体验会十分糟糕。 二次标记算法:1.如果对象与GC Root没有连接的引用链，就会被第一次标记，随后判定该对象是否有必要执行finalize()方法 2.如果有必要执行finalize()方法，则这个对象就会被放到F-Queue的队列中，稍后由虚拟机建立低优先级的Finalizer线程去执行，但并不承诺等待它运行结束（对象类中能够重写finalize()方法进行自救，但系统最多只能执行一次） 3.如果没必要执行finalize()方法，则第二次标记 2. 通过特定算法回收垃圾主要包括以下四种算法 12341、标记清除算法2、算法算法3、标记整理算法4、分代回收算法 1. 标记清除算法两步走 标记 标记出无用的对象 清除 清除掉对象的空间 可以看到 优缺点很明显 123缺点：容易造成内存碎片，当下次申请大内存的时候，可能找不到连续的内存给其使用，会频繁出发gc，优点：是算法比较简单。 因为标记无用对象耗时，可以看出 标记清除算法比较适合于 垃圾少，存活对象多的情况，可以减少标记次数。在分代回收算法中，它一般应用在老年代（对象存活率高，需要回收的少） 2. 复制算法（也被成为拷贝回收算法）此方法将内存按容量分为两块，例如A、B两块，每次只使用其中的一块，当要进行回收操作时，将A中还存活的对象复制到B块中（假设上次使用A），然后对A中所有对象清空就又构成一个完整的内存块。这种方法就避免了标记清除的内存碎片问题。 123优点：不会产生内存碎片缺点： 会浪费内存，因为不管A块中有多少存活对象，都只能使用内存的一半，AB块中始终有一块为空，属于用空间换时间。 分代回收法中新生代的部分，使用的是该算法。 适合存活对象少 回收对象多的情况，因为存活对象多复制的过程就长一些，算法效率会受影响。 3. 标记整理算法解决了上述两种算法的缺点，但也带来了新的缺点，就是算法效率不够高。 1231. 标记存活对象2. 移动对象到左上角3. 将其他空间全部回收 123优点： 不会产生内存碎片 不会造成空间使用浪费缺点：标记的过程导致其效率不如复制算法，移动的过程，导致其效率不如标记算法。 适合存活对象多 4. 分代回收算法该算法其实是上述三种算法的组合，因为上述三种算法都有其适用的适用情景，不可能适用所有情况，分代回收算法就是根据jvm里不同对象的存活特性来组合使用上述三种算法。 jvm按照对象生命周期将内存划分为两个区域。 新生代 新生代会产生大量的临时对象。这些对象 朝生夕死。存活时间短，经常需要回收，所以采用拷贝回收算法。在新生代的gc，称之为minor gc。 老年代 一般是生命周期长的对象，回收频率很低，只有当老年代内存占满了之后，才会触发一次full gc，或称之为（major gc）。 内存的具体划分 可以看到 新生代又被分为Eden 区 和 s1，s2区。s1 s2是为了拷贝算法划分的乒乓区域。他们大小是相同的。 2. 分代回收算法的具体回收过程 新生对象全部在Eden区域活动，当Eden区域满了之后，会触发一次minor gc 将Eden区域中还能用的的对象拷贝到From区域。 此时 Eden区域的空间被清空，存活对象在From区。 当From区域满了之后，会再次触发monor gc，将Eden和From区域中还可用的对象拷贝到To区域中。 此时 Eden 和From区的空间被清空。 当To的空间满了之后，会再次触发minor gc，此时会将Eden 和To 空间中还存活的对象拷贝到From区。Eden 和To space被清空。 在多次minor gc之后，有些对象会一直在from和to 区域之间来回拷贝，此时会被算法标注为老年代对象，gc会将该对象从新生代直接拷贝到老年代。JVM虚拟机默认的反复拷贝次数为==15次==。如果对象在From 到 to区域中反复拷贝了15次，就会被划分为老年代。 对象进入老年代之后，当老年代内存区域也满了，便会触发一次Full gc， 此时使用的算法是标记算法和标记整理算法。 为什么老年代的gc 不使用拷贝算法，因为老年代中的对象大多是存活率高的对象，使用拷贝算法要创建一个很大的新内存空间来做拷贝，这样很浪费资源。为什么不只使用标记算法，因为这样会导致内存碎片。使用标记清除算法，会将存活对象做地址移动，都集中在一块连续地址空间中，防止产生内存碎片。 所monor gc的时候，是用空间换时间，因为该gc发生频繁，效率是首要考虑的问题。 而full gc的时候，腾出空间更重要，所以选择用时间（使用标注整理算法）换空间。 3. 新生代老年代的内存划分比新生代：老年代 2：1 新生代中 Eden : s1 : s2 = 8 : 1 : 1 3. GC_ROOT要记住一个概念，选gcroot，就是要以这些当前活跃的gcroot对象为根去遍历所有引用关系，能遍历到的就是存活的，遍历不到的认为死去，所以选gcroot，本质是找到==所有存活的对象==，把其他空间认定为无用去清除掉。所以gcroot必须具备两个性质 必须存活 必须有其他引用（因为要以它自己去遍历引用关系） jvm 运行时内存 所以“GC roots”，或者说tracing GC的“根集合”，就是一组必须==活跃==的==引用==。具体包括以下几种： 1234567891. Class 由System Class Loader/Boot Class Loader加载的类，类似于java.util.*包下的类，因为它一定是贯穿于整个生命周期的，可以以此为根遍历出去找到其他引用的类。被引用到的就一定是存活的。2. Thread 对象，已激活但是未结束的线程对象；3. Stack Local 栈中的对象。每个线程都会分配一个栈，栈中的局部变量或者参数的引用都是GC root，因为仍在栈中，表明方法还没执行完，对象仍存活，（执行后的方法会出栈，就不满足存活条件了），同时是引用对象。4.JNI Local JNI中的局部变量和参数引用的对象；可能在JNI中定义的，也可能在虚拟机中定义5. JNI Global JNI中的全局变量引用的对象；同上6. Monitor Used 用于保证同步的对象，例如wait()，notify()中使用的对象、锁等。7. Held by JVM JVM持有的对象。JVM为了特殊用途保留的对象，它与JVM的具体实现有关。比如有System Class Loader, 一些Exceptions对象，和一些其它的ClassLoader。对于这些类，JVM也没有过多的信息。8. 静态数据结构指向对象堆的引用。 关于1 2 我举几个具体例子来说明一下： 123456789101112131415161718192021222324252627//1.由系统类加载器加载的类public class ServiceManager extends Service &#123; public Person p = new Person();&#125;这里不确切，但是大致可以表明意思，安卓ServiceManager贯穿整个应用生命周期，它里面持有Persion对象的引用，这个ServiceManager对象就是gcroot 它持有的person对象永远不会被释放。2. //Thred Localpublic class A&#123; void main()&#123; Thread t = new Thread(new Runnable() &#123; @Override public void run() &#123; B b = new B(); &#125; &#125;); t.start(); &#125; &#125;t 属于gcroot 如果不停止thread t永远不会被回收，它持有的b 也不会被回收。3. ==注意，是一组必须活跃的引用，不是对象==Tracing GC的根本思路就是：给定一个集合的引用作为根出发，通过引用关系遍历对象图，能被遍历到的（可到达的）对象就被判定为存活，其余对象（也就是没有被遍历到的）就自然被判定为死亡。注意再注意：tracing GC的本质是==通过找出所有活对象来把其余空间认定为“无用”==，而不是==找出所有死掉的对象并回收它们占用的空间==。这里非常容易搞混淆！！GC roots这组引用是tracing GC的起点。 4 . 安卓的Dalvik虚拟机与jvm不同的地方1. 堆的结构不同 Dalvik虚拟机用来分配对象的堆划分为两部分，一部分叫做Active Heap，另一部分叫做Zygote Heap。为什么要划分为两个堆，是为了减少内存拷贝的过程。(5.0之后改为ART虚拟机，ART运行时堆划分为四个空间，分别是Image Space、Zygote Space、Allocation Space和Large Object Space) 123graph LRActiveHeapZygoteHeap 我们知道 安卓系统的父进程是Zygote进程，它在开机的过程中就为Android系统准备好了一个Dalvik虚拟机实例。 安卓的每一个应用程序都是一个独立的进程，都有自己独立的内存空间和虚拟机实例，如果在应用启动的时候都重新为其创建虚拟机实例，是十分消耗资源的，为了加快这个速度，dalvik虚拟机采用写时拷贝的方式，将Zygote进程在开机时就创建好的Dalvik虚拟机实例，复制到应用程序的进程中去，从而加快了Android应用程序进程的启动过程。 因为zygote进程作为核心进程，应用的虚拟机实例都是复制于它，在创建虚拟机实例的时候，要预先加载安卓系统的核心方法还有一些核心类，是重量级的进程。主要做了以下四件事情：12341. 创建了一个Dalvik虚拟机实例；2. 加载了Java核心类及其JNI方法；3. 为主线程的设置了一个JNI环境；4. 注册了Android核心类的JNI方法。 这些核心类可以与应用程序共享，所以说 zygote牺牲自己的启动时间，来提高应用的加载速度。 但拷贝仍然是很费时的操作，为了避免拷贝，dalvik将自己的堆分为两部分，事实上，Dalvik虚拟机的堆最初是只有一个的。也就是Zygote进程在启动过程中创建Dalvik虚拟机的时候，只有一个堆。但是当Zygote进程在fork第一个应用程序进程之前，会将已经使用了的那部分堆内存划分为一部分，还没有使用的堆内存划分为另外一部分。前者就称为Zygote堆，后者就称为Active堆。以后无论是Zygote进程，还是应用程序进程，当它们需要分配对象的时候，都在Active堆上进行。 zygote堆 zygote进程启动创建虚拟机的时候已经用了的那部分内存，主要存的是Zygote进程在启动过程中预加载的类、资源和对象 active堆 zygote启动创建虚拟机时尚未使用的堆内存。应用程序还有zygote进程创建对象都在该堆进行 这样就可以使得Zygote堆尽可能少地被执行写操作，因而就可以减少执行写时拷贝的操作，在zygote堆中存放的预加载的类、资源和对象可以在Zygote进程和应用程序进程中做到长期共享。这样既能减少拷贝操作，还能减少对内存的需求。 2.标记机制不同 虽然dalvik虚拟机也是用的标记-清除算法，但为了减少Stop_the_world 造成的停顿，采用的并行垃圾回收算法（Concurrent GC） 标记被分为两部分 第一步 只标记gcroot 引用的对象 第二步 标记被gcroot 引用对象所引用的其他对象例如，一个栈变量引了一个对象，而这个对象又通过成员变量引用了另外一个对象，那该被引用的对象也会同时标记为正在使用。这个标记被根集对象引用的对象的过程就是第二个子阶段。 注意 在Concurrent GC，第一个子阶段是不允许垃圾收集线程之外的线程运行的，但是第二个子阶段是允许的。不过，在第二个子阶段执行的过程中，如果一个线程修改了一个对象，那么该对象必须要记录起来，因为它很有可能引用了新的对象，或者引用了之前未引用过的对象。如果不这样做的话，那么就会导致被引用对象还在使用然而却被回收。这种情况出现在只进行部分垃圾收集的情况，这时候Card Table的作用就是用来记录非垃圾收集堆对象对垃圾收集堆对象的引用。 4. 由垃圾回收机制引申的内存泄漏问题所谓内存泄漏，其实就是该回收的对象无法回收，造成无法回收的原因就是它还被gcroot直接或者间接引用。 可以看几个内存泄漏的例子 静态类123456public class A &#123; public static Context instance; public A(Context context)&#123; this.instance = context; &#125;&#125; 静态成员变量 instance 持有一个context的引用，instance是gcroot，不会被回收，它持有的context对象也不会被回收，导致内存泄漏。 匿名内部类 创建HashMap的时候， 123public class A &#123; public static List&lt;HashMap&lt;String,Object&gt;&gt; list = new ArrayList&lt;&gt;();&#125; 属于匿名创建，list中会持有外部类的引用，list又是一个gcroot，导致类A 无法被回收，另一个常见的例子：123456789101112131415public class MainActivity extends AppCompatActivity &#123; private static MyHandler handler = new MyHandler(); @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); &#125; public class MyHandler extends Handler &#123; @Override public void handleMessage(Message msg) &#123; super.handleMessage(msg); &#125; &#125;&#125; 静态成员变量handler指向Myhandler()，是GCROOT成员，但MyHandler是内部类，持有外部类MainActivity的引用，会导致MainActivity 无法被回收。 线程未结束12345678910111213141516public class MainActivity extends MainActivity &#123; void foo()&#123; Thread t = new Thread(new Runnable() &#123; @Override public void run() &#123; Activity a = MainActivity.this; ... ... &#125; &#125;); t.start(); &#125; &#125; 如果t不执行完，Activity1就无法被回收。 JNI LOCAL GLOBAL reference这类对象一般发生在参与Jni交互的类中。 比如说很多close()相关的类，InputStream,OutputStream,Cursor,SqliteDatabase等。这些对象不止被Java代码中的引用持有，也会被虚拟机中的底层代码持有。在将持有它们的引用设置为null之前，要先将他们close()掉。还有一个特殊的类是Bitmap。在Android系统3.0之前，它的内存一部分在虚拟机中，一部分在虚拟机外。因此它的一部分内存不参与垃圾回收，需要我们主动调用recycler()才能回收。 动态链接库中的内存是用C/C++语言申请的，这些内存不受虚拟机的管辖。所以，so库中的数组，类等都有可能发生内存泄漏，使用的时候务必小心。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://wenyiqingnian.xyz/categories/java基础/"}],"tags":[{"name":"java","slug":"java","permalink":"http://wenyiqingnian.xyz/tags/java/"},{"name":"垃圾回收","slug":"垃圾回收","permalink":"http://wenyiqingnian.xyz/tags/垃圾回收/"}]},{"title":"JAVA的垃圾回收策略","slug":"JAVA的垃圾回收策略","date":"2018-05-16T16:56:50.000Z","updated":"2018-05-16T16:56:24.000Z","comments":true,"path":"2018/05/17/JAVA的垃圾回收策略/","link":"","permalink":"http://wenyiqingnian.xyz/2018/05/17/JAVA的垃圾回收策略/","excerpt":"","text":"前言创建了一个对象，就意味着或早或晚，该对象都是需要 被释放掉的，只不过这个时间有长有短，对象从被new出来到被垃圾回收器回收，就是一个生命周期的完整过程，java的垃圾回收机制可以做到自动决定哪些对象是无用的从而被回收掉，无需使用者担心，但是不健壮的java代码会影响到回收算法对无效对象的识别，从而影响对象的生命周期，导致无法回收。为了弄清楚java的垃圾回收机制，有必要先搞懂下面这些概念。 java程序的生存空间： 堆与栈 堆：实例变量（成员变量）与对象的生存空间 栈：方法调用与局部变量的生存空间 注1：实例变量生命在对象内部，而不是方法内，塔代表每一个独立对象的“字段”，是存储在对象中的。 注2：局部变量生命在方法中，他们是暂时的，生命周期只限于方法被放入栈上的时间，也就是方法执行到结束的过程。 注3：方法的调用过程，是伴随方法栈入栈出栈的过程的，方法被调用，一个对应的方法堆栈块也就被放置到栈顶，这个堆栈块里除了存放局部变量和方法参数之外，还会存放方法的执行状态，包括方法执行的行数，当方法执行完毕之后，该方法堆栈块便会出栈。 如果是这样 1234567891011public static void main(String[] args)&#123; foo1();&#125;void bar()&#123;&#125;void foo2()&#123;&#125;void foo1()&#123; foo2();&#125; 方法foo1 调用了foo2 执行到调用时，会将foo2放在foo1()的栈顶上，foo1被压下去。 注4：非primitive（注5）的变量都只是对对象的引用而已，所以所有的局部变量，变量本身都是存放在方法栈空间的，当所指向的对象被实例化了，对象存放在堆空间。 注5：java的变量类型分为 primitive数据类型和 引用类型，primitive 主数据类型用来保存基本类型的值，包括整数、布尔和浮点数等，而对象引用保存的是对象的引用。 注6： 不管是实例变量还是局部变量，对象本身都是存放在堆上的 对象的创建 三部曲：声明、创建、赋值123Duck duck // 1.创建出新的引用变量duck给Duck类型= //3. 赋值该对象给引用变量new Duck(); //2. 创建该对象实例 调用new 方法，便创建了一个duck实例，这其中的过程其实是调用了类的构造方法。 注意 对象构造方法会先与对象实例被赋值给引用对象之前就执行。1234567891011public class People&#123; public People()&#123; System.out.println('people'); &#125;&#125;public class Person&#123; public static void main()&#123; People p = new People(); &#125;&#125; 会打印出people的log 对象的声明周期对象的生命周期是看对象的引用。如果还有引用，对象继续存活在堆上，如果没有引用了，对象就会被垃圾回收器回收。所以==对象的声明周期 要看引用变量的声明周期==，而引用变量的声明周期，又要看它是局部变量还是成员变量。 局部变量： 与方法声明周期同步，只活在该方法内，方法执行完毕，对象立即被释放，对其他程序和方法不可见。 成员变量： 与对象声明周期同步。如果对象活着，该成员变量也活着。关于局部变量，这里需要讲两个概念Life对象的堆栈块还在栈内，方法还没执行完，就还活着。活到方法执行完结束。 Scope局部变量的范围，只存在声明它的方法内，如果该方法调用了其他方法，则该变量仍然存活，只不过在执行调用方法的时候，该变量不在它的范围而已。 只要方法还没执行完，对象就不会死，但只有方法在栈顶，对象才是可用的。 变量的生命周期如何影响对象的生命周期？只要有活的引用，对象会一直活着，如果对某个对象的引用不在它的范围内，但该引用变量还是活的，则该对象也会活着，呆在堆内存中。如果对该对象的唯一引用没有了，对象便会回收 三种方法释放对象引用：12345678910// 方法执行完，引用便释放了void go()&#123; People p = new People();&#125;// 引用被赋值到别处People p = new People();p = new People(); //第一个对象会在此时被释放// 直接置空People p = new People();p =null; —待续 5.17 00:51","categories":[{"name":"java基础","slug":"java基础","permalink":"http://wenyiqingnian.xyz/categories/java基础/"}],"tags":[{"name":"java","slug":"java","permalink":"http://wenyiqingnian.xyz/tags/java/"},{"name":"垃圾回收","slug":"垃圾回收","permalink":"http://wenyiqingnian.xyz/tags/垃圾回收/"}]},{"title":"hexo+icarus","slug":"hexo+icarus","date":"2018-05-13T16:15:50.000Z","updated":"2018-05-24T03:40:05.000Z","comments":true,"path":"2018/05/14/hexo+icarus/","link":"","permalink":"http://wenyiqingnian.xyz/2018/05/14/hexo+icarus/","excerpt":"","text":"安装hexo1. 安装node2. 生成ssh公钥秘钥对 并且添加到github上3. 安装hexo1npm install -g hexo 4. 初始化hexo1hexo init hexo 5. 安装部署依赖文件进入hexo目录1npm install 6. 安装hexo-server1npm install hexo-server hexo-server 会创建本地服务器，你可以使用hexo s来在本地预览你的博客效果。 6. 生成hexo的目录结构1hexo generate 7. 配置_config.yml文件需要修改博客根目录的config文件，添加上你的github.io仓库地址，注意，你的ssh公钥此时应该已经添加到github上了 我的配置如下 1234deploy: type: git repository: https://github.com/QuincyJiang/QuincyJiang.github.io.git branch: master 8.目录结构以及写作流程1234567/scaffoldssource/themes.gitignore_config.ymlpackage.jsonpackage-lock.json public文件夹是每次hexo g 自动生成的网页静态代码 source中存放日志的原始md文件，每次写了新的文章，就需要将文章放置在该目录下，然后1hexo g 来生成静态网页代码，生成的代码会创建1/public 文件夹， 如果启用了 about tags categories等界面 也需要在source目录中创建对应的文件夹（about，tags，categories文件夹，内部放index.md文件，文件头以 123title: &quot;About&quot;layout: &quot;about&quot;--- 这种格式编写。 当文章写完并且已使用 1hexo g 生成public文件夹后，使用 123hexo sINFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 在浏览器输入 1localhost:4000 来本地预览博客效果。 确认无误，使用 1hexo d 部署博客到github.io仓库。 主题配置下载主题克隆你喜欢的主题到/themes文件夹内。我使用的是icarus主题 自定义主题配置 修改根目录config文件，指定主题为icarus 1theme: icarus 进入themes/icarus/目录下,修改config文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101# Menusmenu: # 配置主页上方的分类项 如果需要开启 要在博客根目录的source 文件夹下创建对应的同名文件并防止index.md 上面已经说过了 Home: . Archives: archives Categories: categories Tags: tags About: about# Customizecustomize: logo: # 左上方小logo 将png文件放在主题目录下的css/image目录下 enabled: true width: 40 height: 40 url: images/logo.png profile: enabled: true # Whether to show profile bar fixed: true avatar: css/images/avatar.png gravatar: # Gravatar email address, if you enable Gravatar, your avatar config will be overriden author: QuincyJiang author_title: Coder &amp; FilmPlayer location: Guangzhou, China follow: https://github.com/QuincyJiang highlight: androidstudio # 代码高亮风格，需要md文件格式支持，在代码块外 要显示标注代码语言 比如 ···java public static void main()&#123; ... &#125; ... sidebar: right # sidebar position, options: left, right or leave it empty thumbnail: true # enable posts thumbnail, options: true, false favicon: css/images/avatar.png social_links: github: https://github.com/QuincyJiang weibo: https://weibo.com/2425393311/ photo: http://aquencyua11.lofter.com/ social_link_tooltip: true # enable the social link tooltip, options: true, false# Widgetswidgets: - recent_posts - category - archive - tag - tagcloud - links# Search 是否启用insight搜索search: insight: true # you need to install `hexo-generator-json-content` before using Insight Search swiftype: # enter swiftype install key here baidu: false # you need to disable other search engines to use Baidu search, options: true, false# Comment 是否开启评论功能 需要disqus账号comment: # disqus: https-quincyjiang-github-io duoshuo: # enter duoshuo shortname here youyan: # enter youyan uid here facebook: # enter true to enable isso: # enter the domain name of your own comment isso server eg. comments.example.com changyan: # please fill in `appid` and `conf` to enable appid: conf: gitment: owner: #QuincyJiang repo: #https://github.com/QuincyJiang/comments.git #Register an OAuth application, and you will get a client ID and a client secret. client_id: client_secret: livere: # enter livere uid here valine: # Valine Comment System https://github.com/xCss/Valine on: # enter true to enable appId: # enter the leancloud application appId here appKey: # enter the leancloud application appKey here notify: # enter true to enable &lt;Mail notifier&gt; https://github.com/xCss/Valine/wiki/Valine-%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E9%82%AE%E4%BB%B6%E6%8F%90%E9%86%92%E8%AE%BE%E7%BD%AE verify: # enter true to enable &lt;Validation code&gt; placeholder: Just Do It # enter the comment box placeholder # Shareshare: default # options: jiathis, bdshare, addtoany, default# Pluginsplugins: lightgallery: true # options: true, false justifiedgallery: true # options: true, false google_analytics: # enter the tracking ID for your Google Analytics google_site_verification: # enter Google site verification code baidu_analytics: # enter Baidu Analytics hash key mathjax: false # options: true, false# Miscellaneousmiscellaneous: open_graph: # see http://ogp.me fb_app_id: fb_admins: twitter_id: google_plus: links: github: https://github.com/QuincyJiang 托管hexo博客源码为了保证切换电脑也可以保留原博客的风格，我们需要将博客的配置用git托管起来 1.创建hexo源码仓库去gitub 新建一个 源码仓库 1https://github.com/QuincyJiang/blog.git 2. 将博客代码使用git托管博客根目录在我们创建hexo项目的时候，就已经生成了一个gitignore文件 1234567.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/ 因为mode_modules public .deploy 文件夹都是会动态生成的，所以被添加到git忽略文件列表中了。注意，theme目录下我们克隆下来的第三方theme，它的远程仓库还是跟克隆时的目标仓库保持一致的，我们需要解除它远程仓库的关联，这样推送代码的时候才不会吧主题推送到其他地方。 a 清除第三方主题的远程仓库12cd themes/icarus/rm -rf .git b 修改主题目录下的gitignore文件因为主题的config配置文件我们也要托管起来，对博客的自定义配置主要都是在这里修改的。修改很简单 删除忽略文件中的config.yml就好了 c 创建版本库并与远程仓库链接123456cd ../../git initgit add . git remote add origin https://github/com/QuincyJiang/blog.gitgit commit -m &quot;init commit&quot;git push -u origin master 关于博客贴图一般使用md文件写博客的时候，贴图是最痛苦的事情，一般是现将图片上传到图床之后，再获取图片链接。这边安利一个软件 Mweb md文件编辑器，它可以用拖拽的方式来贴图，图片可以直接上传到github上。官网地址了解一下 用法非常简单 下载安装选择外部模式 点击右下角的加号 将hexo 博客的source文件夹添加进去编辑该folders，右键点击folder 选择图片保存路径以及路径类型 切换电脑后重新恢复博客环境克隆博客源码1git clone https://github/com/QuincyJiang/blog.git 配置基础环境123安装node安装git配置公钥到github 安装hexo1234npm install -g hexonpm install hexo --savenpm install hexo-servernpm install 至此hexo安装完成，回到熟悉的source/_post 目录愉快开始写作吧","categories":[{"name":"备忘录","slug":"备忘录","permalink":"http://wenyiqingnian.xyz/categories/备忘录/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://wenyiqingnian.xyz/tags/hexo/"}]},{"title":"六大设计模式","slug":"六大设计模式","date":"2018-05-12T16:51:50.000Z","updated":"2018-05-16T17:01:06.000Z","comments":true,"path":"2018/05/13/六大设计模式/","link":"","permalink":"http://wenyiqingnian.xyz/2018/05/13/六大设计模式/","excerpt":"","text":"设计模式六大原则（1）：单一职责原则 定义：不要存在多于一个导致类变更的原因。通俗的说，即一个类只负责一项职责。 问题由来：类T负责两个不同的职责：职责P1，职责P2。当由于职责P1需求发生改变而需要修改类T时，有可能会导致原本运行正常的职责P2功能发生故障。 解决方案：遵循单一职责原则。分别建立两个类T1、T2，使T1完成职责P1功能，T2完成职责P2功能。这样，当修改类T1时，不会使职责P2发生故障风险；同理，当修改T2时，也不会使职责P1发生故障风险。 说到单一职责原则，很多人都会不屑一顾。因为它太简单了。稍有经验的程序员即使从来没有读过设计模式、从来没有听说过单一职责原则，在设计软件时也会自觉的遵守这一重要原则，因为这是常识。在软件编程中，谁也不希望因为修改了一个功能导致其他的功能发生故障。而避免出现这一问题的方法便是遵循单一职责原则。虽然单一职责原则如此简单，并且被认为是常识，但是即便是经验丰富的程序员写出的程序，也会有违背这一原则的代码存在。为什么会出现这种现象呢？因为有职责扩散。所谓职责扩散，就是因为某种原因，职责P被分化为粒度更细的职责P1和P2。 比如：类T只负责一个职责P，这样设计是符合单一职责原则的。后来由于某种原因，也许是需求变更了，也许是程序的设计者境界提高了，需要将职责P细分为粒度更细的职责P1，P2，这时如果要使程序遵循单一职责原则，需要将类T也分解为两个类T1和T2，分别负责P1、P2两个职责。但是在程序已经写好的情况下，这样做简直太费时间了。所以，简单的修改类T，用它来负责两个职责是一个比较不错的选择，虽然这样做有悖于单一职责原则。（这样做的风险在于职责扩散的不确定性，因为我们不会想到这个职责P，在未来可能会扩散为P1，P2，P3，P4……Pn。所以记住，在职责扩散到我们无法控制的程度之前，立刻对代码进行重构。） 举例说明，用一个类描述动物呼吸这个场景： 12345678910111213class Animal&#123; public void breathe(String animal)&#123; System.out.println(animal+\"呼吸空气\"); &#125;&#125;public class Client&#123; public static void main(String[] args)&#123; Animal animal = new Animal(); animal.breathe(\"牛\"); animal.breathe(\"羊\"); animal.breathe(\"猪\"); &#125;&#125; 1234567运行结果：牛呼吸空气羊呼吸空气猪呼吸空气 程序上线后，发现问题了，并不是所有的动物都呼吸空气的，比如鱼就是呼吸水的。修改时如果遵循单一职责原则，需要将Animal类细分为陆生动物类Terrestrial，水生动物Aquatic，代码如下： 12345678910111213141516171819202122class Terrestrial&#123; public void breathe(String animal)&#123; System.out.println(animal+\"呼吸空气\"); &#125;&#125;class Aquatic&#123; public void breathe(String animal)&#123; System.out.println(animal+\"呼吸水\"); &#125;&#125;public class Client&#123; public static void main(String[] args)&#123; Terrestrial terrestrial = new Terrestrial(); terrestrial.breathe(\"牛\"); terrestrial.breathe(\"羊\"); terrestrial.breathe(\"猪\"); Aquatic aquatic = new Aquatic(); aquatic.breathe(\"鱼\"); &#125;&#125; 123456789运行结果：牛呼吸空气羊呼吸空气猪呼吸空气鱼呼吸水 我们会发现如果这样修改花销是很大的，除了将原来的类分解之外，还需要修改客户端。而直接修改类Animal来达成目的虽然违背了单一职责原则，但花销却小的多，代码如下： 12345678910111213141516171819class Animal&#123; public void breathe(String animal)&#123; if(\"鱼\".equals(animal))&#123; System.out.println(animal+\"呼吸水\"); &#125;else&#123; System.out.println(animal+\"呼吸空气\"); &#125; &#125;&#125;public class Client&#123; public static void main(String[] args)&#123; Animal animal = new Animal(); animal.breathe(\"牛\"); animal.breathe(\"羊\"); animal.breathe(\"猪\"); animal.breathe(\"鱼\"); &#125;&#125; 可以看到，这种修改方式要简单的多。但是却存在着隐患：有一天需要将鱼分为呼吸淡水的鱼和呼吸海水的鱼，则又需要修改Animal类的breathe方法，而对原有代码的修改会对调用“猪”“牛”“羊”等相关功能带来风险，也许某一天你会发现程序运行的结果变为“牛呼吸水”了。这种修改方式直接在代码级别上违背了单一职责原则，虽然修改起来最简单，但隐患却是最大的。还有一种修改方式： 12345678910111213141516171819class Animal&#123; public void breathe(String animal)&#123; System.out.println(animal+\"呼吸空气\"); &#125; public void breathe2(String animal)&#123; System.out.println(animal+\"呼吸水\"); &#125;&#125;public class Client&#123; public static void main(String[] args)&#123; Animal animal = new Animal(); animal.breathe(\"牛\"); animal.breathe(\"羊\"); animal.breathe(\"猪\"); animal.breathe2(\"鱼\"); &#125;&#125; 可以看到，这种修改方式没有改动原来的方法，而是在类中新加了一个方法，这样虽然也违背了单一职责原则，但在方法级别上却是符合单一职责原则的，因为它并没有动原来方法的代码。这三种方式各有优缺点，那么在实际编程中，采用哪一中呢？其实这真的比较难说，需要根据实际情况来确定。我的原则是：只有逻辑足够简单，才可以在代码级别上违反单一职责原则；只有类中方法数量足够少，才可以在方法级别上违反单一职责原则； 例如本文所举的这个例子，它太简单了，它只有一个方法，所以，无论是在代码级别上违反单一职责原则，还是在方法级别上违反，都不会造成太大的影响。实际应用中的类都要复杂的多，一旦发生职责扩散而需要修改类时，除非这个类本身非常简单，否则还是遵循单一职责原则的好。 遵循单一职责原的优点有： 可以降低类的复杂度，一个类只负责一项职责，其逻辑肯定要比负责多项职责简单的多； 提高类的可读性，提高系统的可维护性； 变更引起的风险降低，变更是必然的，如果单一职责原则遵守的好，当修改一个功能时，可以显著降低对其他功能的影响。 需要说明的一点是单一职责原则不只是面向对象编程思想所特有的，只要是模块化的程序设计，都适用单一职责原则。 设计模式六大原则（2）：里氏替换原则肯定有不少人跟我刚看到这项原则的时候一样，对这个原则的名字充满疑惑。其实原因就是这项原则最早是在1988年，由麻省理工学院的一位姓里的女士（Barbara Liskov）提出来的。 定义1：如果对每一个类型为 T1的对象 o1，都有类型为 T2 的对象o2，使得以 T1定义的所有程序 P 在所有的对象 o1 都代换成 o2 时，程序 P 的行为没有发生变化，那么类型 T2 是类型 T1 的子类型。 定义2：所有引用基类的地方必须能透明地使用其子类的对象。 问题由来：有一功能P1，由类A完成。现需要将功能P1进行扩展，扩展后的功能为P，其中P由原有功能P1与新功能P2组成。新功能P由类A的子类B来完成，则子类B在完成新功能P2的同时，有可能会导致原有功能P1发生故障。 解决方案：当使用继承时，遵循里氏替换原则。类B继承类A时，除添加新的方法完成新增功能P2外，尽量不要重写父类A的方法，也尽量不要重载父类A的方法。 继承包含这样一层含义：==父类中凡是已经实现好的方法（相对于抽象方法而言），实际上是在设定一系列的规范和契约，虽然它不强制要求所有的子类必须遵从这些契约，但是如果子类对这些非抽象方法任意修改，就会对整个继承体系造成破坏==。而里氏替换原则就是表达了这一层含义。 继承作为面向对象三大特性之一，在给程序设计带来巨大便利的同时，也带来了弊端。比如使用继承会给程序带来侵入性，程序的可移植性降低，增加了对象间的耦合性，如果一个类被其他的类所继承，则当这个类需要修改时，必须考虑到所有的子类，并且父类修改后，所有涉及到子类的功能都有可能会产生故障。 举例说明继承的风险，我们需要完成一个两数相减的功能，由类A来负责。 123456789101112131415161718class A&#123; public int func1(int a, int b)&#123; return a-b; &#125;&#125;public class Client&#123; public static void main(String[] args)&#123; A a = new A(); System.out.println(\"100-50=\"+a.func1(100, 50)); System.out.println(\"100-80=\"+a.func1(100, 80)); &#125;&#125; 运行结果：100-50=50100-80=20 后来，我们需要增加一个新的功能：完成两数相加，然后再与100求和，由类B来负责。即类B需要完成两个功能： 两数相减。两数相加，然后再加100。由于类A已经实现了第一个功能，所以类B继承类A后，只需要再完成第二个功能就可以了，代码如下： 12345678910111213141516171819202122232425class B extends A&#123; public int func1(int a, int b)&#123; return a+b; &#125; public int func2(int a, int b)&#123; return func1(a,b)+100; &#125;&#125;public class Client&#123; public static void main(String[] args)&#123; B b = new B(); System.out.println(\"100-50=\"+b.func1(100, 50)); System.out.println(\"100-80=\"+b.func1(100, 80)); System.out.println(\"100+20+100=\"+b.func2(100, 20)); &#125;&#125; 类B完成后，运行结果：100-50=150100-80=180100+20+100=220 我们发现原本运行正常的相减功能发生了错误。原因就是类B在给方法起名时无意中重写了父类的方法，造成所有运行相减功能的代码全部调用了类B重写后的方法，造成原本运行正常的功能出现了错误。在本例中，引用基类A完成的功能，换成子类B之后，发生了异常。在实际编程中，我们常常会通过重写父类的方法来完成新的功能，这样写起来虽然简单，但是整个继承体系的可复用性会比较差，特别是运用多态比较频繁时，程序运行出错的几率非常大。==如果非要重写父类的方法，比较通用的做法是：原来的父类和子类都继承一个更通俗的基类，原有的继承关系去掉，采用依赖、聚合，组合等关系代替==。 里氏替换原则通俗的来讲就是：子类可以扩展父类的功能，但不能改变父类原有的功能。它包含以下4层含义： 子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。 子类中可以增加自己特有的方法。 当子类的方法重载父类的方法时，方法的前置条件（即方法的形参）要比父类方法的输入参数更宽松。* 当子类的方法实现父类的抽象方法时，方法的后置条件（即方法的返回值）要比父类更严格。 看上去很不可思议，因为我们会发现在自己编程中常常会违反里氏替换原则，程序照样跑的好好的。所以大家都会产生这样的疑问，假如我非要不遵循里氏替换原则会有什么后果？ 后果就是：你写的代码出问题的几率将会大大增加。 设计模式六大原则（3）：依赖倒置原则定义： 高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象。 问题由来：类A直接依赖类B，假如要将类A改为依赖类C，则必须通过修改类A的代码来达成。这种场景下，类A一般是高层模块，负责复杂的业务逻辑；类B和类C是低层模块，负责基本的原子操作；假如修改类A，会给程序带来不必要的风险。 ### 解决方案：将类A修改为依赖接口I，类B和类C各自实现接口I，类A通过接口I间接与类B或者类C发生联系，则会大大降低修改类A的几率。 依赖倒置原则基于这样一个事实：相对于细节的多变性，抽象的东西要稳定的多。以抽象为基础搭建起来的架构比以细节为基础搭建起来的架构要稳定的多。在java中，抽象指的是接口或者抽象类，细节就是具体的实现类，使用接口或者抽象类的目的是制定好规范和契约，而不去涉及任何具体的操作，把展现细节的任务交给他们的实现类去完成。 依赖倒置原则的核心思想是==面向接口编程==，我们依旧用一个例子来说明面向接口编程比相对于面向实现编程好在什么地方。场景是这样的，母亲给孩子讲故事，只要给她一本书，她就可以照着书给孩子讲故事了。代码如下： 123456789101112131415161718192021222324class Book&#123; public String getContent()&#123; return \"很久很久以前有一个阿拉伯的故事……\"; &#125;&#125;class Mother&#123; public void narrate(Book book)&#123; System.out.println(\"妈妈开始讲故事\"); System.out.println(book.getContent()); &#125;&#125;public class Client&#123; public static void main(String[] args)&#123; Mother mother = new Mother(); mother.narrate(new Book()); &#125;&#125; 运行结果：妈妈开始讲故事很久很久以前有一个阿拉伯的故事…… 运行良好，假如有一天，需求变成这样：不是给书而是给一份报纸，让这位母亲讲一下报纸上的故事，报纸的代码如下： 12345class Newspaper&#123; public String getContent()&#123; return \"林书豪38+7领导尼克斯击败湖人……\"; &#125;&#125; 这位母亲却办不到，因为她居然不会读报纸上的故事，这太荒唐了，只是将书换成报纸，居然必须要修改Mother才能读。假如以后需求换成杂志呢？换成网页呢？还要不断地修改Mother，这显然不是好的设计。原因就是Mother与Book之间的耦合性太高了，必须降低他们之间的耦合度才行。 我们引入一个抽象的接口IReader。读物，只要是带字的都属于读物： 123456789101112131415161718192021222324252627282930313233343536373839interface IReader&#123; public String getContent();&#125; Mother类与接口IReader发生依赖关系，而Book和Newspaper都属于读物的范畴，他们各自都去实现IReader接口，这样就符合依赖倒置原则了，代码修改为：class Newspaper implements IReader &#123; public String getContent()&#123; return \"林书豪17+9助尼克斯击败老鹰……\"; &#125;&#125;class Book implements IReader&#123; public String getContent()&#123; return \"很久很久以前有一个阿拉伯的故事……\"; &#125;&#125;class Mother&#123; public void narrate(IReader reader)&#123; System.out.println(\"妈妈开始讲故事\"); System.out.println(reader.getContent()); &#125;&#125;public class Client&#123; public static void main(String[] args)&#123; Mother mother = new Mother(); mother.narrate(new Book()); mother.narrate(new Newspaper()); &#125;&#125;运行结果：妈妈开始讲故事很久很久以前有一个阿拉伯的故事……妈妈开始讲故事林书豪17+9助尼克斯击败老鹰…… 这样修改后，无论以后怎样扩展Client类，都不需要再修改Mother类了。这只是一个简单的例子，实际情况中，代表高层模块的Mother类将负责完成主要的业务逻辑，一旦需要对它进行修改，引入错误的风险极大。所以遵循依赖倒置原则可以降低类之间的耦合性，提高系统的稳定性，降低修改程序造成的风险。 采用依赖倒置原则给多人并行开发带来了极大的便利，比如上例中，原本Mother类与Book类直接耦合时，Mother类必须等Book类编码完成后才可以进行编码，因为Mother类依赖于Book类。修改后的程序则可以同时开工，互不影响，因为Mother与Book类一点关系也没有。参与协作开发的人越多、项目越庞大，采用依赖导致原则的意义就越重大。现在很流行的TDD开发模式就是依赖倒置原则最成功的应用。 传递依赖关系有三种方式，以上的例子中使用的方法是接口传递，另外还有两种传递方式：构造方法传递和setter方法传递，相信用过Spring框架的，对依赖的传递方式一定不会陌生。 在实际编程中，我们一般需要做到如下3点： 低层模块尽量都要有抽象类或接口，或者两者都有。 变量的声明类型尽量是抽象类或接口。 使用继承时遵循里氏替换原则。 依赖倒置原则的核心就是要我们面向接口编程，理解了面向接口编程，也就理解了依赖倒置。 设计模式六大原则（4）：接口隔离原则定义： 客户端不应该依赖它不需要的接口；一个类对另一个类的依赖应该建立在最小的接口上。 问题由来：类A通过接口I依赖类B，类C通过接口I依赖类D，如果接口I对于类A和类B来说不是最小接口，则类B和类D必须去实现他们不需要的方法。 解决方案：将臃肿的接口I拆分为独立的几个接口，类A和类C分别与他们需要的接口建立依赖关系。也就是采用接口隔离原则。举例来说明接口隔离原则： （图1 未遵循接口隔离原则的设计） 这个图的意思是：类A依赖接口I中的方法1、方法2、方法3，类B是对类A依赖的实现。类C依赖接口I中的方法1、方法4、方法5，类D是对类C依赖的实现。对于类B和类D来说，虽然他们都存在着用不到的方法（也就是图中红色字体标记的方法），但由于实现了接口I，所以也必须要实现这些用不到的方法。对类图不熟悉的可以参照程序代码来理解，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778interface I &#123; public void method1(); public void method2(); public void method3(); public void method4(); public void method5();&#125;class A&#123; public void depend1(I i)&#123; i.method1(); &#125; public void depend2(I i)&#123; i.method2(); &#125; public void depend3(I i)&#123; i.method3(); &#125;&#125;class B implements I&#123; public void method1() &#123; System.out.println(\"类B实现接口I的方法1\"); &#125; public void method2() &#123; System.out.println(\"类B实现接口I的方法2\"); &#125; public void method3() &#123; System.out.println(\"类B实现接口I的方法3\"); &#125; //对于类B来说，method4和method5不是必需的，但是由于接口A中有这两个方法， //所以在实现过程中即使这两个方法的方法体为空，也要将这两个没有作用的方法进行实现。 public void method4() &#123;&#125; public void method5() &#123;&#125;&#125;class C&#123; public void depend1(I i)&#123; i.method1(); &#125; public void depend2(I i)&#123; i.method4(); &#125; public void depend3(I i)&#123; i.method5(); &#125;&#125;class D implements I&#123; public void method1() &#123; System.out.println(\"类D实现接口I的方法1\"); &#125; //对于类D来说，method2和method3不是必需的，但是由于接口A中有这两个方法， //所以在实现过程中即使这两个方法的方法体为空，也要将这两个没有作用的方法进行实现。 public void method2() &#123;&#125; public void method3() &#123;&#125; public void method4() &#123; System.out.println(\"类D实现接口I的方法4\"); &#125; public void method5() &#123; System.out.println(\"类D实现接口I的方法5\"); &#125;&#125;public class Client&#123; public static void main(String[] args)&#123; A a = new A(); a.depend1(new B()); a.depend2(new B()); a.depend3(new B()); C c = new C(); c.depend1(new D()); c.depend2(new D()); c.depend3(new D()); &#125;&#125; 可以看到，如果接口过于臃肿，只要接口中出现的方法，不管对依赖于它的类有没有用处，实现类中都必须去实现这些方法，这显然不是好的设计。如果将这个设计修改为符合接口隔离原则，就必须对接口I进行拆分。在这里我们将原有的接口I拆分为三个接口，拆分后的设计如图2所示： （图2 遵循接口隔离原则的设计） 照例贴出程序的代码，供不熟悉类图的朋友参考： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061interface I1 &#123; public void method1();&#125;interface I2 &#123; public void method2(); public void method3();&#125;interface I3 &#123; public void method4(); public void method5();&#125;class A&#123; public void depend1(I1 i)&#123; i.method1(); &#125; public void depend2(I2 i)&#123; i.method2(); &#125; public void depend3(I2 i)&#123; i.method3(); &#125;&#125;class B implements I1, I2&#123; public void method1() &#123; System.out.println(\"类B实现接口I1的方法1\"); &#125; public void method2() &#123; System.out.println(\"类B实现接口I2的方法2\"); &#125; public void method3() &#123; System.out.println(\"类B实现接口I2的方法3\"); &#125;&#125;class C&#123; public void depend1(I1 i)&#123; i.method1(); &#125; public void depend2(I3 i)&#123; i.method4(); &#125; public void depend3(I3 i)&#123; i.method5(); &#125;&#125;class D implements I1, I3&#123; public void method1() &#123; System.out.println(\"类D实现接口I1的方法1\"); &#125; public void method4() &#123; System.out.println(\"类D实现接口I3的方法4\"); &#125; public void method5() &#123; System.out.println(\"类D实现接口I3的方法5\"); &#125;&#125; 接口隔离原则的含义是： 建立单一接口，不要建立庞大臃肿的接口，尽量细化接口，接口中的方法尽量少。 也就是说，我们要为各个类建立专用的接口，而不要试图去建立一个很庞大的接口供所有依赖它的类去调用。本文例子中，将一个庞大的接口变更为3个专用的接口所采用的就是接口隔离原则。在程序设计中，依赖几个专用的接口要比依赖一个综合的接口更灵活。接口是设计时对外部设定的“契约”，通过分散定义多个接口，可以预防外来变更的扩散，提高系统的灵活性和可维护性。 说到这里，很多人会觉的接口隔离原则跟之前的单一职责原则很相似，其实不然。其一，单一职责原则原注重的是职责；而接口隔离原则注重对接口依赖的隔离。其二，单一职责原则主要是约束类，其次才是接口和方法，它针对的是程序中的实现和细节；而接口隔离原则主要约束接口接口，主要针对抽象，针对程序整体框架的构建。 采用接口隔离原则对接口进行约束时，要注意以下几点： 接口尽量小，但是要有限度。对接口进行细化可以提高程序设计灵活性是不挣的事实，但是如果过小，则会造成接口数量过多，使设计复杂化。所以一定要适度。 为依赖接口的类定制服务，只暴露给调用的类它需要的方法，它不需要的方法则隐藏起来。只有专注地为一个模块提供定制服务，才能建立最小的依赖关系。 提高内聚，减少对外交互。使接口用最少的方法去完成最多的事情。 运用接口隔离原则，一定要适度，接口设计的过大或过小都不好。设计接口的时候，只有多花些时间去思考和筹划，才能准确地实践这一原则。 设计模式六大原则（5）：迪米特法则定义： 一个对象应该对其他对象保持最少的了解。 问题由来：类与类之间的关系越密切，耦合度越大，当一个类发生改变时，对另一个类的影响也越大。 解决方案：尽量降低类与类之间的耦合。 自从我们接触编程开始，就知道了软件编程的总的原则：低耦合，高内聚。无论是面向过程编程还是面向对象编程，只有使各个模块之间的耦合尽量的低，才能提高代码的复用率。低耦合的优点不言而喻，但是怎么样编程才能做到低耦合呢？那正是迪米特法则要去完成的。 迪米特法则又叫最少知道原则，最早是在1987年由美国Northeastern University的Ian Holland提出。通俗的来讲，就是一个类对自己依赖的类知道的越少越好。也就是说，对于被依赖的类来说，无论逻辑多么复杂，都尽量地的将逻辑封装在类的内部，对外除了提供的public方法，不对外泄漏任何信息。迪米特法则还有一个更简单的定义：==只与直接的朋友通信==。首先来解释一下什么是直接的朋友：==每个对象都会与其他对象有耦合关系，只要两个对象之间有耦合关系，我们就说这两个对象之间是朋友关系==。耦合的方式很多，依赖、关联、组合、聚合等。其中，我们称出现成员变量、方法参数、方法返回值中的类为直接的朋友，而出现在局部变量中的类则不是直接的朋友。也就是说，陌生的类最好不要作为局部变量的形式出现在类的内部。 举一个例子：有一个集团公司，下属单位有分公司和直属部门，现在要求打印出所有下属单位的员工ID。先来看一下违反迪米特法则的设计。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667//总公司员工class Employee&#123; private String id; public void setId(String id)&#123; this.id = id; &#125; public String getId()&#123; return id; &#125;&#125;//分公司员工class SubEmployee&#123; private String id; public void setId(String id)&#123; this.id = id; &#125; public String getId()&#123; return id; &#125;&#125;class SubCompanyManager&#123; public List&lt;SubEmployee&gt; getAllEmployee()&#123; List&lt;SubEmployee&gt; list = new ArrayList&lt;SubEmployee&gt;(); for(int i=0; i&lt;100; i++)&#123; SubEmployee emp = new SubEmployee(); //为分公司人员按顺序分配一个ID emp.setId(\"分公司\"+i); list.add(emp); &#125; return list; &#125;&#125;class CompanyManager&#123; public List&lt;Employee&gt; getAllEmployee()&#123; List&lt;Employee&gt; list = new ArrayList&lt;Employee&gt;(); for(int i=0; i&lt;30; i++)&#123; Employee emp = new Employee(); //为总公司人员按顺序分配一个ID emp.setId(\"总公司\"+i); list.add(emp); &#125; return list; &#125; public void printAllEmployee(SubCompanyManager sub)&#123; List&lt;SubEmployee&gt; list1 = sub.getAllEmployee(); for(SubEmployee e:list1)&#123; System.out.println(e.getId()); &#125; List&lt;Employee&gt; list2 = this.getAllEmployee(); for(Employee e:list2)&#123; System.out.println(e.getId()); &#125; &#125;&#125;public class Client&#123; public static void main(String[] args)&#123; CompanyManager e = new CompanyManager(); e.printAllEmployee(new SubCompanyManager()); &#125;&#125; 现在这个设计的主要问题出在CompanyManager中，根据迪米特法则，只与直接的朋友发生通信，而SubEmployee类并不是CompanyManager类的直接朋友（以局部变量出现的耦合不属于直接朋友），从逻辑上讲总公司只与他的分公司耦合就行了，与分公司的员工并没有任何联系，这样设计显然是增加了不必要的耦合。按照迪米特法则，应该避免类中出现这样非直接朋友关系的耦合。修改后的代码如下: 123456789101112131415161718192021222324252627282930313233343536373839class SubCompanyManager&#123; public List&lt;SubEmployee&gt; getAllEmployee()&#123; List&lt;SubEmployee&gt; list = new ArrayList&lt;SubEmployee&gt;(); for(int i=0; i&lt;100; i++)&#123; SubEmployee emp = new SubEmployee(); //为分公司人员按顺序分配一个ID emp.setId(\"分公司\"+i); list.add(emp); &#125; return list; &#125; public void printEmployee()&#123; List&lt;SubEmployee&gt; list = this.getAllEmployee(); for(SubEmployee e:list)&#123; System.out.println(e.getId()); &#125; &#125;&#125;class CompanyManager&#123; public List&lt;Employee&gt; getAllEmployee()&#123; List&lt;Employee&gt; list = new ArrayList&lt;Employee&gt;(); for(int i=0; i&lt;30; i++)&#123; Employee emp = new Employee(); //为总公司人员按顺序分配一个ID emp.setId(\"总公司\"+i); list.add(emp); &#125; return list; &#125; public void printAllEmployee(SubCompanyManager sub)&#123; sub.printEmployee(); List&lt;Employee&gt; list2 = this.getAllEmployee(); for(Employee e:list2)&#123; System.out.println(e.getId()); &#125; &#125;&#125; 修改后，为分公司增加了打印人员ID的方法，总公司直接调用来打印，从而避免了与分公司的员工发生耦合。 迪米特法则的初衷是降低类之间的耦合，由于每个类都减少了不必要的依赖，因此的确可以降低耦合关系。但是凡事都有度，虽然可以避免与非直接的类通信，但是要通信，必然会通过一个“中介”来发生联系，例如本例中，总公司就是通过分公司这个“中介”来与分公司的员工发生联系的。过分的使用迪米特原则，会产生大量这样的中介和传递类，导致系统复杂度变大。所以在采用迪米特法则时要反复权衡，既做到结构清晰，又要高内聚低耦合。 设计模式六大原则（6）：开闭原则定义： 一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。 问题由来：在软件的生命周期内，因为变化、升级和维护等原因需要对软件原有代码进行修改时，可能会给旧代码中引入错误，也可能会使我们不得不对整个功能进行重构，并且需要原有代码经过重新测试。 解决方案：当软件需要变化时，尽量通过扩展软件实体的行为来实现变化，而不是通过修改已有的代码来实现变化。 开闭原则是面向对象设计中最基础的设计原则，它指导我们如何建立稳定灵活的系统。开闭原则可能是设计模式六项原则中定义最模糊的一个了，它只告诉我们对扩展开放，对修改关闭，可是到底如何才能做到对扩展开放，对修改关闭，并没有明确的告诉我们。以前，如果有人告诉我“你进行设计的时候一定要遵守开闭原则”，我会觉的他什么都没说，但貌似又什么都说了。因为开闭原则真的太虚了。 在仔细思考以及仔细阅读很多设计模式的文章后，终于对开闭原则有了一点认识。其实，我们遵循设计模式前面5大原则，以及使用23种设计模式的目的就是遵循开闭原则。也就是说，只要我们对前面5项原则遵守的好了，设计出的软件自然是符合开闭原则的，这个开闭原则更像是前面五项原则遵守程度的“平均得分”，前面5项原则遵守的好，平均分自然就高，说明软件设计开闭原则遵守的好；如果前面5项原则遵守的不好，则说明开闭原则遵守的不好。 其实笔者认为，开闭原则无非就是想表达这样一层意思：用抽象构建框架，用实现扩展细节。因为抽象灵活性好，适应性广，只要抽象的合理，可以基本保持软件架构的稳定。而软件中易变的细节，我们用从抽象派生的实现类来进行扩展，当软件需要发生变化时，我们只需要根据需求重新派生一个实现类来扩展就可以了。当然前提是我们的抽象要合理，要对需求的变更有前瞻性和预见性才行。 说到这里，再回想一下前面说的5项原则，恰恰是告诉我们用抽象构建框架，用实现扩展细节的注意事项而已： 单一职责原则告诉我们实现类要职责单一； 里氏替换原则告诉我们不要破坏继承体系； 依赖倒置原则告诉我们要面向接口编程； 接口隔离原则告诉我们在设计接口的时候要精简单一； 迪米特法则告诉我们要降低耦合。 开闭原则是总纲，他告诉我们要对扩展开放，对修改关闭。 最后说明一下如何去遵守这六个原则。对这六个原则的遵守并不是是和否的问题，而是多和少的问题，也就是说，我们一般不会说有没有遵守，而是说遵守程度的多少。任何事都是过犹不及，设计模式的六个设计原则也是一样，制定这六个原则的目的并不是要我们刻板的遵守他们，而需要根据实际情况灵活运用。对他们的遵守程度只要在一个合理的范围内，就算是良好的设计。我们用一幅图来说明一下。 图中的每一条维度各代表一项原则，我们依据对这项原则的遵守程度在维度上画一个点，则如果对这项原则遵守的合理的话，这个点应该落在红色的同心圆内部；如果遵守的差，点将会在小圆内部；如果过度遵守，点将会落在大圆外部。一个良好的设计体现在图中，应该是六个顶点都在同心圆中的六边形。 在上图中，设计1、设计2属于良好的设计，他们对六项原则的遵守程度都在合理的范围内；设计3、设计4设计虽然有些不足，但也基本可以接受；设计5则严重不足，对各项原则都没有很好的遵守；而设计6则遵守过渡了，设计5和设计6都是迫切需要重构的设计。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://wenyiqingnian.xyz/categories/java基础/"}],"tags":[{"name":"java","slug":"java","permalink":"http://wenyiqingnian.xyz/tags/java/"},{"name":"设计模式","slug":"设计模式","permalink":"http://wenyiqingnian.xyz/tags/设计模式/"}]},{"title":"AnimatedVectorDrawable总结","slug":"AnimatedVectorDrawable 总结","date":"2018-05-09T16:51:50.000Z","updated":"2018-05-24T03:55:08.000Z","comments":true,"path":"2018/05/10/AnimatedVectorDrawable 总结/","link":"","permalink":"http://wenyiqingnian.xyz/2018/05/10/AnimatedVectorDrawable 总结/","excerpt":"","text":"在更新Android N之后 会注意到状态栏上的快捷方式有了新的变化 当我们点击的时候，从开启到关闭状态，会有一个顺滑自然的过渡动画，在学习完AnimatinVectorDrawable的api用法之后，你就会知道该怎么实现这些类似的效果了。 Vector在开始之前，想先说明一下安卓中的矢量图标文件Vector，我们经常会用到矢量图，将一张SVG的图片通过AS自动生成一个以vector为根节点的xml文件，可以直接通过1R.drawable.xx 的格式引用它。矢量图形不管我们如何拉伸都不会模糊，因此广受开发者青睐。看一下一个典型的vector文件结构 12345678910111213&lt;vector android:height=\"24dp\" android:viewportHeight=\"24dp\" android:viewportWidth=\"24\" android:width=\"24\" xmlns:android=\"http://schemas.android.com/apk/res/android\"&gt; &lt;path android:fillColor=\"#36ab60\" android:pathData=\"M6.4,6.4 L17.6,17.6 M6.4,17.6 L17.6 ,6.4\" android:strokeWidth=\"2\" android:strokeColor=\"#999\" android:trimPathStart=\"0.1\" android:trimPathEnd=\"0.9\"/&gt;&lt;/vector&gt; heigit/width: 图片的宽高 viewportWidth/viewportHeight: 画布宽高，也是必填的，定义Path路径的时候就必须在这个画布大小里去绘制，超出画布就显示不出来了。 path 绘制路径 主要理解几个字母代表的意思 1234M：MOVE 将画笔移动到该点L: LINE 直线连接到该点C: CURVE 曲线连接到该点Z: CLOSE 闭合曲线 strokeWidth: 线的粗细 trimPathStart: 绘制线段起始点偏移的百分比 这么说起来其实有点抽象，用一张图来解释会更加直观一些 12android:trimPathStart=\"0\"android:trimPathEnd=\"1\"/&gt; 12android:trimPathStart=\"0\"android:trimPathEnd=\"0.75\"/&gt; 12android:trimPathStart=\"0.5\"android:trimPathEnd=\"0.75\"/&gt; 123android:trimPathStart=\"0.25\"android:trimPathEnd=\"0.75\"android:trimPathOffset=\"0.25\"/&gt; 123android:trimPathStart=\"0.25\"android:trimPathEnd=\"0.75\"android:trimPathOffset=\"0.375\"/&gt; 其实这几张图片连在一起看，你会发现只要将这几个数值重复循环，这就成了一个进度条动画了。下面正式讲解文章主角 AnimatedVectorDrawable听名字其实可以猜到，它主要是靠两个东西来实现的 ObjectAnimation 属性动画：不用于补间动画，属性动画是直接对view的属性值进行动态、更改，不再只是一种视觉上的动画效果了。它实际上是一种不断地对值进行操作的机制，并将值赋值到指定对象的指定属性上，可以是任意对象的任意属性。关于属性动画的具体介绍不在本文重点，可以参考郭林的博客，属性动画完全解析 VectorDrawable 矢量图型，上文已经介绍过，不再详述 创建一个AnimatedVectorDrawable定义一个vectorDrawable1android:drawable=\"@drawable/foo\" 创建一个animation1234567&lt;ObjectAnimator android:propertyName=\"rotation\" android:valueFrom=\"0\" android:valueTo=\"180\" android:duration=\"200\" android:interpolator=\"@interpolator/...\" android:valueType=\"floatVaule\" valueFrom valueTo propertyName: 要进行变换的属性值该值有以以下几种取值 1234567891011Paths:(support-library 25.3以上 支持变换path数据)Color:Opacity:Trim start /end /offsetPath:Groups:Translate:Scale:Rotate: paths分组下我们可以对颜色 不透明度 起始点偏移量 还有path元数据进行变换 动画1 这是通过动态变换paths分组下的start end的偏移位置，做到x变为对号，同时通过groups分组下的translate 来动态改变位置图像在变化前后还保持中心位置 其实通过trim属性，我们可以做到更多炫酷的动画效果，可以先看下面这个动画 它的完整路径其实是这样的 只是通过变换trim的值，让其部分不可见便实现了上述效果 动画2 本质是将碎裂的心分为两组图片，心的填充颜色默认为白色，点击填充是更改了透明度opacity，裂开的动画是使用groups中的rotation动画 Path Morphing我们还可以直接对path元数据进行变换 1234567&lt;ObjectAnimator android:propertyName=\"pathData\" android:valueFrom=\"M6.4,6.4 L17.6,17.6 M6.4,17.6 L17.6 ,6.4\" android:valueTo=\"M6,10 L4,10 ...\" android:duration=\"200\" android:valueType=\"pathType\" ... 但进行path变换的前提是前后两条path路径 他们的绘制点数量和绘制命令必须是相同的就比如上面代码中 变换前是4个点 变换后也必须是四个点 而且 m l m l 的顺序不可以改变 上面这种 两个正方形 大小变了 形状没变，我们可以选定点的四个点作为变换参考点，只需要改变下四个点的前后坐标就可以了，绘制流程是不变的，符合要求，但如果变换前后是这样的呢？ 圆是没有顶点的，这时候只能变通一下，这样来选择四个点，同时要将连接点与点之间的命令由L （直线）改为C（曲线），这样可以通过控制贝塞尔曲线的控制点坐标，达到绘制圆弧和直线的效果。你可以通过设置更多的控制点 来达到更顺滑的变换效果 进行path变换 因为要操作控制点坐标，也带来了下面几个问题 1.无法精确获取点的坐标我们绘制的矢量图 一般用的是sketch之类的软件，它并不能让我们直接选择变换的点，比如上面的圆，只能得到一个半径和圆心坐标，无法精准的获取四个或者更多控制点的坐标 2.点与点之间无法重叠3.不能直观的看到动画中间状态的样子有时候点选择的不合理，会导致变换中间产生一些非常奇怪的形状，类似sketch之类的设计工具并不能直观看到变化中间态的样子 幸运的是 有个工具可以很好解决上述的三个问题 是一个在线预览工具，shapeshafter 官方的详细介绍 在这里我这边以创建一个-号到+号的变换动画为例，简单介绍下用法 1. 上传两张svg图片分别表示的是变换前，变换后 2.复制第二个涂层的pathdata后，删除该图层 3. 调整第一张图，选择要变换的数据是pathdata，并将变化后 也即第二张图的pathdata 粘贴进去 这时候因为“+”和“-”的节点数不一致，会报错提示，可以点击修改pathdata 按钮去手动删减增加一些节点数据 4.妥善选择好前后的节点位置，就可以点击下方播放按钮直观查看变化效果了，不满意可以修改节点，知道达到预期目标。 待续 —————–18.5.9","categories":[{"name":"CoolUI","slug":"CoolUI","permalink":"http://wenyiqingnian.xyz/categories/CoolUI/"}],"tags":[{"name":"句柄animation","slug":"句柄animation","permalink":"http://wenyiqingnian.xyz/tags/句柄animation/"},{"name":"AnimatedVectorDrawable","slug":"AnimatedVectorDrawable","permalink":"http://wenyiqingnian.xyz/tags/AnimatedVectorDrawable/"}]},{"title":"Rxjava2操作符","slug":"Rxjava2操作符","date":"2018-04-12T12:20:50.000Z","updated":"2018-05-06T14:18:23.000Z","comments":true,"path":"2018/04/12/Rxjava2操作符/","link":"","permalink":"http://wenyiqingnian.xyz/2018/04/12/Rxjava2操作符/","excerpt":"","text":"Rxjava2 操作符 Createcreate操作符，主要用于产生一个 Obserable 被观察者对象，因为Observable主要用于发射事件，Observer主要用于消费时间，所以以后统一把被观察者 Observable 称为发射器（上游事件），观察者 Observer 称为接收器（下游事件）。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253Observable.create(new ObservableOnSubscribe&lt;Integer&gt;() &#123; @Override public void subscribe(@NonNull ObservableEmitter&lt;Integer&gt; e) throws Exception &#123; mRxOperatorsText.append(\"Observable emit 1\" + \"\\n\"); Log.e(TAG, \"Observable emit 1\" + \"\\n\"); e.onNext(1); mRxOperatorsText.append(\"Observable emit 2\" + \"\\n\"); Log.e(TAG, \"Observable emit 2\" + \"\\n\"); e.onNext(2); mRxOperatorsText.append(\"Observable emit 3\" + \"\\n\"); Log.e(TAG, \"Observable emit 3\" + \"\\n\"); e.onNext(3); e.onComplete(); mRxOperatorsText.append(\"Observable emit 4\" + \"\\n\"); Log.e(TAG, \"Observable emit 4\" + \"\\n\" ); e.onNext(4); &#125; &#125;).subscribe(new Observer&lt;Integer&gt;() &#123; private int i; private Disposable mDisposable; @Override public void onSubscribe(@NonNull Disposable d) &#123; mRxOperatorsText.append(\"onSubscribe : \" + d.isDisposed() + \"\\n\"); Log.e(TAG, \"onSubscribe : \" + d.isDisposed() + \"\\n\" ); mDisposable = d; &#125; @Override public void onNext(@NonNull Integer integer) &#123; mRxOperatorsText.append(\"onNext : value : \" + integer + \"\\n\"); Log.e(TAG, \"onNext : value : \" + integer + \"\\n\" ); i++; if (i == 2) &#123; // 在RxJava 2.x 中，新增的Disposable可以做到切断的操作，让Observer观察者不再接收上游事件 mDisposable.dispose(); mRxOperatorsText.append(\"onNext : isDisposable : \" + mDisposable.isDisposed() + \"\\n\"); Log.e(TAG, \"onNext : isDisposable : \" + mDisposable.isDisposed() + \"\\n\"); &#125; &#125; @Override public void onError(@NonNull Throwable e) &#123; mRxOperatorsText.append(\"onError : value : \" + e.getMessage() + \"\\n\"); Log.e(TAG, \"onError : value : \" + e.getMessage() + \"\\n\" ); &#125; @Override public void onComplete() &#123; mRxOperatorsText.append(\"onComplete\" + \"\\n\"); Log.e(TAG, \"onComplete\" + \"\\n\" ); &#125; &#125;); MapMap 基本算是 RxJava 中一个最简单的操作符了，熟悉 RxJava 1.x 的知道，它的作用是对发射时间发送的每一个事件应用一个函数，是的每一个事件都按照指定的函数去变化，而在 2.x 中它的作用几乎一致。map 基本作用就是将一个 Observable 通过某种函数关系，转换为另一种 Observable，下面例子中就是把我们的 Integer 数据变成了 String 类型。从Log日志显而易见。 12345678910111213141516171819Observable.create(new ObservableOnSubscribe&lt;Integer&gt;() &#123; @Override public void subscribe(@NonNull ObservableEmitter&lt;Integer&gt; e) throws Exception &#123; e.onNext(1); e.onNext(2); e.onNext(3); &#125; &#125;).map(new Function&lt;Integer, String&gt;() &#123; @Override public String apply(@NonNull Integer integer) throws Exception &#123; return \"This is result \" + integer; &#125; &#125;).subscribe(new Consumer&lt;String&gt;() &#123; @Override public void accept(@NonNull String s) throws Exception &#123; mRxOperatorsText.append(\"accept : \" + s +\"\\n\"); Log.e(TAG, \"accept : \" + s +\"\\n\" ); &#125; &#125;); Zip zip 专用于合并事件，该合并不是连接（连接操作符后面会说），而是两两配对，也就意味着，最终配对出的 Observable 发射事件数目只和少的那个相同。 12345678910111213141516Observable.zip(getStringObservable(), getIntegerObservable(), new BiFunction&lt;String, Integer, String&gt;() &#123; @Override public String apply(@NonNull String s, @NonNull Integer integer) throws Exception &#123; return s + integer; &#125; &#125;).subscribe(new Consumer&lt;String&gt;() &#123; @Override public void accept(@NonNull String s) throws Exception &#123; mRxOperatorsText.append(\"zip : accept : \" + s + \"\\n\"); Log.e(TAG, \"zip : accept : \" + s + \"\\n\"); &#125; &#125;); /***注： getStringObservable 返回A B C ，getIntegerObservable返回的是1 2 3 4 5 */ 输出结果： zip 组合事件的过程就是分别从发射器 A 和发射器 B 各取出一个事件来组合，并且一个事件只能被使用一次，组合的顺序是严格按照事件发送的顺序来进行的，所以上面截图中，可以看到，1 永远是和 A 结合的，2 永远是和 B 结合的。 最终接收器收到的事件数量是和发送器发送事件最少的那个发送器的发送事件数目相同上面的例子就可以看出 结合后的事件数量是3 Concat 因为zip连接事件有上述两个特点： 121. 分别从两个发射器取一个事件组合成新事件，且事件组合顺序与发射顺序严格相同 2. 最终接受事件数量与原始发射器数量最小的那个相同 对于单一的把两个发射器连接成一个发射器，可以尝试Contact 12345678Observable.concat(Observable.just(1,2,3), Observable.just(4,5,6)) .subscribe(new Consumer&lt;Integer&gt;() &#123; @Override public void accept(@NonNull Integer integer) throws Exception &#123; mRxOperatorsText.append(\"concat : \"+ integer + \"\\n\"); Log.e(TAG, \"concat : \"+ integer + \"\\n\" ); &#125; &#125;); **输出结果 123456** FlatMap FlatMap ，它可以把一个发射器 Observable 通过某种方法转换为多个 Observables，然后再把这些分散的 Observables装进一个单一的发射器 Observable。但有个需要注意的是，flatMap ==并不能保证事件的顺序==，如果需要保证，需要用到我们下面要讲的 ConcatMap。 123456789101112131415161718192021222324252627Observable.create(new ObservableOnSubscribe&lt;Integer&gt;() &#123; @Override public void subscribe(@NonNull ObservableEmitter&lt;Integer&gt; e) throws Exception &#123; e.onNext(1); e.onNext(2); e.onNext(3); &#125; &#125;).flatMap(new Function&lt;Integer, ObservableSource&lt;String&gt;&gt;() &#123; @Override public ObservableSource&lt;String&gt; apply(@NonNull Integer integer) throws Exception &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 3; i++) &#123; list.add(\"I am value \" + integer); &#125; int delayTime = (int) (1 + Math.random() * 10); return Observable.fromIterable(list).delay(delayTime, TimeUnit.MILLISECONDS); // 使用delay操作符，做一个小延时操作，而查看 Log 日志也表明，FlatMap是无序的。 &#125; &#125;).subscribeOn(Schedulers.newThread()) .observeOn(AndroidSchedulers.mainThread()) .subscribe(new Consumer&lt;String&gt;() &#123; @Override public void accept(@NonNull String s) throws Exception &#123; Log.e(TAG, \"flatMap : accept : \" + s + \"\\n\"); mRxOperatorsText.append(\"flatMap : accept : \" + s + \"\\n\"); &#125; &#125;); 输出 12,3,3,3,2,2,1,1 concatMap 上面其实就说了，concatMap 与 FlatMap 的唯一区别就是 concatMap 保证了顺序，所以，我们就直接把 flatMap 替换为 concatMap 验证。 1234567891011121314151617181920212223242526Observable.create(new ObservableOnSubscribe&lt;Integer&gt;() &#123; @Override public void subscribe(@NonNull ObservableEmitter&lt;Integer&gt; e) throws Exception &#123; e.onNext(1); e.onNext(2); e.onNext(3); &#125; &#125;).concatMap(new Function&lt;Integer, ObservableSource&lt;String&gt;&gt;() &#123; @Override public ObservableSource&lt;String&gt; apply(@NonNull Integer integer) throws Exception &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 3; i++) &#123; list.add(\"I am value \" + integer); &#125; int delayTime = (int) (1 + Math.random() * 10); return Observable.fromIterable(list).delay(delayTime, TimeUnit.MILLISECONDS); &#125; &#125;).subscribeOn(Schedulers.newThread()) .observeOn(AndroidSchedulers.mainThread()) .subscribe(new Consumer&lt;String&gt;() &#123; @Override public void accept(@NonNull String s) throws Exception &#123; Log.e(TAG, \"flatMap : accept : \" + s + \"\\n\"); mRxOperatorsText.append(\"flatMap : accept : \" + s + \"\\n\"); &#125; &#125;); 输出结果： 11 1 1 2 2 2 3 3 3 distinct作用是去重，输入11 1 2 2 3 4 5 输出11 2 3 4 5 12345678910Observable.just(1, 1, 1, 2, 2, 3, 4, 5) .distinct() .subscribe(new Consumer&lt;Integer&gt;() &#123; @Override public void accept(@NonNull Integer integer) throws Exception &#123; mRxOperatorsText.append(\"distinct : \" + integer + \"\\n\"); Log.e(TAG, \"distinct : \" + integer + \"\\n\"); &#125; &#125;); FilterFilter 过滤器，可以接受一个参数，让其过滤掉不符合我们条件的值 12345678910111213Observable.just(1, 20, 65, -5, 7, 19) .filter(new Predicate&lt;Integer&gt;() &#123; @Override public boolean test(@NonNull Integer integer) throws Exception &#123; return integer &gt;= 10; &#125; &#125;).subscribe(new Consumer&lt;Integer&gt;() &#123; @Override public void accept(@NonNull Integer integer) throws Exception &#123; mRxOperatorsText.append(\"filter : \" + integer + \"\\n\"); Log.e(TAG, \"filter : \" + integer + \"\\n\"); &#125; &#125;); 输出大于10的事件 120 65 19 buffer buffer 操作符接受两个参数，buffer(count,skip)作用是将 Observable 中的数据按 skip (步长) 分成最大不超过 count 的 buffer ，然后生成一个 Observable 。也就是说 ==按照步长，将原始事件 分成一组一组 重新发射出去== 1234567891011121314151617Observable.just(1, 2, 3, 4, 5) .buffer(3, 2) .subscribe(new Consumer&lt;List&lt;Integer&gt;&gt;() &#123; @Override public void accept(@NonNull List&lt;Integer&gt; integers) throws Exception &#123; mRxOperatorsText.append(\"buffer size : \" + integers.size() + \"\\n\"); Log.e(TAG, \"buffer size : \" + integers.size() + \"\\n\"); mRxOperatorsText.append(\"buffer value : \"); Log.e(TAG, \"buffer value : \" ); for (Integer i : integers) &#123; mRxOperatorsText.append(i + \"\"); Log.e(TAG, i + \"\"); &#125; mRxOperatorsText.append(\"\\n\"); Log.e(TAG, \"\\n\"); &#125; &#125;); 输出结果 123456size 3value 1 2 3 size 3value 3 4 5 size 1 value 5 timer timer，相当于一个定时任务。在 1.x 中它还可以执行间隔逻辑，但在 2.x 中此功能被交给了 interval。但需要注意的是，timer 和 interval 均==默认在新线程==。==执行timer方法，将使得接受延时== 123456789101112mRxOperatorsText.append(\"timer start : \" + TimeUtil.getNowStrTime() + \"\\n\"); Log.e(TAG, \"timer start : \" + TimeUtil.getNowStrTime() + \"\\n\"); Observable.timer(2, TimeUnit.SECONDS) .subscribeOn(Schedulers.io()) .observeOn(AndroidSchedulers.mainThread()) // timer 默认在新线程，所以需要切换回主线程 .subscribe(new Consumer&lt;Long&gt;() &#123; @Override public void accept(@NonNull Long aLong) throws Exception &#123; mRxOperatorsText.append(\"timer :\" + aLong + \" at \" + TimeUtil.getNowStrTime() + \"\\n\"); Log.e(TAG, \"timer :\" + aLong + \" at \" + TimeUtil.getNowStrTime() + \"\\n\"); &#125; &#125;); 当我们两次点击按钮触发这个事件的时候，接收被延迟了 2 秒。 interval 如同我们上面可说，interval 操作符用于间隔时间执行某个操作，其接受三个参数，分别是第一次发送延迟，间隔时间，时间单位。 123456789101112mRxOperatorsText.append(\"interval start : \" + TimeUtil.getNowStrTime() + \"\\n\"); Log.e(TAG, \"interval start : \" + TimeUtil.getNowStrTime() + \"\\n\"); Observable.interval(3,2, TimeUnit.SECONDS) .subscribeOn(Schedulers.io()) .observeOn(AndroidSchedulers.mainThread()) // 由于interval默认在新线程，所以我们应该切回主线程 .subscribe(new Consumer&lt;Long&gt;() &#123; @Override public void accept(@NonNull Long aLong) throws Exception &#123; mRxOperatorsText.append(\"interval :\" + aLong + \" at \" + TimeUtil.getNowStrTime() + \"\\n\"); Log.e(TAG, \"interval :\" + aLong + \" at \" + TimeUtil.getNowStrTime() + \"\\n\"); &#125; &#125;); 执行结果是第一次延迟了 3 秒后接收到，后面每次间隔了 2 秒。然而，由于我们这个是间隔执行，所以当我们的Activity 都销毁的时候，==实际上这个操作还依然在进行==，查看源码发现，我们1subscribe(Cousumer&lt;? super T&gt; onNext) 返回的是Disposable，Disposable 可以用来解除绑定。 1234567891011121314151617181920212223@Override protected void doSomething() &#123; mRxOperatorsText.append(\"interval start : \" + TimeUtil.getNowStrTime() + \"\\n\"); Log.e(TAG, \"interval start : \" + TimeUtil.getNowStrTime() + \"\\n\"); mDisposable = Observable.interval(3, 2, TimeUnit.SECONDS) .subscribeOn(Schedulers.io()) .observeOn(AndroidSchedulers.mainThread()) // 由于interval默认在新线程，所以我们应该切回主线程 .subscribe(new Consumer&lt;Long&gt;() &#123; @Override public void accept(@NonNull Long aLong) throws Exception &#123; mRxOperatorsText.append(\"interval :\" + aLong + \" at \" + TimeUtil.getNowStrTime() + \"\\n\"); Log.e(TAG, \"interval :\" + aLong + \" at \" + TimeUtil.getNowStrTime() + \"\\n\"); &#125; &#125;); &#125; @Override protected void onDestroy() &#123; super.onDestroy(); if (mDisposable != null &amp;&amp; !mDisposable.isDisposed()) &#123; mDisposable.dispose(); &#125; &#125; doOnNext doOnNext 它的作用是让订阅者在接收到数据之前做一些其他操作。假如我们在获取到数据之前想先保存一下它，无疑我们可以这样实现。 1234567891011121314Observable.just(1, 2, 3, 4) .doOnNext(new Consumer&lt;Integer&gt;() &#123; @Override public void accept(@NonNull Integer integer) throws Exception &#123; mRxOperatorsText.append(\"doOnNext 保存 \" + integer + \"成功\" + \"\\n\"); Log.e(TAG, \"doOnNext 保存 \" + integer + \"成功\" + \"\\n\"); &#125; &#125;).subscribe(new Consumer&lt;Integer&gt;() &#123; @Override public void accept(@NonNull Integer integer) throws Exception &#123; mRxOperatorsText.append(\"doOnNext :\" + integer + \"\\n\"); Log.e(TAG, \"doOnNext :\" + integer + \"\\n\"); &#125; &#125;); skip skip ，接受一个 long 型参数 count ，代表跳过 count 个数目开始接收。 123456789Observable.just(1,2,3,4,5) .skip(2) .subscribe(new Consumer&lt;Integer&gt;() &#123; @Override public void accept(@NonNull Integer integer) throws Exception &#123; mRxOperatorsText.append(\"skip : \"+integer + \"\\n\"); Log.e(TAG, \"skip : \"+integer + \"\\n\"); &#125; &#125;); 输出： 13 4 5 take take，接受一个 long 型参数 count ，代表至多接收 count 个数据。 123456789Flowable.fromArray(1,2,3,4,5) .take(2) .subscribe(new Consumer&lt;Integer&gt;() &#123; @Override public void accept(@NonNull Integer integer) throws Exception &#123; mRxOperatorsText.append(\"take : \"+integer + \"\\n\"); Log.e(TAG, \"accept: take : \"+integer + \"\\n\" ); &#125; &#125;); 输出： 11 2 just just一个简单的发射器依次调用 onNext() 方法。 12345678910Observable.just(\"1\", \"2\", \"3\") .subscribeOn(Schedulers.io()) .observeOn(AndroidSchedulers.mainThread()) .subscribe(new Consumer&lt;String&gt;() &#123; @Override public void accept(@NonNull String s) throws Exception &#123; mRxOperatorsText.append(\"accept : onNext : \" + s + \"\\n\"); Log.e(TAG,\"accept : onNext : \" + s + \"\\n\" ); &#125; &#125;); 输出： 11 2 3 Single 顾名思义，Single 只会接收一个参数，也就是只发射一次事件，他的而 SingleObserver 只会调用 onError() 或者 onSuccess()。 12345678910111213141516171819Single.just(new Random().nextInt()) .subscribe(new SingleObserver&lt;Integer&gt;() &#123; @Override public void onSubscribe(@NonNull Disposable d) &#123; &#125; @Override public void onSuccess(@NonNull Integer integer) &#123; mRxOperatorsText.append(\"single : onSuccess : \"+integer+\"\\n\"); Log.e(TAG, \"single : onSuccess : \"+integer+\"\\n\" ); &#125; @Override public void onError(@NonNull Throwable e) &#123; mRxOperatorsText.append(\"single : onError : \"+e.getMessage()+\"\\n\"); Log.e(TAG, \"single : onError : \"+e.getMessage()+\"\\n\"); &#125; &#125;); 输出： 1onSuccess distinct 去重操作符，简单的作用就是去重。 123456789Observable.just(1, 1, 1, 2, 2, 3, 4, 5) .distinct() .subscribe(new Consumer&lt;Integer&gt;() &#123; @Override public void accept(@NonNull Integer integer) throws Exception &#123; mRxOperatorsText.append(\"distinct : \" + integer + \"\\n\"); Log.e(TAG, \"distinct : \" + integer + \"\\n\"); &#125; &#125;); 输出： 11 2 3 4 5 发射器发送的事件，在接收的时候被去重了。 debounce 去除发送频率过快的项，可以用来过滤点击过快的点击事件 1234567891011121314151617181920212223242526Observable.create(new ObservableOnSubscribe&lt;Integer&gt;() &#123; @Override public void subscribe(@NonNull ObservableEmitter&lt;Integer&gt; emitter) throws Exception &#123; // send events with simulated time wait emitter.onNext(1); // skip Thread.sleep(400); emitter.onNext(2); // deliver Thread.sleep(505); emitter.onNext(3); // skip Thread.sleep(100); emitter.onNext(4); // deliver Thread.sleep(605); emitter.onNext(5); // deliver Thread.sleep(510); emitter.onComplete(); &#125; &#125;).debounce(500, TimeUnit.MILLISECONDS) .subscribeOn(Schedulers.io()) .observeOn(AndroidSchedulers.mainThread()) .subscribe(new Consumer&lt;Integer&gt;() &#123; @Override public void accept(@NonNull Integer integer) throws Exception &#123; mRxOperatorsText.append(\"debounce :\" + integer + \"\\n\"); Log.e(TAG,\"debounce :\" + integer + \"\\n\"); &#125; &#125;); 输出： 12 4 5 代码很清晰，去除发送间隔时间小于 500 毫秒的发射事件，所以 1 和 3 被去掉了。 defer ==直到有订阅，才会创建Observable==具有延时的效果。 代码对比如下： 12345678910a = 10;Observable&lt;String&gt; o1 = Observable.just(\"just result: \" + a);a = 12;o1.subscribe(new Action1&lt;String&gt;() &#123; @Override public void call(String t) &#123; System.out.println(t); &#125;&#125;); 输出： 1just result: 10 可见：在使用just的时候，便创建了Observable对象，随后改变a的值，并不会改变Observable对象中的值。 使用defer 123456789101112131415161718a = 12;Observable&lt;String&gt; o2 = Observable.defer(new Func0&lt;Observable&lt;String&gt;&gt;() &#123; @Override public Observable&lt;String&gt; call() &#123; return Observable.just(\"defer result: \" + a); &#125;&#125;);a = 20;o2.subscribe(new Action1&lt;String&gt;() &#123; @Override public void call(String t) &#123; System.out.println(t); &#125; &#125;); 输出： 1defer result: 20 可见：在a=12时，虽然定义了一个Observable，但是并没有创建这个示例，当a=20时，这时候订阅这个Observable，则开始创建，所以对象中的a为20. last last 操作符仅取出可观察到的最后一个值，或者是满足某些条件的最后一项。 123456789Observable.just(1, 2, 3) .last() .subscribe(new Consumer&lt;Integer&gt;() &#123; @Override public void accept(@NonNull Integer integer) throws Exception &#123; mRxOperatorsText.append(\"last : \" + integer + \"\\n\"); Log.e(TAG, \"last : \" + integer + \"\\n\"); &#125; &#125;); 输出：13 merge merge 顾名思义 在 Rx 操作符中，merge 的作用是把多个 Observable 结合起来，接受可变参数，也支持迭代器集合。注意它和 concat 的区别在于，==不用等到 发射器 A 发送完所有的事件再进行发射器 B 的发送==。 12345678Observable.merge(Observable.just(1, 2), Observable.just(3, 4, 5)) .subscribe(new Consumer&lt;Integer&gt;() &#123; @Override public void accept(@NonNull Integer integer) throws Exception &#123; mRxOperatorsText.append(\"merge :\" + integer + \"\\n\"); Log.e(TAG, \"accept: merge :\" + integer + \"\\n\" ); &#125; &#125;); 输出： 11 2 3 4 5 reduce reduce 操作符每次用一个方法处理一个值，可以有一个 seed 作为初始值。 12345678910111213Observable.just(1, 2, 3) .reduce(new BiFunction&lt;Integer, Integer, Integer&gt;() &#123; @Override public Integer apply(@NonNull Integer integer, @NonNull Integer integer2) throws Exception &#123; return integer + integer2; &#125; &#125;).subscribe(new Consumer&lt;Integer&gt;() &#123; @Override public void accept(@NonNull Integer integer) throws Exception &#123; mRxOperatorsText.append(\"reduce : \" + integer + \"\\n\"); Log.e(TAG, \"accept: reduce : \" + integer + \"\\n\"); &#125; &#125;); 输出：16 可以看到，代码中，我们中间采用 reduce ，支持一个 function 为两数值相加，所以应该最后的值是：1 + 2 = 3 + 3 = 6 ， scan scan 操作符作用和上面的 reduce 一致，唯一区别是 reduce 是个只追求结果的坏人，而 scan 会始终如一地把每一个步骤都输出。 12345678910111213Observable.just(1, 2, 3) .scan(new BiFunction&lt;Integer, Integer, Integer&gt;() &#123; @Override public Integer apply(@NonNull Integer integer, @NonNull Integer integer2) throws Exception &#123; return integer + integer2; &#125; &#125;).subscribe(new Consumer&lt;Integer&gt;() &#123; @Override public void accept(@NonNull Integer integer) throws Exception &#123; mRxOperatorsText.append(\"scan \" + integer + \"\\n\"); Log.e(TAG, \"accept: scan \" + integer + \"\\n\"); &#125; &#125;); 输出： 11 3 6 window 按照实际划分窗口，将数据发送给不同的 Observable 1234567891011121314151617181920212223mRxOperatorsText.append(\"window\\n\"); Log.e(TAG, \"window\\n\"); Observable.interval(1, TimeUnit.SECONDS) // 间隔一秒发一次 .take(15) // 最多接收15个 .window(3, TimeUnit.SECONDS) .subscribeOn(Schedulers.io()) .observeOn(AndroidSchedulers.mainThread()) .subscribe(new Consumer&lt;Observable&lt;Long&gt;&gt;() &#123; @Override public void accept(@NonNull Observable&lt;Long&gt; longObservable) throws Exception &#123; mRxOperatorsText.append(\"Sub Divide begin...\\n\"); Log.e(TAG, \"Sub Divide begin...\\n\"); longObservable.subscribeOn(Schedulers.io()) .observeOn(AndroidSchedulers.mainThread()) .subscribe(new Consumer&lt;Long&gt;() &#123; @Override public void accept(@NonNull Long aLong) throws Exception &#123; mRxOperatorsText.append(\"Next:\" + aLong + \"\\n\"); Log.e(TAG, \"Next:\" + aLong + \"\\n\"); &#125; &#125;); &#125; &#125;); 输出：","categories":[{"name":"Android","slug":"Android","permalink":"http://wenyiqingnian.xyz/categories/Android/"}],"tags":[{"name":"android","slug":"android","permalink":"http://wenyiqingnian.xyz/tags/android/"},{"name":"开源框架","slug":"开源框架","permalink":"http://wenyiqingnian.xyz/tags/开源框架/"},{"name":"rxjava2","slug":"rxjava2","permalink":"http://wenyiqingnian.xyz/tags/rxjava2/"}]},{"title":"socket未释放导致句柄泄露","slug":"Socket未释放导致的句柄泄露","date":"2018-03-16T11:40:50.000Z","updated":"2018-05-06T13:28:37.000Z","comments":true,"path":"2018/03/16/Socket未释放导致的句柄泄露/","link":"","permalink":"http://wenyiqingnian.xyz/2018/03/16/Socket未释放导致的句柄泄露/","excerpt":"","text":"问题描述客户反馈话机的voipsdk demo在运行起来之后 放置不动，几小时过后，应用进行任何操作都会崩溃。通过logcat 报错信息 发现出现了句柄泄露。通过ls -l /proc//fd可以查看到在demo进程下，持有的socket数量会规律性上升。 12345lrwx------ system system 2018-03-08 14:11 60 -&gt; socket:[4027431]lrwx------ system system 2018-03-08 14:11 61 -&gt; socket:[4025517]lrwx------ system system 2018-03-08 14:11 62 -&gt; socket:[4028038]lrwx------ system system 2018-03-08 14:11 63 -&gt; socket:[4028322]lrwx------ system system 2018-03-08 14:11 64 -&gt; socket:[4026799] 大概十秒增加一个，一直到超出安卓规定的数量，此时由于已无可用fd句柄，在进行任何操作都会因无可用句柄直接导致崩溃。 可以看到新增socket的inode号码之后，通过查找/proc/net/tcp(udp对应/proc/net/udp)文件，其中也列出了相应socket的inode号，通过比对此字段，我在/proc/net/tcp下获得此套接口的其他信息，对应的&lt;本地地址：端口号，远端地址：端口号&gt;对，窗口大小，状态等信息。具体字段含义详见net/ipv4/tcp_ipv4.c 中的 tcp4_seq_show 函数。cat /proc/net/tcp 如下： 12345678root@TOS_IP:/proc/net # cat tcp6 sl local_address remote_address st tx_queue rx_queue tr tm-&gt;when retrnsmt uid timeout inode 0: 0000000000000000FFFF00007665A8C0:D483 0000000000000000FFFF00009F173379:0050 08 00000000:00000001 00:00000000 00000000 10077 0 3660979 1 00000000 25 4 30 10 -1 1: 0000000000000000FFFF00007665A8C0:E595 0000000000000000FFFF0000DCD5B276:0050 08 00000000:00000001 00:00000000 00000000 10077 0 3661419 1 00000000 24 4 28 10 -1 2: 0000000000000000FFFF00007665A8C0:81EC 0000000000000000FFFF00009F173379:0050 08 00000000:00000001 00:00000000 00000000 1000 0 4019721 1 00000000 23 4 30 10 -1 3: 0000000000000000FFFF00007665A8C0:B885 0000000000000000FFFF0000F28D0D6F:0050 08 00000000:00000001 00:00000000 00000000 1000 0 3659952 1 00000000 26 4 30 10 -1 4: 0000000000000000FFFF00007665A8C0:8AD0 0000000000000000FFFF00009F173379:0050 08 00000000:00000001 00:00000000 00000000 1000 0 4018811 1 00000000 24 4 30 10 -1 5: 0000000000000000FFFF00007665A8C0:E83C 0000000000000000FFFF00009F173379:0050 08 00000000:00000001 00:00000000 00000000 1000 0 4018828 1 00000000 23 4 30 10 -1 将本端16进制端口号转化为10进制可以看到是一个与8080端口在通信的socket。 目前初步猜测是端口争夺导致demo没有获取到端口，就会隔段时间重试去申请该端口。 首先去java端排除，全局搜索发现并没有找到对应的8080端口申请情况 那就只有可能是linphone库里或者webrtc库里做了8080相关的操作了。 请linphone端的李工排查，发现在一段前离职同事的代码里，有一段申请8080端口的相关操作。查看了一下，发现和猜测的一致，因为要和底层通讯，同事使用了socket并通过8080端口，但是在申请资源后并未释放改socket，当系统自带的拨号服务起来之后，因为系统自带拨号和sdk的demo使用的linphone库是相同的，导致两个进程都在抢占8080，那个进程服务先拿到，另一个进程就拿不到该端口，会隔10s重新发起申请，但是之前创建的socket又没有释放，就会导致句柄泄露。 我将系统自带的拨号进程彻底杀死，同事运行起demo，然后再将系统拨号运行起来，发现这时候 系统自带拨号也出现了句柄泄露。而demo就没有出现过了。 应征我之前的猜测。解决这个问题就很简单了，在linphone的代码里将改socket释放。","categories":[{"name":"bug记录","slug":"bug记录","permalink":"http://wenyiqingnian.xyz/categories/bug记录/"}],"tags":[{"name":"句柄泄露","slug":"句柄泄露","permalink":"http://wenyiqingnian.xyz/tags/句柄泄露/"},{"name":"bugs","slug":"bugs","permalink":"http://wenyiqingnian.xyz/tags/bugs/"}]},{"title":"线程阻塞和中断的四种方式","slug":"线程阻塞和中断的四种方式","date":"2018-03-13T12:46:25.000Z","updated":"2018-05-06T14:15:08.000Z","comments":true,"path":"2018/03/13/线程阻塞和中断的四种方式/","link":"","permalink":"http://wenyiqingnian.xyz/2018/03/13/线程阻塞和中断的四种方式/","excerpt":"","text":"1、线程阻塞一个线程进入阻塞状态可能的原因： 通过调用sleep(millseconds)使任务进入休眠状态；123456789101112class Demo1 implements Runnable throws InterruptedException&#123; public void run()&#123; Thread.sleep(1000); &#125;&#125;②通过调用wait（）使线程挂起，直到线程获取notify（）/notifyAll（）消息，（或者在Java SE5中java.util.concurrent类库中等价的signal（）/signalAll（）消息），线程才会进入就绪状态；class Demo2 implements Runnable&#123; public void run()&#123; Thread.await(); Thread.notify(); &#125;&#125; 任务在等待某个输入 / 输出流的完成；123456class Demo3 implements Runnable throws InterruptedException&#123; private InputStream in; public void run()&#123; in.read(); &#125;&#125; 任务试图在某个对象上调用其同步控制方法，但是对象锁不可用，因为另一个任务已经获取了该锁；1234567class Demo4 implements Runnable&#123; public synchronized void method1()&#123; &#125; public synchronized void method2()&#123; &#125; public void run()&#123; method1(); &#125;&#125; 2、线程中断的方法Thread类包含interrupt（）方法，用于终止阻塞任务； 1）中断①②类线程休眠，挂起阻塞的方法1.直接使用Thread.interrupt();1234main()&#123; Thread t = new Thread(new Demo1()); t.interrupt();&#125; 2.使用Executor线程池，中断线程池中的所有线程；123456main()&#123; ExecutorService exec = Executors.newCachedThreadPool(); for(int i=0;i&lt;5;i++) exec.execute(new Demo1()) exec.shutdownNow();&#125; 3.使用Executor线程池，中断线程池中单个阻塞的线程；12345main()&#123; ExecutorService exec = Executors.newCachedThreadPool(); Futrue&lt;?&gt; f = exec.submit(new Demo1()); f.interrupt();&#125; //中断后的清除代码放置在InterruptedException异常的catch捕获的代码块中 2）中断③类I/O阻塞的方法使用Thread.iterrupt方法无法中断I/O阻塞，这对于基于Web的程序是很不利的； 有一种解决方法：关闭任务在其上发生阻塞的底层资源；123456789101112main()&#123; ExecutorService exec = Executors.newCachedThreadPool(); ServerSocket server = new ServerSocket(8080); InputStream socketInput = new Socket(\"localhost\",8080) exec.execute(socketInput); exec.execute(Sytsem.in); //exec.shutdownNow(); 无法中断2个线程； socketInput.close(); in.close(); exec.shutdownNow();&#125; java.nio类库提供了更加人性化的I/O中断，被阻塞的nio通道会自动地响应中断；12345678910111213141516171819202122232425262728class Demo impelenets Runnable&#123; private final SocketChannel sc; public Demo(SocketChannel sc)&#123; this.sc = sc;&#125; public void run()&#123; try&#123; sc.read(ByteBuffer.allocate(1)); &#125;catch(CloseByInteruptedException e1)&#123; &#125;catch(AsyncronousCloseException e2)&#123; &#125;catch(IOException e3)&#123; &#125; &#125;&#125;public Test &#123; public static void main()&#123; ExecutorService exec = Executors.newCachedThreadPool(); ServerSocket server = new ServerSocket(8080); InetSocketAddress isa = new InetSocketAddress(\"localhost\",8080); SocketChannel sc1 = new SocketChannel.open(isa); SocketChannel sc2 = new SocketChannel.open(isa); exec.execute(new Demo(sc1)); Future&lt;?&gt; f = exec.submit(new Demo(sc2)); f.cancel(true); //可以终止sc1通道所在的线程； exec.shutdownNow(); //可以终止exec线程池内所有的线程； sc1.close(); sc2.close(); &#125;&#125; 3）中断④类被互斥阻塞的线程使用Thread.iterrupt方法无法中断互斥类线程， 解决方式1：可以使用ReentrantLock显式加锁，在JavaSE5中引入的新特性，ReentrantLock上阻塞的任务可以被中断；123456789101112131415161718class Task imlements Runnable&#123; private Lock lock = new ReentrantLock(); public void run()&#123; lock.lock(); try&#123; while(true) &#125;catch(InterruptedExcpetion e)&#123; System.out.println(\"The Task is interrupted!\"); &#125;finally&#123; lock.unlock(); &#125; &#125; public void main()&#123; Thread t = new Thread(new Task()); t.start(); t.interrupt(); &#125;&#125; 解决方式2：使用一个while（！Thread.interrupted（））包裹同步的代码块123456789101112131415161718class Task impelments Runnable&#123; private synchronized void method1()&#123; &#125; public void run()&#123; try&#123; whlie(!Thread.interrupted()) method1(); &#125;catch(InteruptedException e)&#123; &#125; &#125; public static void main()&#123; ExecutorService exec = Executors.newCachedThreadPool(); exec.execute(new Task()); exec.shutdownNow(); //线程被打断 /*或 Thread t = new Thread(new Task()); t.start(); t.interrupt(); */ &#125;&#125;","categories":[{"name":"java基础","slug":"java基础","permalink":"http://wenyiqingnian.xyz/categories/java基础/"}],"tags":[{"name":"java","slug":"java","permalink":"http://wenyiqingnian.xyz/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"http://wenyiqingnian.xyz/tags/多线程/"}]},{"title":"mac搭建Pyqt5环境","slug":"mac搭建PyQt5环境","date":"2017-12-11T12:30:50.000Z","updated":"2018-05-06T13:25:36.000Z","comments":true,"path":"2017/12/11/mac搭建PyQt5环境/","link":"","permalink":"http://wenyiqingnian.xyz/2017/12/11/mac搭建PyQt5环境/","excerpt":"","text":"1.首先基于virtualenv 搭建一个python3的运行环境virtualenv是一个十分好用的python工具，可以为不同的软件创建独立的“隔离”的Python运行环境。 1. 首先，我们用pip安装virtualenv：1$ pip3 install virtualenv 2.创建一个pyhton3的运行环境1jiangxqdeMBP:~ jiangxq$ virtualenv py3 --python=python3 可以通过python=python3来指定要安装的python版本，python3是mac的写法，其他linux系统需要制定为python2.7 或者python3.6 3. 激活该运行环境执行 12jiangxqdeMBP:~ jiangxq$ source ~/py3/bin/activate(py3) jiangxqdeMBP:~ jiangxq$ 当用户名前出现该运行环境的名称时，表示环境已经激活了 2. 检查pip工具的版本 目前最新的为9.0.2 需要更新请 执行1pip3 install --upgrade pip 这里有个窍门是如果mac的默认python运行环境为python2.7，但是不想修改注册文件，可以直接打pip3，pip3是是python3的pip工具，pip是python2的pip工具。 3. 使用pip工具安装PyQt51pip3 install PyQt5 当PyQt5安装完成之后，其实Qt的组件此时已经可用了，如果要测试是否安装成功，可以新建一个Python项目，然后倒入PyQt5的包看看。 4.在pycharm上安装QtDesign工具包QtDesign是Pycharm上的可视化uI设计工具，可以拖动控件来达到实现设计界面的功能安装Qtdesign 需要先安装QT 1. 下载QT安装包下载地址：http://iso.mirrors.ustc.edu.cn/qtproject/archive/qt/5.10/5.10.1/qt-opensource-mac-x64-5.10.1.dmg下载完成后直接安装 2.打开pycharm 点击preference 点击Tools 新建一个插件 注意插件地址不要写错了，是qt5的安装路径 3. 创建PyUIC 插件（将pydesigner的布局自动转化为python代码）","categories":[{"name":"python","slug":"python","permalink":"http://wenyiqingnian.xyz/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://wenyiqingnian.xyz/tags/python/"},{"name":"qt","slug":"qt","permalink":"http://wenyiqingnian.xyz/tags/qt/"}]},{"title":"MQTT相关总结","slug":"MQTT相关","date":"2017-12-11T12:30:50.000Z","updated":"2018-05-09T16:54:08.000Z","comments":true,"path":"2017/12/11/MQTT相关/","link":"","permalink":"http://wenyiqingnian.xyz/2017/12/11/MQTT相关/","excerpt":"","text":"MQTT相关MQTT官网：http://mqtt.org/ MQTT介绍：http://www.ibm.com MQTT Android github：https://github.com/eclipse/paho.mqtt.android MQTT API：http://www.eclipse.org/paho/files/javadoc/index.html MQTT Android API： http://www.eclipse.org/paho/files/android-javadoc/index.html MQTT服务器搭建 环境：windows7 64位 JAVA环境:jdk 1.8.0 下载：Apollo服务器 以下为步骤： 下载Apollo服务器后，解压安装； 用命令行进入到安装目录bin目录下 输入 apollo create xxx (xxx为服务器实例名，eg.apollo create xmaihh) 执行之后会在bin目录下创建名称为xxx的文件夹，比如我生成的文件夹是 xmaihhxxx文件夹下etc\\apollo.xml文件是 配置服务器文件信息etc\\users.properties文件包含连接MQTT服务器时用到的用户名和密码，默认为admin=password，即账号为admin，密码为password，可自行更改。 用命令行进入到刚创建的xxx\\bin目录下，输入apollo-broker.cmd run开启服务器 在浏览器输入http://127.0.0.1:61680/，查看是否安装成功MQTT Android客户端 环境：AndroidStudio 3.0.1 topic：中文意思是“话题”。在MQTT中订阅了(subscribe)同一话题（topic）的客户端会同时收到消息推送。 clientId：客户身份唯一标识。 qos：服务质量。 retained：要保留最后的断开连接信息。 MqttAndroidClient#subscribe()：订阅某个话题。 MqttAndroidClient#publish()： 向某个话题发送消息，之后服务器会推送给所有订阅了此话题的客户。 userName：连接到MQTT服务器的用户名。 passWord ：连接到MQTT服务器的密码 以下为步骤： 添加依赖 123456789repositories &#123; maven &#123; url &quot;https://repo.eclipse.org/content/repositories/paho-snapshots/&quot; &#125;&#125;dependencies &#123; compile &apos;org.eclipse.paho:org.eclipse.paho.client.mqttv3:1.1.0&apos; compile &apos;org.eclipse.paho:org.eclipse.paho.android.service:1.1.1&apos;&#125; 添加权限 123&lt;uses-permission android:name=&quot;android.permission.INTERNET&quot; /&gt;&lt;uses-permission android:name=&quot;android.permission.ACCESS_NETWORK_STATE&quot; /&gt;&lt;uses-permission android:name=&quot;android.permission.WAKE_LOCK&quot; /&gt; 注册Service 12&lt;!-- Mqtt Service --&gt;&lt;service android:name=&quot;org.eclipse.paho.android.service.MqttService&quot; /&gt; 具体实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157/** * MQTT长连接服务 */public class MQTTService extends Service &#123; public static final String TAG = MQTTService.class.getSimpleName(); public static MqttAndroidClient client; private MqttConnectOptions connectOptions; private String host = &quot;tcp://192.168.102.216:61613&quot;;// private String host = &quot;tcp://192.168.8.241:61613&quot;;// private String host = &quot;tcp://10.0.2.2:61613&quot;;// private String host = &quot;tcp://192.168.26.144:1883&quot;; private String username = &quot;admin&quot;; private String password = &quot;password&quot;; private static String myTopic = &quot;topic&quot;; private String clientId = &quot;test123&quot;; @Override public int onStartCommand(Intent intent, int flags, int startId) &#123; init(); return super.onStartCommand(intent, flags, startId); &#125; @Nullable @Override public IBinder onBind(Intent intent) &#123; return null; &#125; public static void publish(String msg) &#123; String topic = myTopic; Integer qos = 0; Boolean retained = false; try &#123; client.publish(topic, msg.getBytes(), qos.intValue(), retained.booleanValue()); &#125; catch (MqttException e) &#123; e.printStackTrace(); &#125; &#125; /** * 初始化方法 */ private void init() &#123; // 服务器地址 (协议+地址+端口号) String url = host; client = new MqttAndroidClient(this, url, clientId); client.setCallback(mqttCallback); connectOptions = new MqttConnectOptions(); // 清除缓存 connectOptions.setCleanSession(true); // 设置超时时间,单位:秒 connectOptions.setConnectionTimeout(10); // 心跳包发送时间间隔,单位:秒 connectOptions.setKeepAliveInterval(20); // 用户名 connectOptions.setUserName(username); // 密码 connectOptions.setPassword(password.toCharArray()); // last will message boolean doConnect = true; String message = &quot;&#123;\\&quot;terminal_uid\\&quot;:\\&quot;&quot; + clientId + &quot;\\&quot;&#125;&quot;; String topic = myTopic; Integer qos = 0; Boolean retained = false; if ((!message.equals(&quot;&quot;)) || (!topic.equals(&quot;&quot;))) &#123; //最后的遗嘱 try &#123; connectOptions.setWill(topic, message.getBytes(), qos.intValue(), retained.booleanValue()); &#125; catch (Exception ex) &#123; Log.d(TAG, &quot;Exception Occured&quot;, ex); doConnect = false; iMqttActionListener.onFailure(null, ex); &#125; &#125; if (doConnect) &#123; //连接MQTT服务器 doClientConnection(); &#125; &#125; /** * 连接MQTT服务器 */ private void doClientConnection() &#123; if (!client.isConnected() &amp;&amp; isConnectIsNomarl()) &#123; try &#123; client.connect(connectOptions, null, iMqttActionListener); &#125; catch (MqttException e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 判断网络是否连接 * * @return */ private boolean isConnectIsNomarl() &#123; ConnectivityManager connectivityManager = (ConnectivityManager) this.getApplicationContext().getSystemService(Context.CONNECTIVITY_SERVICE); NetworkInfo info = connectivityManager.getActiveNetworkInfo(); if (info != null &amp;&amp; info.isAvailable()) &#123; String name = info.getTypeName(); Log.i(TAG, &quot;MQTT当前网络名称：&quot; + name); return true; &#125; else &#123; Log.i(TAG, &quot;MQTT 没有可用网络&quot;); return false; &#125; &#125; /** * MQTT监听并且接收消息 */ private MqttCallback mqttCallback = new MqttCallback() &#123; @Override public void connectionLost(Throwable cause) &#123; //失去连接，重连 &#125; @Override public void messageArrived(String topic, MqttMessage message) throws Exception &#123; EventBus.getDefault().post(message); String str2 = topic + &quot;;qos :&quot; + message.getQos() + &quot;;retained:&quot; + message.isRetained(); Log.d(TAG, &quot;messageArrived: str2&quot; + str2); &#125; @Override public void deliveryComplete(IMqttDeliveryToken token) &#123; &#125; &#125;; /** * MQTT是否连接成功 */ private IMqttActionListener iMqttActionListener = new IMqttActionListener() &#123; @Override public void onSuccess(IMqttToken asyncActionToken) &#123; Log.d(TAG, &quot;onSuccess: MQTT连接成功&quot;); try &#123; //订阅myTopic话题 client.subscribe(myTopic, 1); &#125; catch (MqttException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void onFailure(IMqttToken asyncActionToken, Throwable exception) &#123; exception.printStackTrace(); //连接失败，重连 &#125; &#125;;&#125; 初始化各个参数，之后连接服务器。连接成功之后在http://127.0.0.1:61680/ 看到自动创建了名称为”topic”的topic。这里我使用两台真机。http://127.0.0.1:61680/ 服务端看到的是这个样子 模拟器运行的时候host = “tcp://10.0.2.2:61613”，因为10.0.2.2 是模拟器设置的特定ip，是你电脑的别名。真机运行的时候host = “tcp://192.168.102.216:61613”。192.168.102.216是我主机的IPv4地址，查看本机IP的cmd命令为ipconfig/all。 两次运行时的clientId不能一样（为了保证客户标识的唯一性） 访问管理界面要修改前面创建的xxx文件夹下etc\\apollo.xml文件，添加你的host就可以通过host访问管理界面，否则只能通过 http://127.0.0.1:61680 和 https://127.0.0.1:61681 访问123456789101112131415161718192021222324252627282930313233343536373839... ... &lt;virtual_host id=&quot;xmaihh&quot;&gt; &lt;!-- You should add all the host names that this virtual host is known as to properly support the STOMP 1.1 virtual host feature. --&gt; &lt;host_name&gt;xmaihh&lt;/host_name&gt; &lt;host_name&gt;localhost&lt;/host_name&gt; &lt;host_name&gt;127.0.0.1&lt;/host_name&gt; &lt;!--以下为添加内容--&gt; &lt;host_name&gt;192.168.102.216&lt;/host_name&gt; &lt;!--以上为添加内容--&gt; &lt;!-- Uncomment to disable security for the virtual host --&gt; &lt;!-- &lt;authentication enabled=&quot;false&quot;/&gt; --&gt; &lt;!-- Uncomment to disable security for the virtual host --&gt; &lt;!-- &lt;authentication enabled=&quot;false&quot;/&gt; --&gt; &lt;access_rule allow=&quot;users&quot; action=&quot;connect create destroy send receive consume&quot;/&gt; &lt;!-- You can delete this element if you want to disable persistence for this virtual host --&gt; &lt;leveldb_store directory=&quot;$&#123;apollo.base&#125;/data&quot;/&gt; &lt;/virtual_host&gt; &lt;web_admin bind=&quot;http://127.0.0.1:61680&quot;/&gt; &lt;web_admin bind=&quot;https://127.0.0.1:61681&quot;/&gt; &lt;!--以下为添加内容--&gt; &lt;web_admin bind=&quot;http://192.168.102.216:61680&quot;/&gt; &lt;web_admin bind=&quot;https://192.168.102.216:61681&quot;/&gt; &lt;!--以上为添加内容--&gt; &lt;connector id=&quot;tcp&quot; bind=&quot;tcp://0.0.0.0:61613&quot; connection_limit=&quot;2000&quot;/&gt; &lt;connector id=&quot;tls&quot; bind=&quot;tls://0.0.0.0:61614&quot; connection_limit=&quot;2000&quot;/&gt; &lt;connector id=&quot;ws&quot; bind=&quot;ws://0.0.0.0:61623&quot; connection_limit=&quot;2000&quot;/&gt; &lt;connector id=&quot;wss&quot; bind=&quot;wss://0.0.0.0:61624&quot; connection_limit=&quot;2000&quot;/&gt; &lt;key_storage file=&quot;$&#123;apollo.base&#125;/etc/keystore&quot; password=&quot;password&quot; key_password=&quot;password&quot;/&gt;","categories":[{"name":"MQTT","slug":"MQTT","permalink":"http://wenyiqingnian.xyz/categories/MQTT/"}],"tags":[{"name":"mqtt","slug":"mqtt","permalink":"http://wenyiqingnian.xyz/tags/mqtt/"}]},{"title":"view 绘制机制","slug":"view 绘制机制","date":"2017-10-12T11:30:50.000Z","updated":"2018-05-24T03:11:00.000Z","comments":true,"path":"2017/10/12/view 绘制机制/","link":"","permalink":"http://wenyiqingnian.xyz/2017/10/12/view 绘制机制/","excerpt":"","text":"View的绘制和事件处理是两个重要的主题，上一篇《图解 Android事件分发机制》已经把事件的分发机制讲得比较详细了，这一篇是针对View的绘制，View的绘制如果你有所了解，基本分为measure、layout、draw 过程，其中比较难理解就是measure过程，所以本篇文章大幅笔地分析measure过程，相对讲得比较详细，文章也比较长，如果你对View的绘制还不是很懂，对measure过程掌握得不是很深刻，那么耐心点，看完这篇文章，相信你会有所收获的。 Measure过程对于测量我们来说几个知识点,了解这几个知识点，之后的实例分析你才看得懂。 1、MeasureSpec 的理解对于View的测量，肯定会和MeasureSpec接触，MeasureSpec是两个单词组成，翻译过来“测量规格”或者“测量参数”，很多博客包括官方文档对他的说明基本都是“一个MeasureSpec封装了从父容器传递给子容器的布局要求”,这个MeasureSpec 封装的是父容器传递给子容器的布局要求，而不是父容器对子容器的布局要求，“传递” 两个字很重要，更精确的说法应该这个MeasureSpec是由父View的MeasureSpec和子View的LayoutParams通过简单的计算得出一个针对子View的测量要求，这个测量要求就是MeasureSpec。 大家都知道一个MeasureSpec是一个大小跟模式的组合值,MeasureSpec中的值是一个整型（32位）将size和mode打包成一个Int型，其中高两位是mode，后面30位存的是size，是为了减少对象的分配开支。MeasureSpec 类似于下图，只不过这边用的是十进制的数，而MeasureSpec 是二进制存储的。 注：-1 代表的是EXACTLY，-2 是AT_MOSTMeasureSpec一共有三种模式 123UPSPECIFIED : 父容器对于子容器没有任何限制,子容器想要多大就多大EXACTLY: 父容器已经为子容器设置了尺寸,子容器应当服从这些边界,不论子容器想要多大的空间。AT_MOST：子容器可以是声明大小内的任意大小 很多文章都会把这三个模式说成这样，当然其实包括官方文档也是这样表达的，但是这样并不好理解。特别是如果把这三种模式又和MATCH_PARENT和WRAP_CONTENT 联系到一起，很多人就懵逼了。如果从代码上来看1view.measure(int widthMeasureSpec, int heightMeasureSpec) 12 的两个MeasureSpec是父类传递过来的，但并不是完全是父View的要求，而是父View的MeasureSpec和子View自己的LayoutParams共同决定的，而子View的LayoutParams其实就是我们在xml写的时候设置的layout_width和layout_height 转化而来的。我们先来看代码会清晰一些： 父View的measure的过程会先测量子View，等子View测量结果出来后，再来测量自己，上面的measureChildWithMargins就是用来测量某个子View的，我们来分析是怎样测量的，具体看注释： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112protected void measureChildWithMargins(View child, int parentWidthMeasureSpec, int widthUsed, int parentHeightMeasureSpec, int heightUsed) &#123; // 子View的LayoutParams，你在xml的layout_width和layout_height,// layout_xxx的值最后都会封装到这个个LayoutParams。final MarginLayoutParams lp = (MarginLayoutParams) child.getLayoutParams(); //根据父View的测量规格和父View自己的Padding，//还有子View的Margin和已经用掉的空间大小（widthUsed），就能算出子View的MeasureSpec,具体计算过程看getChildMeasureSpec方法。final int childWidthMeasureSpec = getChildMeasureSpec(parentWidthMeasureSpec, mPaddingLeft + mPaddingRight + lp.leftMargin + lp.rightMargin + widthUsed, lp.width); final int childHeightMeasureSpec = getChildMeasureSpec(parentHeightMeasureSpec, mPaddingTop + mPaddingBottom + lp.topMargin + lp.bottomMargin + heightUsed, lp.height); //通过父View的MeasureSpec和子View的自己LayoutParams的计算，算出子View的MeasureSpec，然后父容器传递给子容器的// 然后让子View用这个MeasureSpec（一个测量要求，比如不能超过多大）去测量自己，如果子View是ViewGroup 那还会递归往下测量。child.measure(childWidthMeasureSpec, childHeightMeasureSpec);&#125;// spec参数 表示父View的MeasureSpec // padding参数 父View的Padding+子View的Margin，父View的大小减去这些边距，才能精确算出// 子View的MeasureSpec的size// childDimension参数 表示该子View内部LayoutParams属性的值（lp.width或者lp.height）// 可以是wrap_content、match_parent、一个精确指(an exactly size), public static int getChildMeasureSpec(int spec, int padding, int childDimension) &#123; int specMode = MeasureSpec.getMode(spec); //获得父View的mode int specSize = MeasureSpec.getSize(spec); //获得父View的大小 //父View的大小-自己的Padding+子View的Margin，得到值才是子View的大小。 int size = Math.max(0, specSize - padding); int resultSize = 0; //初始化值，最后通过这个两个值生成子View的MeasureSpec int resultMode = 0; //初始化值，最后通过这个两个值生成子View的MeasureSpec switch (specMode) &#123; // Parent has imposed an exact size on us //1、父View是EXACTLY的 ！ case MeasureSpec.EXACTLY: //1.1、子View的width或height是个精确值 (an exactly size) if (childDimension &gt;= 0) &#123; resultSize = childDimension; //size为精确值 resultMode = MeasureSpec.EXACTLY; //mode为 EXACTLY 。 &#125; //1.2、子View的width或height为 MATCH_PARENT/FILL_PARENT else if (childDimension == LayoutParams.MATCH_PARENT) &#123; // Child wants to be our size. So be it. resultSize = size; //size为父视图大小 resultMode = MeasureSpec.EXACTLY; //mode为 EXACTLY 。 &#125; //1.3、子View的width或height为 WRAP_CONTENT else if (childDimension == LayoutParams.WRAP_CONTENT) &#123; // Child wants to determine its own size. It can't be // bigger than us. resultSize = size; //size为父视图大小 resultMode = MeasureSpec.AT_MOST; //mode为AT_MOST 。 &#125; break; // Parent has imposed a maximum size on us //2、父View是AT_MOST的 ！ case MeasureSpec.AT_MOST: //2.1、子View的width或height是个精确值 (an exactly size) if (childDimension &gt;= 0) &#123; // Child wants a specific size... so be it resultSize = childDimension; //size为精确值 resultMode = MeasureSpec.EXACTLY; //mode为 EXACTLY 。 &#125; //2.2、子View的width或height为 MATCH_PARENT/FILL_PARENT else if (childDimension == LayoutParams.MATCH_PARENT) &#123; // Child wants to be our size, but our size is not fixed. // Constrain child to not be bigger than us. resultSize = size; //size为父视图大小 resultMode = MeasureSpec.AT_MOST; //mode为AT_MOST &#125; //2.3、子View的width或height为 WRAP_CONTENT else if (childDimension == LayoutParams.WRAP_CONTENT) &#123; // Child wants to determine its own size. It can't be // bigger than us. resultSize = size; //size为父视图大小 resultMode = MeasureSpec.AT_MOST; //mode为AT_MOST &#125; break; // Parent asked to see how big we want to be //3、父View是UNSPECIFIED的 ！ case MeasureSpec.UNSPECIFIED: //3.1、子View的width或height是个精确值 (an exactly size) if (childDimension &gt;= 0) &#123; // Child wants a specific size... let him have it resultSize = childDimension; //size为精确值 resultMode = MeasureSpec.EXACTLY; //mode为 EXACTLY &#125; //3.2、子View的width或height为 MATCH_PARENT/FILL_PARENT else if (childDimension == LayoutParams.MATCH_PARENT) &#123; // Child wants to be our size... find out how big it should // be resultSize = 0; //size为0！ ,其值未定 resultMode = MeasureSpec.UNSPECIFIED; //mode为 UNSPECIFIED &#125; //3.3、子View的width或height为 WRAP_CONTENT else if (childDimension == LayoutParams.WRAP_CONTENT) &#123; // Child wants to determine its own size.... find out how // big it should be resultSize = 0; //size为0! ，其值未定 resultMode = MeasureSpec.UNSPECIFIED; //mode为 UNSPECIFIED &#125; break; &#125; //根据上面逻辑条件获取的mode和size构建MeasureSpec对象。 return MeasureSpec.makeMeasureSpec(resultSize, resultMode); &#125; 上面的代码有点多，希望你仔细看一些注释，代码写得很多，其实计算原理很简单： 如果我们在xml 的layout_width或者layout_height 把值都写死，那么上述的测量完全就不需要了，之所以要上面的这步测量，是因为 match_parent 就是充满父容器，wrap_content 就是自己多大就多大， 我们写代码的时候特别爽，我们编码方便的时候，google就要帮我们计算你match_parent的时候是多大，wrap_content的是多大，这个计算过程，就是计算出来的父View的MeasureSpec不断往子View传递，结合子View的LayoutParams 一起再算出子View的MeasureSpec，然后继续传给子View，不断计算每个View的MeasureSpec，子View有了MeasureSpec才能更测量自己和自己的子View。 上述代码如果这么来理解就简单了 如果父View的MeasureSpec 是EXACTLY，说明父View的大小是确切的，（确切的意思很好理解，如果一个View的MeasureSpec 是EXACTLY，那么它的size 是多大，最后展示到屏幕就一定是那么大）。 1.如果子View 的layout_xxxx是MATCH_PARENT，父View的大小是确切，子View的大小又MATCH_PARENT（充满整个父View），那么子View的大小肯定是确切的，而且大小值就是父View的size。所以子View的size=父View的size，mode=EXACTLY 2.如果子View 的layout_xxxx是WRAP_CONTENT，也就是子View的大小是根据自己的content 来决定的，但是子View的毕竟是子View，大小不能超过父View的大小，但是子View的是WRAP_CONTENT，我们还不知道具体子View的大小是多少，要等到child.measure(childWidthMeasureSpec, childHeightMeasureSpec) 调用的时候才去真正测量子View 自己content的大小（比如TextView wrap_content 的时候你要测量TextView content 的大小，也就是字符占用的大小，这个测量就是在child.measure(childWidthMeasureSpec, childHeightMeasureSpec)的时候，才能测出字符的大小，MeasureSpec 的意思就是假设你字符100px，但是MeasureSpec 要求最大的只能50px，这时候就要截掉了）。通过上述描述，子View MeasureSpec mode的应该是AT_MOST，而size 暂定父View的 size，表示的意思就是子View的大小没有不确切的值，子View的大小最大为父View的大小，不能超过父View的大小（这就是AT_MOST 的意思），然后这个MeasureSpec 做为子View measure方法 的参数，做为子View的大小的约束或者说是要求，有了这个MeasureSpec子View再实现自己的测量。 3、如果如果子View 的layout_xxxx是确定的值（200dp），那么就更简单了，不管你父View的mode和size是什么，我都写死了就是200dp，那么控件最后展示就是就是200dp，不管我的父View有多大，也不管我自己的content 有多大，反正我就是这么大，所以这种情况MeasureSpec 的mode = EXACTLY 大小size=你在layout_xxxx 填的那个值。 如果父View的MeasureSpec 是AT_MOST，说明父View的大小是不确定，最大的大小是MeasureSpec 的size值，不能超过这个值。 1、如果子View 的layout_xxxx是MATCH_PARENT，父View的大小是不确定（只知道最大只能多大），子View的大小MATCH_PARENT（充满整个父View），那么子View你即使充满父容器，你的大小也是不确定的，父View自己都确定不了自己的大小，你MATCH_PARENT你的大小肯定也不能确定的，所以子View的mode=AT_MOST，size=父View的size，也就是你在布局虽然写的是MATCH_PARENT，但是由于你的父容器自己的大小不确定，导致子View的大小也不确定，只知道最大就是父View的大小。 2、如果子View 的layout_xxxx是WRAP_CONTENT，父View的大小是不确定（只知道最大只能多大），子View又是WRAP_CONTENT，那么在子View的Content没算出大小之前，子View的大小最大就是父View的大小，所以子View MeasureSpec mode的就是AT_MOST，而size 暂定父View的 size。 3、如果如果子View 的layout_xxxx是确定的值（200dp），同上，写多少就是多少，改变不了的。 如果父View的MeasureSpec 是UNSPECIFIED(未指定),表示没有任何束缚和约束，不像AT_MOST表示最大只能多大，不也像EXACTLY表示父View确定的大小，子View可以得到任意想要的大小，不受约束 1、如果子View 的layout_xxxx是MATCH_PARENT，因为父View的MeasureSpec是UNSPECIFIED，父View自己的大小并没有任何约束和要求，那么对于子View来说无论是WRAP_CONTENT还是MATCH_PARENT，子View也是没有任何束缚的，想多大就多大，没有不能超过多少的要求，一旦没有任何要求和约束，size的值就没有任何意义了，所以一般都直接设置成0 2、同上… 3、如果如果子View 的layout_xxxx是确定的值（200dp），同上，写多少就是多少，改变不了的（记住，只有设置的确切的值，那么无论怎么测量，大小都是不变的，都是你写的那个值） 2、View的测量过程主要是在onMeasure()方法打开View的源码，找到measure方法，这个方法代码不少，但是测量工作都是在onMeasure()做的，measure方法是final的所以这个方法也不可重写，如果想自定义View的测量，你应该去重写onMeasure()方法 12345public final void measure(int widthMeasureSpec, int heightMeasureSpec) &#123; ...... onMeasure(widthMeasureSpec,heightMeasureSpec); .....&#125; 3、View的onMeasure 的默认实现打开View.java 的源码来看下onMeasure的实现 12345protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) &#123; setMeasuredDimension( getDefaultSize(getSuggestedMinimumWidth(), widthMeasureSpec), getDefaultSize(getSuggestedMinimumHeight(), heightMeasureSpec));&#125; View的onMeasure方法默认实现很简单，就是调用setMeasuredDimension()，setMeasuredDimension()可以简单理解就是给mMeasuredWidth和mMeasuredHeight设值，如果这两个值一旦设置了，那么意味着对于这个View的测量结束了，这个View的宽高已经有测量的结果出来了。如果我们想设定某个View的高宽，完全可以直接通过setMeasuredDimension（100，200）来设置死它的高宽（不建议），但是setMeasuredDimension方法必须在onMeasure方法中调用，不然会抛异常。我们来看下对于View来说它的默认高宽是怎么获取的。 1234567891011121314151617181920//获取的是android:minHeight属性的值或者View背景图片的大小值protected int getSuggestedMinimumWidth() &#123; return (mBackground == null) ? mMinWidth : max(mMinWidth, mBackground.getMinimumWidth()); &#125; //@param size参数一般表示设置了android:minHeight属性或者该View背景图片的大小值 public static int getDefaultSize(int size, int measureSpec) &#123; int result = size; int specMode = MeasureSpec.getMode(measureSpec); int specSize = MeasureSpec.getSize(measureSpec); switch (specMode) &#123; case MeasureSpec.UNSPECIFIED: //表示该View的大小父视图未定，设置为默认值 result = size; break; case MeasureSpec.AT_MOST: case MeasureSpec.EXACTLY: result = specSize; break; &#125; return result;&#125; getDefaultSize的第一个参数size等于getSuggestedMinimumXXXX返回的的值（建议的最小宽度和高度），而建议的最小宽度和高度都是由View的Background尺寸与通过设置View的minXXX属性共同决定的，这个size可以理解为View的默认长度，而第二个参数measureSpec，是父View传给自己的MeasureSpec,这个measureSpec是通过测量计算出来的，具体的计算测量过程前面在讲解MeasureSpec已经讲得比较清楚了（是有父View的MeasureSpec和子View自己的LayoutParams 共同决定的）只要这个测试的mode不是UNSPECIFIED（未确定的），那么默认的就会用这个测量的数值当做View的高度。 对于View默认是测量很简单，大部分情况就是拿计算出来的MeasureSpec的size 当做最终测量的大小。而对于其他的一些View的派生类，如TextView、Button、ImageView等，它们的onMeasure方法系统了都做了重写，不会这么简单直接拿 MeasureSpec 的size来当大小，而去会先去测量字符或者图片的高度等，然后拿到View本身content这个高度（字符高度等），如果MeasureSpec是AT_MOST，而且View本身content的高度不超出MeasureSpec的size，那么可以直接用View本身content的高度（字符高度等），而不是像View.java 直接用MeasureSpec的size做为View的大小。 4、ViewGroup的Measure过程ViewGroup 类并没有实现onMeasure，我们知道测量过程其实都是在onMeasure方法里面做的，我们来看下FrameLayout 的onMeasure 方法,具体分析看注释哦。 1234567891011121314151617181920212223//FrameLayout 的测量protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) &#123; ....int maxHeight = 0;int maxWidth = 0;int childState = 0;for (int i = 0; i &lt; count; i++) &#123; final View child = getChildAt(i); if (mMeasureAllChildren || child.getVisibility() != GONE) &#123; // 遍历自己的子View，只要不是GONE的都会参与测量，measureChildWithMargins方法在最上面 // 的源码已经讲过了，如果忘了回头去看看，基本思想就是父View把自己的MeasureSpec // 传给子View结合子View自己的LayoutParams 算出子View 的MeasureSpec，然后继续往下传， // 传递叶子节点，叶子节点没有子View，根据传下来的这个MeasureSpec测量自己就好了。 measureChildWithMargins(child, widthMeasureSpec, 0, heightMeasureSpec, 0); final LayoutParams lp = (LayoutParams) child.getLayoutParams(); maxWidth = Math.max(maxWidth, child.getMeasuredWidth() + lp.leftMargin + lp.rightMargin); maxHeight = Math.max(maxHeight, child.getMeasuredHeight() + lp.topMargin + lp.bottomMargin); .... .... &#125;&#125;.......... //所有的孩子测量之后，经过一系类的计算之后通过setMeasuredDimension设置自己的宽高，//对于FrameLayout 可能用最大的字View的大小，对于LinearLayout，可能是高度的累加，//具体测量的原理去看看源码。总的来说，父View是等所有的子View测量结束之后，再来测量自己。 1234setMeasuredDimension(resolveSizeAndState(maxWidth, widthMeasureSpec, childState), resolveSizeAndState(maxHeight, heightMeasureSpec, childState &lt;&lt; MEASURED_HEIGHT_STATE_SHIFT));....&#125; 到目前为止，基本把Measure 主要原理都过了一遍，接下来我们会结合实例来讲解整个match的过程，首先看下面的代码： 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;LinearLayout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; android:id=&quot;@+id/linear&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;wrap_content&quot; android:layout_marginTop=&quot;50dp&quot; android:background=&quot;@android:color/holo_blue_dark&quot; android:paddingBottom=&quot;70dp&quot; android:orientation=&quot;vertical&quot;&gt; &lt;TextView android:id=&quot;@+id/text&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;wrap_content&quot; android:background=&quot;@color/material_blue_grey_800&quot; android:text=&quot;TextView&quot; android:textColor=&quot;@android:color/white&quot; android:textSize=&quot;20sp&quot; /&gt; &lt;View android:id=&quot;@+id/view&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;150dp&quot; android:background=&quot;@android:color/holo_green_dark&quot; /&gt;&lt;/LinearLayout&gt; 上面的代码对于出来的布局是下面的一张图 对于上面图可能有些不懂，这边做下说明: 整个图是一个DecorView,DecorView可以理解成整个页面的根View,DecorView是一个FrameLayout,包含两个子View，一个id=statusBarBackground的View和一个是LineaLayout，id=statusBarBackground的View，我们可以先不管（我也不是特别懂这个View,应该就是statusBar的设置背景的一个控件，方便设置statusBar的背景)，而这个LinearLayout比较重要，它包含一个title和一个content，title很好理解其实就是TitleBar或者ActionBar,content 就更简单了，setContentView()方法你应该用过吧，android.R.id.content 你应该听过吧，没错就是它,content是一个FrameLayout，你写的页面布局通过setContentView加进来就成了content的直接子View。 整个View的布局图如下： 这张图在下面分析measure，会经常用到，主要用于了解递归的时候view 的measure顺序 注:1、 header的是个ViewStub,用来惰性加载ActionBar，为了便于分析整个测量过程，我把Theme设成NoActionBar，避免ActionBar 相关的measure干扰整个过程，这样可以忽略掉ActionBar 的测量，在调试代码更清晰。2、包含Header(ActionBar）和id/content 的那个父View，我不知道叫什么名字好，我们姑且叫它ViewRoot（看上图）,它是垂直的LinearLayout，放着整个页面除statusBar 的之外所有的东西，叫它ViewRoot 应该还ok，一个代号而已。 既然我们知道整个View的Root是DecorView，那么View的绘制是从哪里开始的呢，我们知道每个Activity 均会创建一个 PhoneWindow对象，是Activity和整个View系统交互的接口，每个Window都对应着一个View和一个ViewRootImpl，Window和View通过ViewRootImpl来建立联系,对于Activity来说，ViewRootImpl是连接WindowManager和DecorView的纽带,绘制的入口是由ViewRootImpl的performTraversals方法来发起Measure，Layout，Draw等流程的。 我们来看下ViewRootImpl的performTraversals 方法： 123456789101112131415161718192021222324private void performTraversals() &#123; ...... int childWidthMeasureSpec = getRootMeasureSpec(mWidth, lp.width); int childHeightMeasureSpec = getRootMeasureSpec(mHeight, lp.height); ...... mView.measure(childWidthMeasureSpec, childHeightMeasureSpec); ......mView.layout(0, 0, mView.getMeasuredWidth(), mView.getMeasuredHeight());...... mView.draw(canvas); ......&#125;private static int getRootMeasureSpec(int windowSize, int rootDimension) &#123; int measureSpec; switch (rootDimension) &#123; case ViewGroup.LayoutParams.MATCH_PARENT: // Window can't resize. Force root view to be windowSize. measureSpec = MeasureSpec.makeMeasureSpec(windowSize,MeasureSpec.EXACTLY); break; ...... &#125; return measureSpec; &#125; performTraversals 中我们看到的mView其实就是DecorView,View的绘制从DecorView开始， 在mView.measure()的时候调用getRootMeasureSpec获得两个MeasureSpec做为参数，getRootMeasureSpec的两个参数（mWidth, lp.width）mWith和mHeight 是屏幕的宽度和高度， lp是WindowManager.LayoutParams，它的lp.width和lp.height的默认值是MATCH_PARENT,所以通过getRootMeasureSpec 生成的测量规格MeasureSpec 的mode是MATCH_PARENT ，size是屏幕的高宽。因为DecorView 是一个FrameLayout 那么接下来会进入FrameLayout 的measure方法，measure的两个参数就是刚才getRootMeasureSpec的生成的两个MeasureSpec，DecorView的测量开始了。首先是DecorView 的 MeasureSpec ，根据上面的分析DecorView 的 MeasureSpec是Windows传过来的，我们画出DecorView 的MeasureSpec 图： 注：1、-1 代表的是EXACTLY，-2 是AT_MOST2、由于屏幕的像素是1440x2560,所以DecorView 的MeasureSpec的size 对应于这两个值 那么接下来在FrameLayout 的onMeasure()方法DecorView开始for循环测量自己的子View,测量完所有的子View再来测量自己，由下图可知，接下来要测量ViewRoot的大小 1234567891011121314151617181920//FrameLayout 的测量protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) &#123; ....int maxHeight = 0;int maxWidth = 0;int childState = 0;for (int i = 0; i &lt; count; i++) &#123; final View child = getChildAt(i); if (mMeasureAllChildren || child.getVisibility() != GONE) &#123; // 遍历自己的子View，只要不是GONE的都会参与测量，measureChildWithMargins方法在最上面 // 的源码已经讲过了，如果忘了回头去看看，基本思想就是父View把自己当MeasureSpec // 传给子View结合子View自己的LayoutParams 算出子View 的MeasureSpec，然后继续往下穿， // 传递叶子节点，叶子节点没有子View，只要负责测量自己就好了。 measureChildWithMargins(child, widthMeasureSpec, 0, heightMeasureSpec, 0); .... .... &#125;&#125;....&#125; DecorView 测量ViewRoot 的时候把自己的widthMeasureSpec和heightMeasureSpec传进去了，接下来你就要去看measureChildWithMargins的源码了 123456789101112protected void measureChildWithMargins(View child, int parentWidthMeasureSpec, int widthUsed, int parentHeightMeasureSpec, int heightUsed) &#123; final MarginLayoutParams lp = (MarginLayoutParams) child.getLayoutParams(); final int childWidthMeasureSpec = getChildMeasureSpec(parentWidthMeasureSpec, mPaddingLeft + mPaddingRight + lp.leftMargin + lp.rightMargin + widthUsed, lp.width); final int childHeightMeasureSpec = getChildMeasureSpec(parentHeightMeasureSpec, mPaddingTop + mPaddingBottom + lp.topMargin + lp.bottomMargin + heightUsed, lp.height); child.measure(childWidthMeasureSpec, childHeightMeasureSpec);&#125; ViewRoot 是系统的View，它的LayoutParams默认都是match_parent,根据我们文章最开始MeasureSpec 的计算规则，ViewRoot 的MeasureSpec mode应该等于EXACTLY（DecorView MeasureSpec 的mode是EXACTLY，ViewRoot的layoutparams 是match_parent），size 也等于DecorView的size，所以ViewRoot的MeasureSpec图如下： 算出ViewRoot的MeasureSpec 之后，开始调用ViewRoot.measure 方法去测量ViewRoot的大小，然而ViewRoot是一个LinearLayout ，ViewRoot.measure最终会执行的LinearLayout 的onMeasure 方法，LinearLayout 的onMeasure 方法又开始逐个测量它的子View，上面的measureChildWithMargins方法又会被调用，那么根据View的层级图，接下来测量的是header（ViewStub）,由于header的Gone，所以直接跳过不做测量工作，所以接下来轮到ViewRoot的第二个child content（android.R.id.content）,我们要算出这个content 的MeasureSpec，所以又要拿ViewRoot 的MeasureSpec 和 android.R.id.content的LayoutParams 做计算了，计算过程就是调用getChildMeasureSpec的方法， 1234567891011121314protected void measureChildWithMargins(View child, int parentWidthMeasureSpec, int widthUsed, int parentHeightMeasureSpec, int heightUsed) &#123; ..... final int childHeightMeasureSpec = getChildMeasureSpec(parentHeightMeasureSpec, mPaddingTop + mPaddingBottom + lp.topMargin + lp.bottomMargin + heightUsed, lp.height); ....&#125;public static int getChildMeasureSpec(int spec, int padding, int childDimension) &#123; int specMode = MeasureSpec.getMode(spec); //获得父View的mode int specSize = MeasureSpec.getSize(spec); //获得父View的大小 int size = Math.max(0, specSize - padding); //父View的大小-自己的Padding+子View的Margin，得到值才是子View可能的最大值。 .....&#125; 由上面的代码 1int size = Math.max(0, specSize - padding); 而1padding=mPaddingTop + mPaddingBottom + lp.topMargin + lp.bottomMargin + heightUsed 算出android.R.id.content 的MeasureSpec 的size由于ViewRoot 的mPaddingBottom=100px(这个可能和状态栏的高度有关，我们测量的最后会发现id/statusBarBackground的View的高度刚好等于100px，ViewRoot 是系统的View的它的Padding 我们没法改变，所以计算出来Content（android.R.id.content） 的MeasureSpec 的高度少了100px ，它的宽高的mode 根据算出来也是EXACTLY（ViewRoot 是EXACTLY和android.R.id.content 是match_parent）。所以Content（android.R.id.content）的MeasureSpec 如下（高度少了100px）：Paste_Image.pngContent（android.R.id.content） 是FrameLayout，递归调用开始准备计算id/linear的MeasureSpec，我们先给出结果： 图中有两个要注意的地方：1、id/linear的heightMeasureSpec 的mode=AT_MOST，因为id/linear 的LayoutParams 的layout_height=”wrap_content”2、id/linear的heightMeasureSpec 的size 少了200px, 由上面的代码padding=mPaddingTop + mPaddingBottom + lp.topMargin + lp.bottomMargin + heightUsed;int size = Math.max(0, specSize - padding);由于id/linear 的 android:layout_marginTop=”50dp” 使得lp.topMargin=200px (本设备的density=4，px=4*pd)，在计算后id/linear的heightMeasureSpec 的size 少了200px。（布局代码前面已给出，可自行查看id/linear 控件xml中设置的属性） linear.measure接着往下算linear的子View的的MeasureSpec，看下View 层级图，往下走应该是id/text,接下来是计算id/text的MeasureSpec，直接看图，mode=AT_MOST ,size 少了280，别问我为什么 …specSize - padding. 算出id/text 的MeasureSpec 后，接下来text.measure(childWidthMeasureSpec, childHeightMeasureSpec);准备测量id/text 的高宽，这时候已经到底了，id/text是TextView，已经没有子类了，这时候跳到TextView的onMeasure方法了。TextView 拿着刚才计算出来的heightMeasureSpec（mode=AT_MOST,size=1980）,这个就是对TextView的高度和宽度的约束，进到TextView 的onMeasure(widthMeasureSpec,heightMeasureSpec) 方法，在onMeasure 方法执行调试过程中，我们发现下面的代码： 123456int desired = getDesiredHeight(); desired = 107pxif(heightMode == MeasureSpec.AT_MOST)&#123; height = Math.min(desired,heightSize); height = 1980px &#125; setMeasuredDimension(width,height); TextView字符的高度（也就是TextView的content高度[wrap_content]）测出来=107px，107px 并没有超过1980px(允许的最大高度)，所以实际测量出来TextView的高度是107px。最终算出id/text 的mMeasureWidth=1440px,mMeasureHeight=107px。 贴一下布局代码，免得你忘了具体布局。 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;LinearLayout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; android:id=&quot;@+id/linear&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;wrap_content&quot; android:layout_marginTop=&quot;50dp&quot; android:background=&quot;@android:color/holo_blue_dark&quot; android:paddingBottom=&quot;70dp&quot; android:orientation=&quot;vertical&quot;&gt; &lt;TextView android:id=&quot;@+id/text&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;wrap_content&quot; android:background=&quot;@color/material_blue_grey_800&quot; android:text=&quot;TextView&quot; android:textColor=&quot;@android:color/white&quot; android:textSize=&quot;20sp&quot; /&gt; &lt;View android:id=&quot;@+id/view&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;150dp&quot; android:background=&quot;@android:color/holo_green_dark&quot; /&gt;&lt;/LinearLayout&gt; TextView的高度已经测量出来了，接下来测量id/linear的第二个child（id/view），同样的原理测出id/view的MeasureSpec. id/view的MeasureSpec 计算出来后，调用view.measure(childWidthMeasureSpec, childHeightMeasureSpec)的测量id/view的高宽，之前已经说过View measure的默认实现是 12345protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) &#123; setMeasuredDimension( getDefaultSize(getSuggestedMinimumWidth(), widthMeasureSpec), getDefaultSize(getSuggestedMinimumHeight(), heightMeasureSpec));&#125; 最终算出id/view的mMeasureWidth=1440px,mMeasureHeight=600px。 id/linear 的子View的高度都计算完毕了，接下来id/linear就通过所有子View的测量结果计算自己的高宽，id/linear是LinearLayout，所有它的高度计算简单理解就是子View的高度的累积+自己的Padding. 最终算出id/linear的mMeasureWidth=1440px,mMeasureHeight=987px。 最终算出id/linear出来后，id/content 就要根据它唯一的子View id/linear 的测量结果和自己的之前算出的MeasureSpec一起来测量自己的结果，具体计算的逻辑去看FrameLayout onMeasure 函数的计算过程。以此类推，接下来测量ViewRoot,然后再测量id/statusBarBackground,虽然不知道id/statusBarBackground 是什么，但是调试的过程中，测出的它的高度=100px, 和 id/content 的paddingTop 刚好相等。在最后测量DecorView 的高宽，最终整个测量过程结束。所有的View的大小测量完毕。所有的getMeasureWidth 和 getMeasureWidth 都已经有值了。Measure 分析到此为止 layout过程123mView.measure(childWidthMeasureSpec, childHeightMeasureSpec); ......mView.layout(0, 0, mView.getMeasuredWidth(), mView.getMeasuredHeight()); performTraversals 方法执行完mView.measure 计算出mMeasuredXXX后就开始执行layout 函数来确定View具体放在哪个位置，我们计算出来的View目前只知道view矩阵的大小，具体这个矩阵放在哪里，这就是layout 的工作了。layout的主要作用 ：根据子视图的大小以及布局参数将View树放到合适的位置上。 既然是通过mView.layout(0, 0, mView.getMeasuredWidth(), mView.getMeasuredHeight()); 那我们来看下layout 函数做了什么，mView肯定是个ViewGroup，不会是View,我们直接看下ViewGroup 的layout函数 1234567891011public final void layout(int l, int t, int r, int b) &#123; if (!mSuppressLayout &amp;&amp; (mTransition == null || !mTransition.isChangingLayout())) &#123; if (mTransition != null) &#123; mTransition.layoutChange(this); &#125; super.layout(l, t, r, b); &#125; else &#123; // record the fact that we noop'd it; request layout when transition finishes mLayoutCalledWhileSuppressed = true; &#125;&#125; 代码可以看个大概，LayoutTransition是用于处理ViewGroup增加和删除子视图的动画效果，也就是说如果当前ViewGroup未添加LayoutTransition动画，或者LayoutTransition动画此刻并未运行，那么调用super.layout(l, t, r, b)，继而调用到ViewGroup中的onLayout，否则将mLayoutSuppressed设置为true，等待动画完成时再调用requestLayout()。这个函数是final 不能重写，所以ViewGroup的子类都会调用这个函数，layout 的具体实现是在super.layout(l, t, r, b)里面做的，那么我接下来看一下View类的layout函数 12345678910111213141516public final void layout(int l, int t, int r, int b) &#123; ..... //设置View位于父视图的坐标轴 boolean changed = setFrame(l, t, r, b); //判断View的位置是否发生过变化，看有必要进行重新layout吗 if (changed || (mPrivateFlags &amp; LAYOUT_REQUIRED) == LAYOUT_REQUIRED) &#123; if (ViewDebug.TRACE_HIERARCHY) &#123; ViewDebug.trace(this, ViewDebug.HierarchyTraceType.ON_LAYOUT); &#125; //调用onLayout(changed, l, t, r, b); 函数 onLayout(changed, l, t, r, b); mPrivateFlags &amp;= ~LAYOUT_REQUIRED; &#125; mPrivateFlags &amp;= ~FORCE_LAYOUT; ..... &#125; 1、setFrame(l, t, r, b) 可以理解为给mLeft 、mTop、mRight、mBottom赋值，然后基本就能确定View自己在父视图的位置了，这几个值构成的矩形区域就是该View显示的位置，这里的具体位置都是相对与父视图的位置。 2、回调onLayout，对于View来说，onLayout只是一个空实现，一般情况下我们也不需要重载该函数,： 123protected void onLayout(boolean changed, int left, int top, int right, int bottom) &#123; &#125; 对于ViewGroup 来说，唯一的差别就是ViewGroup中多了关键字abstract的修饰，要求其子类必须重载onLayout函数。 123@Override protected abstract void onLayout(boolean changed, int l, int t, int r, int b); 而重载onLayout的目的就是安排其children在父视图的具体位置，那么如何安排子View的具体位置呢？ 123456int childCount = getChildCount() ; for(int i=0 ;i&lt;childCount ;i++)&#123; View child = getChildAt(i) ; //整个layout()过程就是个递归过程 child.layout(l, t, r, b) ; &#125; 代码很简单，就是遍历自己的孩子，然后调用 child.layout(l, t, r, b) ，给子view 通过setFrame(l, t, r, b) 确定位置，而重点是(l, t, r, b) 怎么计算出来的呢。还记得我们之前测量过程，测量出来的MeasuredWidth和MeasuredHeight吗？还记得你在xml 设置的Gravity吗？还有RelativeLayout 的其他参数吗，没错，就是这些参数和MeasuredHeight、MeasuredWidth 一起来确定子View在父视图的具体位置的。具体的计算过程大家可以看下最简单FrameLayout 的onLayout 函数的源码，每个不同的ViewGroup 的实现都不一样，这边不做具体分析了吧。 3、MeasuredWidth和MeasuredHeight这两个参数为layout过程提供了一个很重要的依据（如果不知道View的大小，你怎么固定四个点的位置呢），但是这两个参数也不是必须的，layout过程中的4个参数l, t, r, b完全可以由我们任意指定，而View的最终的布局位置和大小（mRight - mLeft=实际宽或者mBottom-mTop=实际高）完全由这4个参数决定，measure过程得到的mMeasuredWidth和mMeasuredHeight提供了视图大小测量的值，但我们完全可以不使用这两个值，所以measure过程并不是必须的。如果我们不使用这两个值，那么getMeasuredWidth() 和getWidth() 就很有可能不是同一个值，它们的计算是不一样的： 123456public final int getMeasuredWidth() &#123; return mMeasuredWidth &amp; MEASURED_SIZE_MASK; &#125; public final int getWidth() &#123; return mRight - mLeft; &#125; layout 过程相对简单些，分析就到此为止。 draw过程performTraversals 方法的下一步就是mView.draw(canvas); 因为View的draw 方法一般不去重写，官网文档也建议不要去重写draw 方法，所以下一步执行就是View.java的draw 方法，我们来看下源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public void draw(Canvas canvas) &#123; ... /* * Draw traversal performs several drawing steps which must be executed * in the appropriate order: * * 1. Draw the background * 2. If necessary, save the canvas' layers to prepare for fading * 3. Draw view's content * 4. Draw children * 5. If necessary, draw the fading edges and restore layers * 6. Draw decorations (scrollbars for instance) */ // Step 1, draw the background, if needed ... background.draw(canvas); ... // skip step 2 &amp; 5 if possible (common case) ... // Step 2, save the canvas' layers ... if (solidColor == 0) &#123; final int flags = Canvas.HAS_ALPHA_LAYER_SAVE_FLAG; if (drawTop) &#123; canvas.saveLayer(left, top, right, top + length, null, flags); &#125; ... // Step 3, draw the content if (!dirtyOpaque) onDraw(canvas); // Step 4, draw the children dispatchDraw(canvas); // Step 5, draw the fade effect and restore layers if (drawTop) &#123; matrix.setScale(1, fadeHeight * topFadeStrength); matrix.postTranslate(left, top); fade.setLocalMatrix(matrix); canvas.drawRect(left, top, right, top + length, p); &#125; ... // Step 6, draw decorations (scrollbars) onDrawScrollBars(canvas); &#125; 注释写得比较清楚，一共分成6步，看到注释没有（ // skip step 2 &amp; 5 if possible (common case)）除了2 和 5之外 我们一步一步来看：1、第一步：背景绘制看注释即可，不是重点 12345678910111213private void drawBackground(Canvas canvas) &#123; Drawable final Drawable background = mBackground; ...... //mRight - mLeft, mBottom - mTop layout确定的四个点来设置背景的绘制区域 if (mBackgroundSizeChanged) &#123; background.setBounds(0, 0, mRight - mLeft, mBottom - mTop); mBackgroundSizeChanged = false; rebuildOutline(); &#125; ...... //调用Drawable的draw() 把背景图片画到画布上 background.draw(canvas); ...... &#125; 2、第三步，对View的内容进行绘制。onDraw(canvas) 方法是view用来draw 自己的，具体如何绘制，颜色线条什么样式就需要子View自己去实现，View.java 的onDraw(canvas) 是空实现，ViewGroup 也没有实现，每个View的内容是各不相同的，所以需要由子类去实现具体逻辑。 3、第4步 对当前View的所有子View进行绘制dispatchDraw(canvas) 方法是用来绘制子View的，View.java 的dispatchDraw()方法是一个空方法,因为View没有子View,不需要实现dispatchDraw ()方法，ViewGroup就不一样了，它实现了dispatchDraw ()方法： 1234567891011121314151617181920@Override protected void dispatchDraw(Canvas canvas) &#123; ... if ((flags &amp; FLAG_USE_CHILD_DRAWING_ORDER) == 0) &#123; for (int i = 0; i &lt; count; i++) &#123; final View child = children[i]; if ((child.mViewFlags &amp; VISIBILITY_MASK) == VISIBLE || child.getAnimation() != null) &#123; more |= drawChild(canvas, child, drawingTime); &#125; &#125; &#125; else &#123; for (int i = 0; i &lt; count; i++) &#123; final View child = children[getChildDrawingOrder(count, i)]; if ((child.mViewFlags &amp; VISIBILITY_MASK) == VISIBLE || child.getAnimation() != null) &#123; more |= drawChild(canvas, child, drawingTime); &#125; &#125; &#125; ...... &#125; 代码一眼看出，就是遍历子View然后drawChild(),drawChild()方法实际调用的是子View.draw()方法,ViewGroup类已经为我们实现绘制子View的默认过程，这个实现基本能满足大部分需求，所以ViewGroup类的子类（LinearLayout,FrameLayout）也基本没有去重写dispatchDraw方法，我们在实现自定义控件，除非比较特别，不然一般也不需要去重写它， drawChild()的核心过程就是为子视图分配合适的cavas剪切区，剪切区的大小正是由layout过程决定的，而剪切区的位置取决于滚动值以及子视图当前的动画。设置完剪切区后就会调用子视图的draw()函数进行具体的绘制了。 4、第6步 对View的滚动条进行绘制不是重点，知道有这东西就行，onDrawScrollBars 的一句注释 ：Request the drawing of the horizontal and the vertical scrollbar. The scrollbars are painted only if they have been awakened first. 一张图看下整个draw的递归流程。 到此整个绘制过程基本讲述完毕了。","categories":[{"name":"Android","slug":"Android","permalink":"http://wenyiqingnian.xyz/categories/Android/"}],"tags":[{"name":"android","slug":"android","permalink":"http://wenyiqingnian.xyz/tags/android/"}]},{"title":"linux用户控件、内和空间","slug":"Linux 用户空间 内核空间","date":"2017-09-07T12:30:15.000Z","updated":"2018-05-06T13:11:43.000Z","comments":true,"path":"2017/09/07/Linux 用户空间 内核空间/","link":"","permalink":"http://wenyiqingnian.xyz/2017/09/07/Linux 用户空间 内核空间/","excerpt":"","text":"用户空间就是用户进程所在的内存区域，相对的，系统空间就是操作系统占据的内存区域。 用户进程和系统进程的所有数据都在内存中。 是谁来划分内存空间的呢？ 在电脑开机之前，内存就是一块原始的物理内存。什么也没有。开机加电，系统启动后，就对物理内存进行了划分。当然，这是系统的规定，物理内存条上并没有划分好的地址和空间范围。这些划分都是操作系统在逻辑上的划分。不同版本的操作系统划分的结果都是不一样的。 为什么要划分用户空间和系统空间呢？当然是有必要的。操作系统的数据都是存放于系统空间的，用户进程的数据是存放于用户空间的。这是第一点，不同的身份，数据放置的位置必然不一样，否则大混战就会导致系统的数据和用户的数据混在一起，系统就不能很好的运行了。分开来存放，就让系统的数据和用户的数据互不干扰，保证系统的稳定性。分开存放，管理上很方便，而更重要的是，将用户的数据和系统的数据隔离开，就可以对两部分的数据的访问进行控制。这样就可以确保用户程序不能随便操作系统的数据，这样防止用户程序误操作或者是恶意破坏系统。 处于用户态的程序只能访问用户空间，而处于内核态的程序可以访问用户空间和内核空间。那么用户态和内核态有什么区别呢？ 当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。即此时处理器在特权级最低的（3级）用户代码中运行。 内核态与用户态是操作系统的两种运行级别,Intel x86架构提供Ring0-Ring3四种级别的运行模式，Ring0级别最高，Ring3最低。Linux使用了Ring3级别运行用户态，Ring0作为 内核态，没有使用Ring1和Ring2。Ring3状态不能访问Ring0的地址空间，包括代码和数据。程序特权级别的不同，其所拥有的权力也不同。如下图所示。 用户态切换到内核态的3种方式 a. 系统调用 这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。 b. 异常 当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。 c. 外围设备的中断 当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。 这3种方式是系统在运行时由用户态转到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wenyiqingnian.xyz/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://wenyiqingnian.xyz/tags/linux/"}]},{"title":"webrtc音频总结","slug":"webrtc 音频","date":"2017-08-16T13:10:30.000Z","updated":"2018-05-06T13:37:22.000Z","comments":true,"path":"2017/08/16/webrtc 音频/","link":"","permalink":"http://wenyiqingnian.xyz/2017/08/16/webrtc 音频/","excerpt":"","text":"webrtc/modules/audio_device/android/audio_record_jni.cc 这个文件，是音频采集jni类文件。 Android Audio Record 和 JNI 通信接口包括： 123// java 调用 c++ 接口nativeCacheDirectBufferAddressnativeDataIsRecorded 123456// c++ 回调 java 接口initRecordingstartRecordingstopRecordingenableBuiltInAECenableBuiltInNS nativeCacheDirectBufferAddress 和 nativeDataIsRecorded 只是为了高效的将 AudioRecord 采集到的音频数据传递给 native。 WebRtcVoiceEngineWebRtcVoiceEngine 初始化 12345678910111213WebRtcVoiceEngine::Init()&#123; send_codecs_ = CollectCodecs(encoder_factory_-&gt;GetSupportedEncoders()); recv_codecs_ = CollectCodecs(decoder_factory_-&gt;GetSupportedDecoders()); adm_ = webrtc::AudioDeviceModule::Create( webrtc::AudioDeviceModule::kPlatformDefaultAudio ); webrtc::adm_helpers::Init(adm()); webrtc::apm_helpers::Init(apm());&#125; 可知，WebRtcVoiceEngine 里面的 adm_ 就是 AudioDeviceModule ，代码在 /modules/audio_device/audio_device_impl.cc 在 webrtcvoiceengine.h123456789101112131415161718192021222324252627// WebRtcVoiceEngine//public void Init();AudioState GetAudioState();VoiceMediaChannel* CreateChannel(Call call, MediaConfig config, AudioOptions options);AudioCodec send_codecs();AudioCodec recv_codecs();RtpCapabilities GetCapabilities();void RegisterChannel(WebRtcVoiceMediaChannel* channel);void UnregisterChannel(WebRtcVoiceMediaChannel* channel);bool StartAecDump();void StopAecDump();//privateAudioDeviceModule adm_;AudioEncoderFactory encoder_factory_;AudioDecoderFactory decoder_factory_;AudioMixer audio_mixer_;AudioProcessing apm_;AudioState audio_state_;AudioCodec send_codecs_;AudioCodec recv_codecs_;WebRtcVoiceMediaChannel channels_; audio_device//webrtc/modules/audio_device/ audio_device_impl.cc 123456789AudioDeviceModule::Create()&#123; audioDevice(new AudioDeviceModuleImpl(audio_layer)); audioDevice-&gt;CheckPlatform(); audioDevice-&gt;CreatePlatformSpecificObjects(); audioDevice-&gt;AttachAudioBuffer(); return audioDevice;&#125; 123456789101112131415161718192021222324252627282930313233343536373839AudioDeviceModuleImpl::CreatePlatformSpecificObjects()&#123; // WEBRTC_DUMMY_AUDIO_BUILD audio_device_.reset(new AudioDeviceDummy()); // WEBRTC_DUMMY_FILE_DEVICES audio_device_.reset(FileAudioFactory::CreateFileAudioDevice()); // WEBRTC_WINDOWS_CORE_AUDIO_BUILD audio_device_.reset(new AudioDeviceWindowsCore()); // WEBRTC_ANDROID audio_manager_android_.reset(new AudioManager()); if(audio_layer == kPlatformDefaultAudio)&#123; audio_layer = kAndroidOpenSLESAudio; &#125; else if(isLowLatencySupported)&#123; audio_layer = kAndroidJavaInputAndroidOpenSLESOutputAudio; &#125; else &#123; audio_layer = kAndroidJavaAudio; &#125; if(kAndroidJavaAudio)&#123; audio_device_.reset(new AudioDeviceTemplate&lt;AudioRecordJni, AudioTrackJni&gt;()) &#125; else if(kAndroidOpenSLESAudio)&#123; audio_device_.reset(new AudioDeviceTemplate&lt;OpenSLESRecorder, OpenSLESPlayer&gt;()); &#125; else if(kAndroidJavaInputAndOpenSLESOutputAudio)&#123; audio_device_.reset(new AudioDeviceTemplate&lt;AudioRecordJni, OpenSLESPlayer&gt;()) &#125; // WEBRTC_LINUX if(kLinuxPulseAudio || kPlatformDefaultAudio)&#123; audio_device_.reset(new AudioDeviceLinuxPulse()) &#125; else if(kLinuxAlsaAudio)&#123; audio_device_.reset(new AudioDeviceLinuxALSA()) &#125; // WEBRTC_IOS audio_device_.reset(new AudioDeviceIOS()) // WEBRTC_MAC audio_device_.reset(new AudioDeviceMac())&#125; 我们以 Android 为例；使用 AudioDeviceTemplate 封装 音频输入（采集）、输出类型（渲染）；目前使用 AudioRecordJni 和 AudioTrackJni。如果直接使用 NDK 的openSLES 开发的化，使用的是 OpenSLESRecorder 和 OpenSLESPlayer。 audio_manager.h12345678910// JavaAudioManagerbool Init()void Close()bool IsCommunicationModeEnabled()bool IsDeviceBlacklistedForOpenSLESUsage()// privateJNICALL CacheAudioParameters()void OnCacheAudioParameters() audio_record_jni.h1234567891011121314151617181920212223242526272829//JavaAudioRecordint InitRecording(int sample_reate, size_t channels);bool StartRecording();bool StopRecording();bool EnableBuiltInAEC(bool enable);bool EnableBuiltInNS(bool enable);// publicint32_t Init();int32_t Terminate();int32_t InitRecording();bool RecordingIsInitialized();int32_t StartRecording();int32_t StopRecording();bool Recording();void AttachAudioBuffer();int32_t EnableBuiltInAEC(bool enable);int32_t EnableBuiltInAGC(bool enable);int32_t EnableBuiltInNS(bool enable);// privateJNICALL CacheDirectBufferAddress()void OnCacheDirectBufferAddress(jobject byte_buffer)JNICALL DataIsRecorded();void OnDataIsRecorded(int length); audio_track_jni.h 12345678910111213141516171819202122232425262728293031// JavaAudioTrackbool InitPlayout(int sample_rate, int channels);bool StartPlayout();bool StopPlayout();bool SetStreamVolume(int volume);int GetStreamMaxVolume();int GetStreamVolume();// publicInit()Terminate()InitPlayout()PlayoutIsInitialized()StartPlayout()StopPlayout()Playing()SpeakerVolumeIsAvailable(bool available);SetSpeakerVolume(volume);SpeakerVolume(volume);MaxSpeakerVolume(max_volume);MinSpeakerVolume(min_volume);AttachAudioBuffer(audioBuffer);// privateJNICALL CacheDirectBufferAddress();void OnCacheDirectBufferAddress(jobject byte_buffer);JNICALL GetPlayoutData();void OnGetPlayoutData(size_t length); AudioRecordJni音频采集初始化AudioRecordJni 初始化时，在构造方法中初始化 JavaAudioRecord。123j_audio-record_.reset( new JavaAudioRecord()) 然后在 webrtcvoiceengine 中 AddSendStream 后，SetSend() 配置媒体通道发送。 12345678910111213//media/engine/webrtcvoiceengine.ccWebRtcVoiceMediaChannel::SetSend(bool send)&#123; ... if(send)&#123; engine()-&gt;ApplyOptions(options_); if(!engine()-&gt;adm()-&gt;RecordingIsInitialized() &amp;&amp; !engine()-&gt;adm()-&gt;Recording())&#123; engine()-&gt;adm()-&gt;InitRecording(); &#125; &#125; ...&#125; 这里面会初始化 AudioRecord。 InitRecording() 方法实现，在 Android 中实在 audio_record_jni.cc 的 JavaAudioRecord::InitRecording() ，最终通过 JNI 回调 Java 层的 InitRecording() 方法。 音频采集初始化完成后，就要开始采集音频数据。 /audio/audio_send_stream.cc音频发送流里面 AudioSendStream::Start() 方法启动音频流发送； 1234AudioSendSstream::Start()&#123; channel_proxy_-&gt;StartSend(); audio_state()-&gt;AddSendingStream(this, encoder_sample_rate_hz_, encoder_num_channels_);&#125; 调用 /audio/audio_state.cc 的 AudioState::AddSendingStream() 方法； 123456AudioState::AddSendingStream()&#123; auto* adm = config_.audio_device_module.get(); ... amd-&gt;StartRecording(); ...&#125; 音频开关另外，PeerConnection 提供了 音频采集开关。 1234//org.webrtc.PeerConnection.javapublic void setAudioRecording(boolean recording)&#123; nativeSetAudioRecording();&#125; 对应的JNI方法1234//JNI/pc/peerconnection.ccvoid JNI_PeerConnection_SetAudioRecording()&#123; ExtractNativePC(jni,j_pc)-&gt;SetAudioRecording(recording);&#125; 其实JNI方法也是调用 webrtc 的 peerconnection 1234567//webrtc/pc/peerconnection.ccPeerConnection::SetAudioRecording(bool recording)&#123; auto audio_state = factory_-&gt;channel_manager()-&gt;media_engine()-&gt;GetAudioState(); // AudioState audio_state-&gt;SetRecording(recording);&#125; 由上代码可知， 通过 WebRtcVoiceEngine 的 GetAudioState() 方法获取 audio_state。然后通过 audio_state 设置音频采集开关。 在 AudioState::SetRecording() 方法调用具体设备模块开始或停止音频采集。 123456789//webrtc/audio/audio_state.ccAudioState::SetRecording(bool enabled)&#123; ... if(enabled)&#123; config_.audio_device_module-&gt;StartRecording(); &#125;else&#123; config_.audio_device_module-&gt;StopRecording(); &#125;&#125; 音频采集具体实现这里我们只以Android为例。 如果使用 opensles ndk 采集音频，采集的具体实现在 opensles_recorder.cc 文件的 StartRecording() 方法。 1234// modules/audio_device/android/opensles_recorder.ccint OpenSLESRecorder::StartRecording()&#123; ...&#125; 这种方法的具体实现我们暂时不深入。 我们讨论 java 实现方案。 java 实现的jni类，audio_record_jni.cc123456//modules/audio_device/android/audio_record_jni.ccAudioRecordJni::StartRecording()&#123; ... j_audio_record_-&gt;StartRecording() ...&#125; j_audio_record_-&gt;StartRecording() 调用的就是 AudioRecordJni::JavaAudioRecord::StartRecording() 方法。 123AudioRecordJni::JavaAudioRecord::StartRecording()&#123; return audio_record_-&gt;CallBooleanMethod(start_recording_);&#125; CallBooleanMethod 就是jni回调java 实现的封装，最终实现回调 WebRtcAudioRecord.java 中的 StartRecording() 方法。 123456//org.webrtc.voiceengine.WebRtcAudioRecord.java boolean startRecording()&#123; audioRecord.startRecording(); audioThread = new AudioRecordThread(&quot;AudioRecordJavaThread&quot;); audioThread.start();&#125; 音频采集线程音频采集线 AudioRecordThread；我们只跟踪 run() 方法。 123456789101112131415161718@Overridepublic void run()&#123; ... while(keepAlive)&#123; int bytesRead = audioRecord.read(byteBuffer, byteBuffer.capacity()); // 通知 native 音频数据 nativeDataIsRecorded(bytesRead, nativeAudioRecord); // 应用音频采集回调 byte[] data = Arrays.copyOf(byteBuffer.array(), byteBuffer.capacity()); audioSamplesReadyCallback.onWebRtcAudioRecordSamplesReady( new AudioSamples(audioRecord, data) ); &#125; ...&#125;","categories":[{"name":"webrtc","slug":"webrtc","permalink":"http://wenyiqingnian.xyz/categories/webrtc/"}],"tags":[{"name":"webrtc","slug":"webrtc","permalink":"http://wenyiqingnian.xyz/tags/webrtc/"}]},{"title":"linux的地址映射","slug":"linux的地址映射","date":"2017-06-18T12:30:15.000Z","updated":"2018-06-24T14:47:20.000Z","comments":true,"path":"2017/06/18/linux的地址映射/","link":"","permalink":"http://wenyiqingnian.xyz/2017/06/18/linux的地址映射/","excerpt":"","text":"内存管理1 物理内存Linux 内存的最小单位为页，一页通常是4K，初始化时，linux 会为每个物理内存建立一个page的管理结构，操作物理内存时 实际上就是操作page。 2 进程内存Linux 进程是通过vma进行管理的，每一个进程都有一个task_struct 结构体进行维护，其中mm_struct结构体管理进程内的所有内存。mm_struct 的结构如下 123456struct mm_struct &#123;struct vm_area_struct * mmap; /* list of VMAs */int map_count; /* number of VMAs */ 可以看到 mm_struct 中有个vma链表，其中每个vma节点对应一段连续内存，（在进程的虚拟地址空间是连续的，物理空间中不一定）。当使用malloc 申请内存时，内核会给进程增加vma节点。 对于32位的linux 操作系统，为每一个进程分配的寻址空间都是4g，linux将这4g的虚拟内存分为两部分 用户空间 0-3g 内核空间 3-4g 用户空间和内核空间linux将 进程虚拟地址中的0-3g空间 用作用户空间. 为什么会有用户控件和内核空间的划分是为了将用户空间与内核空间区分开，为了访问安全Linux使用两级保护机制：0级供内核使用，3级供用户程序使用。每个进程有各自的私有用户空间（0～3G），这个空间对系统中的其他进程是不可见的。如果要访问内核空间，会有优先级的限制从而在一定程度上保护了内核空间的安全性。 为什么会按照内核空间1g，用户空间3g来划分。这个比例其实并不是固定的，它可以是一个人为设定值，可以通过重新编译linux内核来实现更改。 进程只分配了4g虚拟内存，如果物理内存大于4g，如何做到访问其余的内存呢这里涉及到高端地址的概念了 当内核模块代码或线程访问内存时，代码中的内存地址都为逻辑地址，而对应到真正的物理内存地址，需要地址一对一的映射，如果将内核空间的1g内存全部做线性映射【注1】，那么当物理内存为8g的时候，剩下的4g内存将无法被访问到。为了解决这个问题，linux将内核空间分为了3部分 ZONE_DMA 内存开始的16MB ZONE_NORMAL 16MB~896MB ZONE_HIGHMEM 896MB ~ 结束 可以看到，低dma 和 normal 内存区与物理内存做了线性映射。但是高端内存（最上面的128m）并未与物理内存进行线性映射，事实上，linux正是借助这小块高端内存 才做到了用128m 访问剩余4g物理内存的。 当内核想访问高于896MB物理地址内存时，从0xF8000000 ~ 0xFFFFFFFF地址空间范围内找一段相应大小空闲的逻辑地址空间，借用一会。借用这段逻辑地址空间，建立映射到想访问的那段物理内存（即填充内核PTE页面表），临时用一会，用完后归还。这样别人也可以借用这段地址空间访问其他物理内存，实现了使用有限的地址空间，访问所有所有物理内存。如下图。 从上面的描述，我们可以知道高端内存的最基本思想：借一段地址空间，建立临时地址映射，用完后释放，达到这段地址空间可以循环使用，访问所有物理内存。 注1：线性映射与非线性映射：Linux内核只有1G的空间，通常内核把物理内存与其地址空间做了线性映射，也就是一一映，这样可以提高内存访问速度。当内存超过1G时，线性访问机制就不够用了，只能有1G的内存可以被映射，剩余的内存无法被内核使用。当然无法忍受。为了解决这一问题，linux把内核分为线性区与非线性区两部分。线性区规定最大为896M，剩下的为非线性区。与线性区不同，非线性区不会提前进行内存映射，而是在使用时动态映射。线性区映射的物理内存成为低端内存，剩下的内存被称为高端内存。假设物理内存为2G，则地段的896M为低端内存，通过线性映射给内核使用。其他的1128M内存为高端内存，可以被内核的非线性区使用。由于要使用128M非线性区来管理超过1G的高端内存，所以通常都不会映射，只有使用时才使kmap映射，使用完后要尽快用kunmap释放。对于物理内存为1G的内核，系统不会真的分配896M给线性空间，896M最大限制。下面是一个1.5G物理内存linux系统的真实分配情况，只有721M分配给了低端内存区，如果是1G的linxu系统，分配的就更少了。 123MemTotal 1547MBHighTotal 825MBLowTotal 721MB 申请高端内存时，如果高端内存不够了，linux也会去低端内存区申请，反之则不行。 内核空间被所有进程共享，那么进程里的内核空间都是一样的吗？是的，进程里的内核空间都是一样的。Linux启动后，第一个进程是init进程，它的页表与内核页表是一致的，系统中的其他所有进程都是init进程的儿子或后代。Linux中进程创建通过fork()实现，子进程的PGD（进程页目录）与PTE（进程页表项，里面记录了具体的物理地址）是父进程的拷贝此时会把内核进程的页表拷贝到每个进程中。在各个进程的运行过程中，他们的页表可能会发生变化，比如发生缺页异常。如果是进程页表发生改变，则只要改变进程的页表项（0G~3G）就够了，如果是内核页表发生变化，则必须通知到所有进程改变各自维护的一份内核页表（3G~4G）。最简单的方法是每次内核页表改变后，遍历所有进程去改变他们维护的内核页表，显然效率很低。Linux内核通过page fault机制实现内核页表的一致。内核页表改变时，只改变init进程的内核页表。当进程访问该页时，会发生一个缺页异常，异常处理中通过init进程更新当前进程的内核页表。 进程的内核空间都是一样的，那为什么要把每个进程的内核空间都拷贝一份，不可以进程的虚拟地址只有进程空间，而所有内核空间单独只维持一份吗？目的其实很简单，为了减少内核调用的系统开销。我们常说，切换线程和切换进程相比，进程切换的开销更大，是因为每一个进程都对应着一个进程页表，切换进程会对应页表的切换，线程因为在同一个进程里，很多资源是共享的，切换线程（其实linux里 线程与进程是同一个东西，切换线程也对应页表的切换，只不过页表内容没有变而已）相当于只切换一些上下文。从问题中提出的两个方式来考虑开销问题。 每个进程使用独立页表 （当前内核的做法） 所有进程在内核态使用同一页表，但用户态每进程使用独立页表 考虑两个场景 场景1：用户态切陷入内核态采用方案1），进程从用户态陷入内核态时（系统调用，中断都可触发），不需要切换页表；采用方案2），用户态陷入内核态时，需要切换页表。并且进入内核态时，根据没有跳板(一段专代码）来完成切换，因为内核地址空间在切换之后根本没有映射。 场景2：任务切换如果进程跑在用户态，来了中断，陷入内核态，然后任务切换。 方案1）在陷入内核态时有一次页表切换；方案2）在任务切切换有一次页表切换。两者打平手。但通常任务切换之后，新任务也要回到用户态的，那方案1）又会引入一次页切换。在程序的实际运行过程中，程序调用系统调用的次数比任务切换的次数多，所以方案1）远比方案2）有优势。 地址转换一张图解释 用户空间 内核空间 物理地址的转换关系 在linux中，物理地址用page结构 表示，物理内存在初始化时已经生成了page结构管理，其他地址空间则需要生成page再进行管理（ioremap）。物理地址可以被映射到内核空间或进程空间，也可以从内核空间或进程用户空间解除物理地址（page）。 所有转换中，只有mmap可以在进程中使用，其他都是内核函数。即使使用mmap，其内部也是靠内核中使用remap_pfn_range实现的。所有地址空间转换都在内核中实现。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wenyiqingnian.xyz/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://wenyiqingnian.xyz/tags/linux/"}]},{"title":"MK语法规范","slug":"MK语法规范","date":"2017-05-07T12:11:15.000Z","updated":"2018-05-06T13:07:44.000Z","comments":true,"path":"2017/05/07/MK语法规范/","link":"","permalink":"http://wenyiqingnian.xyz/2017/05/07/MK语法规范/","excerpt":"","text":"Android.mk文件语法规范及使用模板 Introduction:Android.mk编译文件是用来向Android NDK描述你的C,C++源代码文件的， 这篇文档描述了它的语法。在阅读下面的内容之前，假定你已经阅读了docs/OVERVIEW.TXT文件，了解了它们的用途。 概述:一个 Android.mk file用来向编译系统描述你的源代码。具体来说：-该文件是GNU Makefile的一小部分，会被编译系统解析一次或更多次的build系统。因此，您应尽量减少您声明的变量，不要认为某些变量在解析过程中不会被定义。-这个文件的语法允许把你的源代码组织成模块，一个模块属下列类型之一： 静态库 、共享库 只有共享库将被安装/复制到您的应用软件包。虽然静态库能被用于生成共享库。 你可以在每一个Android.mk file中定义一个或多个模块，你也可以在几个模块中使用同一个源代码文件。 -编译系统为你处理许多细节问题。例如，你不需要在你的Android.mk中列出头文件和依赖文件。NDK编译系统将会为你自动处理这些问题。这也意味着，在升级NDK后，你应该得到新的toolchain/platform支持，而且不需要改变你的Android.mk文件。 注意，这个语法同公开发布的Android平台的开源代码很接近，然而编译系统实现他们的方式却是不同的，这是故意这样设计的，可以让程序开发人员重用外部库的源代码更容易。 简单的例子: 在描述语法细节之前，咱们来看一个简单的”hello world”的例子，比如，下面的文件： 123sources/helloworld/helloworld.csources/helloworld/Android.mk ‘helloworld.c’是一个JNI共享库，实现返回”hello world”字符串的原生方法。 相应的Android.mk文件会象下面这样： 12345678910111213---------- cut here ------------------LOCAL_PATH := $(call my-dir)include $(CLEAR_VARS)LOCAL_MODULE:= helloworldLOCAL_SRC_FILES := helloworld.cinclude $(BUILD_SHARED_LIBRARY)---------- cut here ------------------ 好，我们来解释一下这几行代码： 1LOCAL_PATH := $(call my-dir) 一个Android.mk file首先必须定义好LOCAL_PATH变量。它用于在开发树中查找源文件。在这个例子中，宏函数’my-dir’, 由编译系统提供，用于返回当前路径（即包含Android.mk file文件的目录）。 1include $( CLEAR_VARS) CLEAR_VARS由编译系统提供，指定让GNU MAKEFILE为你清除许多LOCAL_XXX变量（例如 LOCAL_MODULE, LOCAL_SRC_FILES, LOCAL_STATIC_LIBRARIES, 等等…), 除LOCAL_PATH 。这是必要的，因为所有的编译控制文件都在同一个GNU MAKE执行环境中，所有的变量都是全局的。 1LOCAL_MODULE := helloworld LOCAL_MODULE变量必须定义，以标识你在Android.mk文件中描述的每个模块。名称必须是唯一的，而且不包含任何空格。注意编译系统会自动产生合适的前缀和后缀，换句话说，一个被命名为’foo’的共享库模块，将会生成’libfoo.so’文件。 重要注意事项 如果你把库命名为‘libhelloworld’，编译系统将不会添加任何的lib前缀，也会生成libhelloworld.so，这是为了支持来源于Android平台的源代码的Android.mk文件，如果你确实需要这么做的话。 1LOCAL_SRC_FILES := helloworld.c LOCAL_SRC_FILES变量必须包含将要编译打包进模块中的C或C++源代码文件。注意，你不用在这里列出头文件和包含文件，因为编译系统将会自动为你找出依赖型的文件；仅仅列出直接传递给编译器的源代码文件就好。【注意，默认的C++源码文件的扩展名是’.cpp’. 指定一个不同的扩展名也是可能的，只要定义LOCAL_DEFAULT_CPP_EXTENSION变量，不要忘记开始的小圆点（也就是定义为‘.cxx’,而不是‘cxx’）（当然这一步我们一般不会去改它）】 1include $(BUILD_SHARED_LIBRARY) BUILD_SHARED_LIBRARY是编译系统提供的变量，指向一个GNU Makefile脚本（应该就是在build/core目录下的shared_library.mk），负责收集自从上次调用’include $(CLEAR_VARS)’以来，定义在LOCAL_XXX变量中的所有信息，并且决定编译什么，如何正确地去做。并根据其规则生成静态库。同理对于静态库。 在sources/samples目录下有更复杂一点的例子，写有注释的Android.mk文件，你可以看看。 参考: 这是一份你应该在Android.mk中依赖或定义的变量列表，您可以定义其他变量为自己使用， 但是NDK编译系统保留下列变量名： -以LOCAL_开头的名字（例如 LOCAL_MODULE） -以PRIVATE_, NDK_ or APP_开头的名字（内部使用） -小写名字（内部使用，例如’my-dir’） 如果您为了方便在Android.mk中定义自己的变量，我们建议使用MY_前缀，一个小例子： 12345678910111213---------- cut here ------------------MY_SOURCES := foo.cifneq ($(MY_CONFIG_BAR),)MY_SOURCES += bar.cendifLOCAL_SRC_FILES += $(MY_SOURCES)---------- cut here ------------------ 这些GNU Make 变量在你的Android.mk文件解析之前，就由编译系统定义好了。 注意在某些情况下，NDK可能分析Android.mk几次，每一次某些变量的定义会有不同。 1CLEAR_VARS 指向一个编译脚本，几乎所有未定义的LOCAL_XXX变量都在”Module-description”节中列出。 你必须在开始一个新模块之前包含这个脚本。 1include $(CLEAR_VARS) 1BUILD_SHARED_LIBRARY 指向编译脚本，收集所有的你在LOCAL_XXX变量中提供的信息，并且决定如何把你列出的源代码文件编译成一个共享库。注意，你必须至少在包含这个文件之前定义LOCAL_MODULE和LOCAL_SRC_FILES，使用例子： 1include $(BUILD_SHARED_LIBRARY) 注意这将生成一个名为lib$(LOCAL_MODULE).so的文件。 1BUILD_STATIC_LIBRARY 一个BUILD_SHARED_LIBRARY变量用于编译一个静态库。静态库不会复制到你的project/packages中，诞生能够用于编译共享库，（看下面描述的LOCAL_STATIC_LIBRARIES and LOCAL_STATIC_WHOLE_LIBRARIES） 使用例子： 1include $(BUILD_STATIC_LIBRARY) 注意，这将会生成一个名为lib$(LOCAL_MODULE).a的文件。 1TARGET_ARCH 目标CPU平台的名字，如同在android开放源码中指定的那样。如果是’arm’，表示要生成ARM兼容的指令，与CPU架构的修订版无关。 1TARGET_PLATFORM Android.mk解析的时候，目标Android平台的名字.详情可参考/development/ndk/docs/stable-apis.txt. android-3 -&gt; Official Android 1.5 system images android-4 -&gt; Official Android 1.6 system images android-5 -&gt; Official Android 2.0 system images 1TARGET_ARCH_ABI 暂时只支持两个value，armeabi和armeabi-v7a。在现在的版本中一般把这两个值简单的定义为arm，通过android 平台内部对它重定义来获得更好的匹配。 其他的ＡＢＩ将在以后的ＮＤＫ版本中介绍，它们会有不同的名字。注意所有基于ＡＲＭ的ＡＢＩ都会把’TARGET_ARCH’定义成‘ａｒｍ’，但是会有不同的‘TARGET_ARCH_ABI’ 1TARGET_ABI 目标平台和ABI的组合，它事实上被定义成$(TARGET_PLATFORM)-$(TARGET_ARCH_ABI) 在你想要在真实的设备中针对一个特别的目标系统进行测试时，会有用。在默认的情况下，它会是’android-3-arm’。 /*/ 下面是GNU Make ‘功能’宏，必须通过使用’$(call )’来求值，他们返回文本化的信息。 1my-dir 返回当前Android.mk所在的目录路径，相对于ＮＤＫ编译系统的顶层。这是有用的，在Android.mk文件的开头如此定义： 1LOCAL_PATH := $(call my-dir) 1all-subdir-makefiles 返回一个位于当前’my-dir’路径的子目录列表。例如，看下面的目录层次： 12345sources/foo/Android.mksources/foo/lib1/Android.mksources/foo/lib2/Android.mk 如果sources/foo/Android.mk包含一行： 1include $(call all-subdir-makefiles) 那么它就会自动包含sources/foo/lib1/Android.mk 和sources/foo/lib2/Android.mk 这项功能用于向编译系统提供深层次嵌套的代码目录层次。注意，在默认情况下，ＮＤＫ将会只搜索在sources/*/Android.mk中的文件。 1this-makefile 返回当前Makefile的路径（即这个函数调用的地方） 1parent-makefile 返回调用树中父Makefile路径。即包含当前Makefile的Makefile路径。 1grand-parent-makefile 猜猜看… /*/ 模块描述变量:下面的变量用于向编译系统描述你的模块。你应该定义在’include $(CLEAR_VARS)’和’include $(BUILD_XXXXX)’之间定义。正如前面描写的那样，$(CLEAR_VARS是一个脚本，清除所有这些变量，除非在描述中显式注明。 1LOCAL_PATH 这个变量用于给出当前文件的路径。你必须在Android.mk的开头定义，可以这样使用： 1LOCAL_PATH := $(call my-dir) 这个变量不会被$(CLEAR_VARS)清除，因此每个Android.mk只需要定义一次（即使你在一个文件中定义了几个模块的情况下）。 1LOCAL_MODULE 这是你模块的名字，它必须是唯一的，而且不能包含空格。你必须在包含任一的$(BUILD_XXXX)脚本之前定义它。模块的名字决定了生成文件的名字，例如，如果一个一个共享库模块的名字是，那么生成文件的名字就是lib.so。但是，在你的NDK生成文件中（或者Android.mk或者Application.mk），你应该只涉及(引用)有正常名字的其他模块。 1LOCAL_SRC_FILES 这是要编译的源代码文件列表。只要列出要传递给编译器的文件，因为编译系统自动为你计算依赖。 注意源代码文件名称都是相对于LOCAL_PATH的，你可以使用路径部分，例如： 1LOCAL_SRC_FILES := foo.c \\ toto/bar.c注意：在生成文件中都要使用UNIX风格的斜杠(/).windows风格的反斜杠不会被正确的处理。 1LOCAL_CPP_EXTENSION 这是一个可选变量，用来指定C++代码文件的扩展名，默认是’.cpp’,但是你可以改变它，比如： 1LOCAL_CPP_EXTENSION := .cxx 1LOCAL_C_INCLUDES 路径的可选配置，是从根目录开始的， 123456789all sources (C, C++ and Assembly). For example: LOCAL_C_INCLUDES := sources/foo Or even: LOCAL_C_INCLUDES := $(LOCAL_PATH)/../foo 需要在任何包含LOCAL_CFLAGS / LOCAL_CPPFLAGS标志之前。 1LOCAL_CFLAGS 可选的编译器选项，在编译C代码文件的时候使用。 这可能是有用的，指定一个附加的包含路径（相对于NDK的顶层目录），宏定义，或者编译选项。 重要信息：不要在Android.mk中改变optimization/debugging级别，只要在Application.mk中指定合适的信息，就会自动地为你处理这个问题，在调试期间，会让ＮＤＫ自动生成有用的数据文件。 123LOCAL_CXXFLAGSSame as LOCAL_CFLAGS for C++ source files 1LOCAL_CPPFLAGS 与LOCAL_CFLAGS相同，但是对C 和 C++ source files都适用。 1LOCAL_STATIC_LIBRARIES 应该链接到这个模块的静态库列表（使用BUILD_STATIC_LIBRARY生成），这仅仅对共享库模块才有意义。 1LOCAL_SHARED_LIBRARIES 这个模块在运行时要依赖的共享库模块列表，在链接时需要，在生成文件时嵌入的相应的信息。注意：这不会附加列出的模块到编译图，也就是，你仍然需要在Application.mk中把它们添加到程序要求的模块中。 1LOCAL_LDLIBS 编译你的模块要使用的附加的链接器选项。这对于使用”-l”前缀传递指定库的名字是有用的。例如，下面将告诉链接器生成的模块要在加载时刻链接到/system/lib/libz.so 1LOCAL_LDLIBS := -lz 看docs/STABLE-APIS.TXT获取你使用NDK发行版能链接到的开放的系统库列表。 1LOCAL_ALLOW_UNDEFINED_SYMBOLS 默认情况下，在试图编译一个共享库时，任何未定义的引用将导致一个“未定义的符号”错误。这对于在你的源代码文件中捕捉错误会有很大的帮助。 然而，如果你因为某些原因，需要不启动这项检查，把这个变量设为‘ｔｒｕｅ’。注意相应的共享库可能在运行时加载失败。（这个一般尽量不要去设为true） 1LOCAL_ARM_MODE 默认情况下，arm目标二进制会以thumb的形式生成（16位），你可以通过设置这个变量为arm如果你希望你的module是以32位指令的形式。 &apos;arm&apos; (32-bit instructions) mode. E.g.: LOCAL_ARM_MODE := arm 注意你同样可以在编译的时候告诉系统编译特定的类型，比如 LOCAL_SRC_FILES := foo.c bar.c.arm 这样就告诉系统总是将bar.c以arm的模式编译， Android.mk使用模板在一个Android.mk中可以生成多个可执行程序、动态库和静态库。 1，编译应用程序的模板：#Test Exe LOCAL_PATH := $(call my-dir) #include $(CLEAR_VARS) LOCAL_SRC_FILES:= main.c LOCAL_MODULE:= test_exe #LOCAL_C_INCLUDES := #LOCAL_STATIC_LIBRARIES := #LOCAL_SHARED_LIBRARIES := include $(BUILD_EXECUTABLE) （菜鸟级别解释：:=是赋值的意思，$是引用某变量的值）LOCAL_SRC_FILES中加入源文件路径，LOCAL_C_INCLUDES 中加入所需要包含的头文件路径，LOCAL_STATIC_LIBRARIES加入所需要链接的静态库（.a）的名称，LOCAL_SHARED_LIBRARIES中加入所需要链接的动态库（.so）的名称，LOCAL_MODULE表示模块最终的名称，BUILD_EXECUTABLE表示以一个可执行程序的方式进行编译。 2，编译静态库的模板：#Test Static Lib LOCAL_PATH := $(call my-dir) include $(CLEAR_VARS) LOCAL_SRC_FILES:= \\ helloworld.c LOCAL_MODULE:= libtest_static #LOCAL_C_INCLUDES := #LOCAL_STATIC_LIBRARIES := #LOCAL_SHARED_LIBRARIES := include $(BUILD_STATIC_LIBRARY) 一般的和上面相似，BUILD_STATIC_LIBRARY表示编译一个静态库。 3，编译动态库的模板：#Test Shared Lib LOCAL_PATH := $(call my-dir) include $(CLEAR_VARS) LOCAL_SRC_FILES:= \\ helloworld.c LOCAL_MODULE:= libtest_shared TARGET_PRELINK_MODULES := false #LOCAL_C_INCLUDES := #LOCAL_STATIC_LIBRARIES := #LOCAL_SHARED_LIBRARIES := include $(BUILD_SHARED_LIBRARY) 一般的和上面相似，BUILD_SHARED_LIBRARY表示编译一个共享库。 以上三者的生成结果分别在如下，generic依具体target会变： 12345out/target/product/generic/obj/EXECUTABLEout/target/product/generic/obj/STATIC_LIBRARYout/target/product/generic/obj/SHARED_LIBRARY 每个模块的目标文件夹分别为： 12345可执行程序：XXX_intermediates静态库： XXX_static_intermediates动态库： XXX_shared_intermediates 另外，在Android.mk文件中，还可以指定最后的目标安装路径，用LOCAL_MODULE_PATH和LOCAL_UNSTRIPPED_PATH来指定。不同的文件系统路径用以下的宏进行选择： 12345TARGET_ROOT_OUT：表示根文件系统。TARGET_OUT：表示system文件系统。TARGET_OUT_DATA：表示data文件系统。 用法如： 1LOCAL_MODULE_PATH:=$(TARGET_ROOT_OUT)","categories":[{"name":"AOSP","slug":"AOSP","permalink":"http://wenyiqingnian.xyz/categories/AOSP/"}],"tags":[{"name":"编译","slug":"编译","permalink":"http://wenyiqingnian.xyz/tags/编译/"},{"name":"mk","slug":"mk","permalink":"http://wenyiqingnian.xyz/tags/mk/"}]},{"title":"Binder通讯机制","slug":"Binder 进程间通讯机制","date":"2017-04-11T11:20:50.000Z","updated":"2018-05-24T03:48:32.000Z","comments":true,"path":"2017/04/11/Binder 进程间通讯机制/","link":"","permalink":"http://wenyiqingnian.xyz/2017/04/11/Binder 进程间通讯机制/","excerpt":"","text":"什么是Binder？Binder是Android系统中进程间通讯（IPC）的一种方式，也是Android系统中最重要的特性之一。Android中的四大组件Activity，Service，Broadcast，ContentProvider，不同的App等都运行在不同的进程中，它是这些进程间通讯的桥梁。正如其名“粘合剂”一样，它把系统中各个组件粘合到了一起，是各个组件的桥梁。 理解Binder对于理解整个Android系统有着非常重要的作用，如果对Binder不了解，就很难对Android系统机制有更深入的理解。 1. Binder架构 Binder 通信采用 C/S 架构，从组件视角来说，包含 Client、 Server、 ServiceManager 以及 Binder 驱动，其中 ServiceManager 用于管理系统中的各种服务。 Binder 在 framework 层进行了封装，通过 JNI 技术调用 Native（C/C++）层的 Binder 架构。 Binder 在 Native 层以 ioctl 的方式与 Binder 驱动通讯。 2.Binder机制 首先需要注册服务端，只有注册了服务端，客户端才有通讯的目标，服务端通过 ServiceManager 注册服务，注册的过程就是向 Binder 驱动的全局链表 binder_procs 中插入服务端的信息（binder_proc 结构体，每个 binder_proc 结构体中都有 todo 任务队列），然后向 ServiceManager 的 svcinfo 列表中缓存一下注册的服务。 有了服务端，客户端就可以跟服务端通讯了，通讯之前需要先获取到服务，拿到服务的代理，也可以理解为引用。比如下面的代码： 121//获取WindowManager服务引用2 WindowManager wm = (WindowManager)getSystemService(getApplication().WINDOW_SERVICE); 获取服务端的方式就是通过 ServiceManager 向 svcinfo 列表中查询一下返回服务端的代理，svcinfo 列表就是所有已注册服务的通讯录，保存了所有注册的服务信息。 有了服务端的引用我们就可以向服务端发送请求了，通过 BinderProxy 将我们的请求参数发送给 ServiceManager，通过共享内存的方式使用内核方法 copy_from_user() 将我们的参数先拷贝到内核空间，这时我们的客户端进入等待状态，然后 Binder 驱动向服务端的 todo 队列里面插入一条事务，执行完之后把执行结果通过 copy_to_user() 将内核的结果拷贝到用户空间（这里只是执行了拷贝命令，并没有拷贝数据，binder只进行一次拷贝），唤醒等待的客户端并把结果响应回来，这样就完成了一次通讯。 怎么样是不是很简单，以上就是 Binder 机制的主要通讯方式，下面我们来看看具体实现。 3.Binder驱动我们先来了解下用户空间与内核空间是怎么交互的。 先了解一些概念 用户空间/内核空间详细解释可以参考 Kernel Space Definition； 简单理解如下： Kernel space 是 Linux 内核的运行空间，User space 是用户程序的运行空间。 为了安全，它们是隔离的，即使用户的程序崩溃了，内核也不受影响。 Kernel space 可以执行任意命令，调用系统的一切资源； User space 只能执行简单的运算，不能直接调用系统资源，必须通过系统接口（又称 system call），才能向内核发出指令。 系统调用/内核态/用户态虽然从逻辑上抽离出用户空间和内核空间；但是不可避免的的是，总有那么一些用户空间需要访问内核的资源；比如应用程序访问文件，网络是很常见的事情，怎么办呢？ Kernel space can be accessed by user processes only through the use of system calls. 用户空间访问内核空间的唯一方式就是系统调用；通过这个统一入口接口，所有的资源访问都是在内核的控制下执行，以免导致对用户程序对系统资源的越权访问，从而保障了系统的安全和稳定。用户软件良莠不齐，要是它们乱搞把系统玩坏了怎么办？因此对于某些特权操作必须交给安全可靠的内核来执行。 当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）此时处理器处于特权级最高的（0级）内核代码中执行。当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。即此时处理器在特权级最低的（3级）用户代码中运行。处理器在特权等级高的时候才能执行那些特权CPU指令。 内核模块/驱动通过系统调用，用户空间可以访问内核空间，那么如果一个用户空间想与另外一个用户空间进行通信怎么办呢？很自然想到的是让操作系统内核添加支持；传统的 Linux 通信机制，比如 Socket，管道等都是内核支持的；但是 Binder 并不是 Linux 内核的一部分，它是怎么做到访问内核空间的呢？ Linux 的动态可加载内核模块（Loadable Kernel Module，LKM）机制解决了这个问题；模块是具有独立功能的程序，它可以被单独编译，但不能独立运行。它在运行时被链接到内核作为内核的一部分在内核空间运行。这样，Android系统可以通过添加一个内核模块运行在内核空间，用户进程之间的通过这个模块作为桥梁，就可以完成通信了。 在 Android 系统中，这个运行在内核空间的，负责各个用户进程通过 Binder 通信的内核模块叫做 Binder 驱动; 驱动程序一般指的是设备驱动程序（Device Driver），是一种可以使计算机和设备通信的特殊程序。相当于硬件的接口，操作系统只有通过这个接口，才能控制硬件设备的工作； 驱动就是操作硬件的接口，为了支持Binder通信过程，Binder 使用了一种“硬件”，因此这个模块被称之为驱动。 熟悉了上面这些概念，我们再来看下上面的图，用户空间中 binder_open(), binder_mmap(), binder_ioctl() 这些方法通过 system call 来调用内核空间 Binder 驱动中的方法。内核空间与用户空间共享内存通过 copy_from_user(), copy_to_user() 内核方法来完成用户空间与内核空间内存的数据传输。 Binder驱动中有一个全局的 binder_procs 链表保存了服务端的进程信息。 4. Binder 进程与线程 对于底层Binder驱动，通过 binder_procs 链表记录所有创建的 binder_proc 结构体，binder 驱动层的每一个 binder_proc 结构体都与用户空间的一个用于 binder 通信的进程一一对应，且每个进程有且只有一个 ProcessState 对象，这是通过单例模式来保证的。在每个进程中可以有很多个线程，每个线程对应一个 IPCThreadState 对象，IPCThreadState 对象也是单例模式，即一个线程对应一个 IPCThreadState 对象，在 Binder 驱动层也有与之相对应的结构，那就是 Binder_thread 结构体。在 binder_proc 结构体中通过成员变量 rb_root threads，来记录当前进程内所有的 binder_thread。 Binder 线程池：每个 Server 进程在启动时创建一个 binder 线程池，并向其中注册一个 Binder 线程；之后 Server 进程也可以向 binder 线程池注册新的线程，或者 Binder 驱动在探测到没有空闲 binder 线程时主动向 Server 进程注册新的的 binder 线程。对于一个 Server 进程有一个最大 Binder 线程数限制，默认为16个 binder 线程，例如 Android 的 system_server 进程就存在16个线程。对于所有 Client 端进程的 binder 请求都是交由 Server 端进程的 binder 线程来处理的。 5. ServiceManager 启动了解了 Binder 驱动，怎么与 Binder 驱动进行通讯呢？那就是通过 ServiceManager，好多文章称 ServiceManager 是 Binder 驱动的守护进程，大管家，其实 ServiceManager 的作用很简单就是提供了查询服务和注册服务的功能。下面我们来看一下 ServiceManager 启动的过程。 ServiceManager 分为 framework 层和 native 层，framework 层只是对 native 层进行了封装方便调用，图上展示的是 native 层的 ServiceManager 启动过程。 ServiceManager 的启动是系统在开机时，init 进程解析 init.rc 文件调用 service_manager.c 中的 main() 方法入口启动的。 native 层有一个 binder.c 封装了一些与 Binder 驱动交互的方法。 ServiceManager 的启动分为三步，首先打开驱动创建全局链表 binder_procs，然后将自己当前进程信息保存到 binder_procs 链表，最后开启 loop 不断的处理共享内存中的数据，并处理 BR_xxx 命令（ioctl 的命令，BR 可以理解为 binder reply 驱动处理完的响应）。 6. ServiceManager 注册服务 注册 MediaPlayerService 服务端，我们通过 ServiceManager 的 addService() 方法来注册服务。 首先 ServiceManager 向 Binder 驱动发送 BC_TRANSACTION 命令（ioctl 的命令，BC 可以理解为 binder client 客户端发过来的请求命令）携带 ADD_SERVICE_TRANSACTION 命令，同时注册服务的线程进入等待状态 waitForResponse()。 Binder 驱动收到请求命令向 ServiceManager 的 todo 队列里面添加一条注册服务的事务。事务的任务就是创建服务端进程 binder_node 信息并插入到 binder_procs 链表中。 事务处理完之后发送 BR_TRANSACTION 命令，ServiceManager 收到命令后向 svcinfo 列表中添加已经注册的服务。最后发送 BR_REPLY 命令唤醒等待的线程，通知注册成功。 7. ServiceManager 获取服务 获取服务的过程与注册类似，相反的过程。通过 ServiceManager 的 getService() 方法来注册服务。 首先 ServiceManager 向 Binder 驱动发送 BC_TRANSACTION 命令携带 CHECK_SERVICE_TRANSACTION 命令，同时获取服务的线程进入等待状态 waitForResponse()。 Binder 驱动收到请求命令向 ServiceManager 的发送 BC_TRANSACTION 查询已注册的服务，查询到直接响应 BR_REPLY 唤醒等待的线程。若查询不到将与 binder_procs 链表中的服务进行一次通讯再响应。 8. 进行一次完整通讯 我们在使用 Binder 时基本都是调用 framework 层封装好的方法，AIDL 就是 framework 层提供的傻瓜式是使用方式。假设服务已经注册完，我们来看看客户端怎么执行服务端的方法。 首先我们通过 ServiceManager 获取到服务端的 BinderProxy 代理对象，通过调用 BinderProxy 将参数，方法标识（例如：TRANSACTION_test，AIDL中自动生成）传给 ServiceManager，同时客户端线程进入等待状态。 ServiceManager 将用户空间的参数等请求数据复制到内核空间，并向服务端插入一条执行执行方法的事务。事务执行完通知 ServiceManager 将执行结果从内核空间复制到用户空间，并唤醒等待的线程，响应结果，通讯结束。 总结好了，这里只是从实现逻辑上简单介绍了下 Binder 机制的工作原理，想要深入理解 Binder 机制，还得自己下功夫，看源码，尽管这个过程很痛苦。一遍看不懂就再来一遍，说实话本人理解能力比较差，跟着博客思路看了不下十遍。努力总会有收获，好好欣赏 native 层各方法之间花式跳转的魅力吧。最后你将发现新世界的大门在向你敞开。 网上资料很多，个人觉得比较好的如下： Bander设计与实现 老罗的 Android进程间通信（IPC）机制Binder简要介绍和学习计划 系列 Innost的 深入理解Binder 系列 Gityuan的 Binder系列 (基于 Android 6.0)5. Binder学习指南","categories":[{"name":"Android","slug":"Android","permalink":"http://wenyiqingnian.xyz/categories/Android/"}],"tags":[{"name":"android","slug":"android","permalink":"http://wenyiqingnian.xyz/tags/android/"},{"name":"Binder","slug":"Binder","permalink":"http://wenyiqingnian.xyz/tags/Binder/"}]},{"title":"编译系统环境初始化过程","slug":"编译系统环境初始化过程","date":"2017-04-05T07:10:25.000Z","updated":"2018-05-06T14:15:45.000Z","comments":true,"path":"2017/04/05/编译系统环境初始化过程/","link":"","permalink":"http://wenyiqingnian.xyz/2017/04/05/编译系统环境初始化过程/","excerpt":"","text":"对Android编译环境进行初始化很简单，分为两步。 第一步是打开一个终端，并且将build/envsetup.sh加载到该终端中：123456789101112131415$ . ./build/envsetup.sh including device/asus/grouper/vendorsetup.sh including device/asus/tilapia/vendorsetup.sh including device/generic/armv7-a-neon/vendorsetup.sh including device/generic/armv7-a/vendorsetup.sh including device/generic/mips/vendorsetup.sh including device/generic/x86/vendorsetup.sh including device/lge/mako/vendorsetup.sh including device/samsung/maguro/vendorsetup.sh including device/samsung/manta/vendorsetup.sh including device/samsung/toroplus/vendorsetup.sh including device/samsung/toro/vendorsetup.sh including device/ti/panda/vendorsetup.sh including sdk/bash_completion/adb.bash 从命令的输出可以知道，文件build/envsetup.sh在加载的过程中，又会在device目录中寻找那些名称为vendorsetup.sh的文件，并且也将它们加载到当前终端来。另外，在sdk/bash_completion目录下的adb.bash文件也会加载到当前终端来，它是用来实现adb命令的bash completion功能的。也就是说，加载了该文件之后，我们在运行adb相关的命令的时候，通过按tab键就可以帮助我们自动完成命令的输入。关于bash completion的知识，可以参考官方文档： http://www.gnu.org/s/bash/manual/bash.html#Programmable-Completion。 第二步是执行命令lunch，如下所示：1234567891011121314151617181920212223$ lunch You're building on Linux Lunch menu... pick a combo: 1. full-eng 2. full_x86-eng 3. vbox_x86-eng 4. full_mips-eng 5. full_grouper-userdebug 6. full_tilapia-userdebug 7. mini_armv7a_neon-userdebug 8. mini_armv7a-userdebug 9. mini_mips-userdebug 10. mini_x86-userdebug 11. full_mako-userdebug 12. full_maguro-userdebug 13. full_manta-userdebug 14. full_toroplus-userdebug 15. full_toro-userdebug 16. full_panda-userdebug Which would you like? [full-eng] 我们看到lunch命令输出了一个Lunch菜单，该菜单列出了当前Android源码支持的所有设备型号及其编译类型。例如，第一项“full-eng”表示的设备“full”即为模拟器，并且编译类型为“eng”即为工程机。当我们选定了一个Lunch菜单项序号(1-16)之后，按回车键，就可以完成Android编译环境的初始化过程。例如，我们选择1，可以看到以下输出： 12345678910111213141516171819[html] view plain copyWhich would you like? [full-eng] 1 ============================================ PLATFORM_VERSION_CODENAME=REL PLATFORM_VERSION=4.2 TARGET_PRODUCT=full TARGET_BUILD_VARIANT=eng TARGET_BUILD_TYPE=release TARGET_BUILD_APPS= TARGET_ARCH=arm TARGET_ARCH_VARIANT=armv7-a HOST_ARCH=x86 HOST_OS=linux HOST_OS_EXTRA=Linux-3.8.0-31-generic-x86_64-with-Ubuntu-13.04-raring HOST_BUILD_TYPE=release BUILD_ID=JOP40C OUT_DIR=out ============================================ 我们可以看到，lunch命令帮我们设置好了很多环境变量。通过设置这些环境变量，就配置好了Android编译环境。通过图1我们就可以直观地看到Android编译环境初始化完成后，我们所获得的东西： 图1 Android编译环境初始化完成之后 总体来说，Android编译环境初始化完成之后，获得了以下三样东西： 123451. 将vendor和device目录下的vendorsetup.sh文件加载到了当前终端；2. 新增了lunch、m、mm和mmm等命令；3. 通过执行lunch命令设置好了TARGET_PRODUCT、TARGET_BUILD_VARIANT、TARGET_BUILD_TYPE和TARGET_BUILD_APPS等环境变量。 接下来我们就主要分析build/envsetup.sh文件的加载过程以及lunch命令的执行过程。 一. 文件build/envsetup.sh的加载过程文件build/envsetup.sh是一个bash shell脚本，从它里面定义的函数hmm可以知道，它提供了lunch、m、mm和mmm等命令供我们初始化编译环境或者编译Android源码。 函数hmm的实现如下所示： 12345678910111213141516171819202122232425[plain] view plain copyfunction hmm() &#123; cat &lt;&lt;EOF Invoke &quot;. build/envsetup.sh&quot; from your shell to add the following functions to your environment: - lunch: lunch &lt;product_name&gt;-&lt;build_variant&gt; - tapas: tapas [&lt;App1&gt; &lt;App2&gt; ...] [arm|x86|mips] [eng|userdebug|user] - croot: Changes directory to the top of the tree. - m: Makes from the top of the tree. - mm: Builds all of the modules in the current directory. - mmm: Builds all of the modules in the supplied directories. - cgrep: Greps on all local C/C++ files. - jgrep: Greps on all local Java files. - resgrep: Greps on all local res/*.xml files. - godir: Go to the directory containing a file. Look at the source to view more functions. The complete list is: EOF T=$(gettop) local A A=&quot;&quot; for i in `cat $T/build/envsetup.sh | sed -n &quot;/^function /s/function [a−z]∗.*/\\1/p&quot; | sort`; do A=&quot;$A $i&quot; done echo $A &#125; 我们在当前终端中执行hmm命令即可以看到函数hmm的完整输出。函数hmm主要完成三个工作： 12345671. 调用另外一个函数gettop获得Android源码的根目录T。 2. 通过cat命令显示一个Here Document，说明$T/build/envsetup.sh文件加载到当前终端后所提供的主要命令。3. 通过sed命令解析$T/build/envsetup.sh文件，并且获得在里面定义的所有函数的名称，这些函数名称就是$T/build/envsetup.sh文件加载到当前终端后提供的所有命令。 注意，sed命令是一个强大的文本分析工具，它以行为单位为执行文本替换、删除、新增和选取等操作。函数hmm通过执行以下的sed命令来获得在$T/build/envsetup.sh文件定义的函数的名称： [plain] view plain copysed -n “/^function /s/function [a−z]∗.*/\\1/p” 它表示对所有以“function ”开头的行，如果紧接在“function ”后面的字符串仅由字母a-z和下横线(_)组成，那么就将这个字符串提取出来。这正好就对应于shell脚本里面函数的定义。 文件build/envsetup.sh除了定义一堆函数之外，还有一个重要的代码段，如下所示： 12345678[plain] view plain copy# Execute the contents of any vendorsetup.sh files we can find. for f in `/bin/ls vendor/*/vendorsetup.sh vendor/*/*/vendorsetup.sh device/*/*/vendorsetup.sh 2&gt; /dev/null` do echo &quot;including $f&quot; . $f done unset f 这个for循环遍历vendor目录下的一级子目录和二级子目录以及device目录下的二级子目录中的vendorsetup.sh文件，并且通过source命令(.)将它们加载当前终端来。vendor和device相应子目录下的vendorsetup.sh文件的实现很简单，它们主要就是添加相应的设备型号及其编译类型支持到Lunch菜单中去。 例如，device/samsung/maguro目录下的vendorsetup.sh文件的实现如下所示： 12[plain] view plain copyadd_lunch_combo full_maguro-userdebug 它调用函数add_lunch_combo添加一个名称为“full_maguro-userdebug”的菜单项到Lunch菜单去。函数add_lunch_combo定义在build/envsetup.sh文件中，它的实现如下所示： 123456789101112[plain] view plain copyfunction add_lunch_combo() &#123; local new_combo=$1 local c for c in $&#123;LUNCH_MENU_CHOICES[@]&#125; ; do if [ &quot;$new_combo&quot; = &quot;$c&quot; ] ; then return fi done LUNCH_MENU_CHOICES=($&#123;LUNCH_MENU_CHOICES[@]&#125; $new_combo) &#125; 传递给函数add_lunch_combo的参数保存在位置参数$1中，接着又保存在一个本地变量new_combo中，用来表示一个要即将要添加的Lunch菜单项。函数首先是在数组LUNCH_MENU_CHOICES中检查要添加的菜单项是否已经存在。只有在不存在的情况下，才会将它添加到数组LUNCH_MENU_CHOICES中去。注意，${LUNCH_MENU_CHOICES[@]}表示数组LUNCH_MENU_CHOICES的所有元素。数组LUNCH_MENU_CHOICES是定义在文件build/envsetup.sh的一个全局变量，当文件build/envsetup.sh被加载的时候，这个数组会被初始化为化full-eng、full_x86-eng、vbox_x86-eng和full_mips-eng，如下所示： 123456[plain] view plain copy# add the default one here add_lunch_combo full-eng add_lunch_combo full_x86-eng add_lunch_combo vbox_x86-eng add_lunch_combo full_mips-eng 这样当文件build/envsetup.sh加载完成之后，数组LUNCH_MENU_CHOICES就包含了当前源码支持的所有设备型号及其编译类型，于是当接下来我们执行lunch命令的时候，就可以通过数组LUNCH_MENU_CHOICES看到一个完整的Lunch藤蔓。 二. lunch命令的执行过程lunch命令实际上是定义在文件build/envsetup.sh的一个函数，它的实现如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273[plain] view plain copyfunction lunch() &#123; local answer if [ &quot;$1&quot; ] ; then answer=$1 else print_lunch_menu echo -n &quot;Which would you like? [full-eng] &quot; read answer fi local selection= if [ -z &quot;$answer&quot; ] then selection=full-eng elif (echo -n $answer | grep -q -e &quot;^[0-9][0-9]*$&quot;) then if [ $answer -le $&#123;#LUNCH_MENU_CHOICES[@]&#125; ] then selection=$&#123;LUNCH_MENU_CHOICES[$(($answer-1))]&#125; fi elif (echo -n $answer | grep -q -e &quot;^[^\\-][^\\-]*-[^\\-][^\\-]*$&quot;) then selection=$answer fi if [ -z &quot;$selection&quot; ] then echo echo &quot;Invalid lunch combo: $answer&quot; return 1 fi export TARGET_BUILD_APPS= local product=$(echo -n $selection | sed -e &quot;s/-.*$//&quot;) check_product $product if [ $? -ne 0 ] then echo echo &quot;** Don&apos;t have a product spec for: &apos;$product&apos;&quot; echo &quot;** Do you have the right repo manifest?&quot; product= fi local variant=$(echo -n $selection | sed -e &quot;s/^[^\\-]*-//&quot;) check_variant $variant if [ $? -ne 0 ] then echo echo &quot;** Invalid variant: &apos;$variant&apos;&quot; echo &quot;** Must be one of $&#123;VARIANT_CHOICES[@]&#125;&quot; variant= fi if [ -z &quot;$product&quot; -o -z &quot;$variant&quot; ] then echo return 1 fi export TARGET_PRODUCT=$product export TARGET_BUILD_VARIANT=$variant export TARGET_BUILD_TYPE=release echo set_stuff_for_environment printconfig &#125; 函数lunch的执行逻辑如下所示： 12345678910111. 检查是否带有参数，即位置参数$1是否等于空。如果不等于空的话，就表明带有参数，并且该参数是用来指定要编译的设备型号及其编译类型的。如果等于空的话，那么就调用另外一个函数print_lunch_menu来显示Lunch菜单项，并且通过调用read函数来等待用户输入。无论通过何种方式，最终变量answer的值就保存了用户所指定的备型号及其编译类型。 2. 对变量answer的值的合法性进行检查。如果等于空的话，就将它设置为默认值“full-eng”。如果不等于空的话，就分为三种情况考虑。第一种情况是值为数字，那么就需要确保该数字的大小不能超过Lunch菜单项的个数。在这种情况下，会将输入的数字索引到数组LUNCH_MENU_CHOICES中去，以便获得一个用来表示设备型号及其编译类型的文本。第二种情况是非数字文本，那么就需要确保该文本符合&lt;product&gt;-&lt;variant&gt;的形式，其中&lt;product&gt;表示设备型号，而&lt;variant&gt;表示编译类型 。第三种情况是除了前面两种情况之外的所有情况，这是非法的。经过合法性检查后，变量selection代表了用户所指定的备型号及其编译类型，如果它的值是非法的，即它的值等于空，那么函数lunch就不往下执行了。 3. 接下来是解析变量selection的值，也就是通过sed命令将它的&lt;product&gt;和&lt;variant&gt;值提取出来，并且分别保存在变量product和variant中。提取出来的product和variant值有可能是不合法的，因此需要进一步通过调用函数check_product和check_variant来检查。一旦检查失败，也就是函数check_product和check_variant的返回值$?等于非0，那么函数lunch就不往下执行了。 4. 通过以上合法性检查之后，就将变量product和variant的值保存在环境变量TARGET_PRODUCT和TARGET_BUILD_VARIANT中。此外，另外一个环境变量TARGET_BUILD_TYPE的值会被设置为&quot;release&quot;，表示此次编译是一个release版本的编译。另外，前面还有一个环境变量TARGET_BUILD_APPS，它的值被函数lunch设置为空，用来表示此次编译是对整个系统进行编译。如果环境变量TARGET_BUILD_APPS的值不等于空，那么就表示此次编译是只对某些APP模块进行编译，而这些APP模块就是由环境变量TARGET_BUILD_APPS来指定的。 5. 调用函数set_stuff_for_environment来配置环境，例如设置Java SDK路径和交叉编译工具路径等。 6. 调用函数printfconfig来显示已经配置好的编译环境参数。 在上述执行过程中，函数check_product、check_variant和printconfig是比较关键的，因此接下来我们就继续分析它们的实现。 函数check_product定义在文件build/envsetup.sh中，它的实现如下所示： 1234567891011121314151617[plain] view plain copy# check to see if the supplied product is one we can build function check_product() &#123; T=$(gettop) if [ ! &quot;$T&quot; ]; then echo &quot;Couldn&apos;t locate the top of the tree. Try setting TOP.&quot; &gt;&amp;2 return fi CALLED_FROM_SETUP=true BUILD_SYSTEM=build/core \\ TARGET_PRODUCT=$1 \\ TARGET_BUILD_VARIANT= \\ TARGET_BUILD_TYPE= \\ TARGET_BUILD_APPS= \\ get_build_var TARGET_DEVICE &gt; /dev/null # hide successful answers, but allow the errors to show &#125; 函数gettop用来返回Android源代码工程的根目录。函数check_product需要在Android源代码工程根目录或者子目录下调用。否则的话，函数check_product就出错返回。 接下来函数check_product设置几个环境变量，其中最重要的是前面三个CALLED_FROM_SETUP、BUILD_SYSTEM和TARGET_PRODUCT。环境变量CALLED_FROM_SETUP的值等于true表示接下来执行的make命令是用来初始化Android编译环境的。环境变量BUILD_SYSTEM用来指定Android编译系统的核心目录，它的值被设置为build/core。环境变量TARGET_PRODUCT用来表示要检查的产品名称（也就是我们前面说的设备型号），它的值被设置为$1，即函数check_product的调用参数。 最后函数check_product调用函数get_build_var来检查由环境变量TARGET_PRODUCT指定的产品名称是否合法，注意，它的调用参数为TARGET_DEVICE。 函数get_build_var定义在文件build/envsetup.sh中，它的实现如下所示： 123456789101112[plain] view plain copy# Get the exact value of a build variable. function get_build_var() &#123; T=$(gettop) if [ ! &quot;$T&quot; ]; then echo &quot;Couldn&apos;t locate the top of the tree. Try setting TOP.&quot; &gt;&amp;2 return fi CALLED_FROM_SETUP=true BUILD_SYSTEM=build/core \\ make --no-print-directory -C &quot;$T&quot; -f build/core/config.mk dumpvar-$1 &#125; 这里就可以看到，函数get_build_var实际上就是通过make命令在Android源代码工程根目录中执行build/core/config.mk文件，并且将make目标设置为dumpvar-$1，也就是dumpvar-TARGET_DEVICE。 文件build/core/config.mk的内容比较多，这里我们只关注与产品名称合法性检查相关的逻辑，这些逻辑也基本上涵盖了Android编译系统初始化的逻辑，如下所示： 12345678910111213141516171819202122232425262728[plain] view plain copy...... # --------------------------------------------------------------- # Define most of the global variables. These are the ones that # are specific to the user&apos;s build configuration. include $(BUILD_SYSTEM)/envsetup.mk # Boards may be defined under $(SRC_TARGET_DIR)/board/$(TARGET_DEVICE) # or under vendor/*/$(TARGET_DEVICE). Search in both places, but # make sure only one exists. # Real boards should always be associated with an OEM vendor. board_config_mk := \\ $(strip $(wildcard \\ $(SRC_TARGET_DIR)/board/$(TARGET_DEVICE)/BoardConfig.mk \\ device/*/$(TARGET_DEVICE)/BoardConfig.mk \\ vendor/*/$(TARGET_DEVICE)/BoardConfig.mk \\ )) ifeq ($(board_config_mk),) $(error No config file found for TARGET_DEVICE $(TARGET_DEVICE)) endif ifneq ($(words $(board_config_mk)),1) $(error Multiple board config files for TARGET_DEVICE $(TARGET_DEVICE): $(board_config_mk)) endif include $(board_config_mk) ......include $(BUILD_SYSTEM)/dumpvar.mk 上述代码主要就是将envsetup.mk、BoardConfig,mk和dumpvar.mk三个Makefile片段文件加载进来。其中，envsetup.mk文件位于$(BUILD_SYSTEM)目录中，也就是build/core目录中，BoardConfig.mk文件的位置主要就是由环境变量TARGET_DEVICE来确定，它是用来描述目标产品的硬件模块信息的，例如CPU体系结构。环境变量TARGET_DEVICE用来描述目标设备，它的值是在envsetup.mk文件加载的过程中确定的。一旦目标设备确定后，就可以在$(SRC_TARGET_DIR)/board/$(TARGET_DEVICE)、device//$(TARGET_DEVICE)和vendor//$(TARGET_DEVICE)目录中找到对应的BoradConfig.mk文件。注意，变量SRC_TARGET_DIR的值等于build/target。最后，dumpvar.mk文件也是位于build/core目录中，它用来打印已经配置好的编译环境信息。 接下来我们就通过进入到build/core/envsetup.mk文件来分析变量TARGET_DEVICE的值是如何确定的： [plain] view plain copy Read the product specs so we an get TARGET_DEVICE and othervariables that we need in order to locate the output files.include $(BUILD_SYSTEM)/product_config.mk 它通过加载另外一个文件build/core/product_config.mk文件来确定变量TARGET_DEVICE以及其它与目标产品相关的变量的值。 文件build/core/product_config.mk的内容很多，这里我们只关注变量TARGET_DEVICE设置相关的逻辑，如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667[plain] view plain copy...... ifneq ($(strip $(TARGET_BUILD_APPS)),) # An unbundled app build needs only the core product makefiles. all_product_configs := $(call get-product-makefiles,\\ $(SRC_TARGET_DIR)/product/AndroidProducts.mk) else # Read in all of the product definitions specified by the AndroidProducts.mk # files in the tree. all_product_configs := $(get-all-product-makefiles) endif # all_product_configs consists items like: # &lt;product_name&gt;:&lt;path_to_the_product_makefile&gt; # or just &lt;path_to_the_product_makefile&gt; in case the product name is the # same as the base filename of the product config makefile. current_product_makefile := all_product_makefiles := $(foreach f, $(all_product_configs),\\ $(eval _cpm_words := $(subst :,$(space),$(f)))\\ $(eval _cpm_word1 := $(word 1,$(_cpm_words)))\\ $(eval _cpm_word2 := $(word 2,$(_cpm_words)))\\ $(if $(_cpm_word2),\\ $(eval all_product_makefiles += $(_cpm_word2))\\ $(if $(filter $(TARGET_PRODUCT),$(_cpm_word1)),\\ $(eval current_product_makefile += $(_cpm_word2)),),\\ $(eval all_product_makefiles += $(f))\\ $(if $(filter $(TARGET_PRODUCT),$(basename $(notdir $(f)))),\\ $(eval current_product_makefile += $(f)),))) _cpm_words := _cpm_word1 := _cpm_word2 := current_product_makefile := $(strip $(current_product_makefile)) all_product_makefiles := $(strip $(all_product_makefiles)) ifneq (,$(filter product-graph dump-products, $(MAKECMDGOALS))) # Import all product makefiles. $(call import-products, $(all_product_makefiles)) else # Import just the current product. ifndef current_product_makefile $(error Cannot locate config makefile for product &quot;$(TARGET_PRODUCT)&quot;) endif ifneq (1,$(words $(current_product_makefile))) $(error Product &quot;$(TARGET_PRODUCT)&quot; ambiguous: matches $(current_product_makefile)) endif $(call import-products, $(current_product_makefile)) endif # Import all or just the current product makefile ...... # Convert a short name like &quot;sooner&quot; into the path to the product # file defining that product. # INTERNAL_PRODUCT := $(call resolve-short-product-name, $(TARGET_PRODUCT)) ifneq ($(current_product_makefile),$(INTERNAL_PRODUCT)) $(error PRODUCT_NAME inconsistent in $(current_product_makefile) and $(INTERNAL_PRODUCT)) endif current_product_makefile := all_product_makefiles := all_product_configs := # Find the device that this product maps to. TARGET_DEVICE := $(PRODUCTS.$(INTERNAL_PRODUCT).PRODUCT_DEVICE) ...... 上述代码的执行逻辑如下所示： 1234567891. 检查环境变量TARGET_BUILD_APPS的值是否等于空。如果不等于空，那么就说明此次编译不是针对整个系统，因此只要将核心的产品相关的Makefile文件加载进来就行了，否则的话，就要将所有与产品相关的Makefile文件加载进来的。核心产品Makefile文件在$(SRC_TARGET_DIR)/product/AndroidProducts.mk文件中指定，也就是在build/target/product/AndroidProducts.mk文件，通过调用函数get-product-makefiles可以获得。所有与产品相关的Makefile文件可以通过另外一个函数get-all-product-makefiles获得。无论如何，最终获得的产品Makefie文件列表保存在变量all_product_configs中。 2. 遍历变量all_product_configs所描述的产品Makefile列表，并且在这些Makefile文件中，找到名称与环境变量TARGET_PRODUCT的值相同的文件，保存在另外一个变量current_product_makefile中，作为需要为当前指定的产品所加载的Makefile文件列表。在这个过程当中，上一步找到的所有的产品Makefile文件也会保存在变量all_product_makefiles中。注意，环境变量TARGET_PRODUCT的值是在我们执行lunch命令的时候设置并且传递进来的。 3. 如果指定的make目标等于product-graph或者dump-products，那么就将所有的产品相关的Makefile文件加载进来，否则的话，只加载与目标产品相关的Makefile文件。从前面的分析可以知道，此时的make目标为dumpvar-TARGET_DEVICE，因此接下来只会加载与目标产品，即$(TARGET_PRODUCT)，相关的Makefile文件，这是通过调用另外一个函数import-products实现的。 4. 调用函数resolve-short-product-name解析环境变量TARGET_PRODUCT的值，将它变成一个Makefile文件路径。并且保存在变量INTERNAL_PRODUCT中。这里要求变量INTERNAL_PRODUCT和current_product_makefile的值相等，否则的话，就说明用户指定了一个非法的产品名称。 5. 找到一个名称为PRODUCTS.$(INTERNAL_PRODUCT).PRODUCT_DEVICE的变量，并且将它的值保存另外一个变量TARGET_DEVICE中。变量PRODUCTS.$(INTERNAL_PRODUCT).PRODUCT_DEVICE是在加载产品Makefile文件的过程中定义的，用来描述当前指定的产品的名称。 上述过程主要涉及到了get-all-product-makefiles、import-products和resolve-short-product-name三个关键函数，理解它们的执行过程对理解Android编译系统的初始化过程很有帮助，接下来我们分别分析它们的实现。 函数get-all-product-makefiles定义在文件build/core/product.mk中，如下所示： 123456789[plain] view plain copy# # Returns the sorted concatenation of all PRODUCT_MAKEFILES # variables set in all AndroidProducts.mk files. # $(call ) isn&apos;t necessary. # define get-all-product-makefiles $(call get-product-makefiles,$(_find-android-products-files)) endef 它首先是调用函数_find-android-products-files来找到Android源代码目录中定义的所有AndroidProducts.mk文件，然后再调用函数get-product-makefiles获得在这里AndroidProducts.mk文件里面定义的产品Makefile文件。 函数_find-android-products-files也是定义在文件build/core/product.mk中，如下所示： 12345678910111213141516171819202122232425262728293031[plain] view plain copy# # Returns the list of all AndroidProducts.mk files. # $(call ) isn&apos;t necessary. # define _find-android-products-files $(shell test -d device &amp;&amp; find device -maxdepth 6 -name AndroidProducts.mk) \\ $(shell test -d vendor &amp;&amp; find vendor -maxdepth 6 -name AndroidProducts.mk) \\ $(SRC_TARGET_DIR)/product/AndroidProducts.mk endef 从这里就可以看出，Android源代码目录中定义的所有AndroidProducts.mk文件位于device、vendor或者build/target/product目录或者相应的子目录（最深是6层）中。 函数get-product-makefiles也是定义在文件build/core/product.mk中，如下所示：[plain] view plain copy# # Returns the sorted concatenation of PRODUCT_MAKEFILES # variables set in the given AndroidProducts.mk files. # $(1): the list of AndroidProducts.mk files. # define get-product-makefiles $(sort \\ $(foreach f,$(1), \\ $(eval PRODUCT_MAKEFILES :=) \\ $(eval LOCAL_DIR := $(patsubst %/,%,$(dir $(f)))) \\ $(eval include $(f)) \\ $(PRODUCT_MAKEFILES) \\ ) \\ $(eval PRODUCT_MAKEFILES :=) \\ $(eval LOCAL_DIR :=) \\ ) endef 这个函数实际上就是遍历参数$1所描述的AndroidProucts.mk文件列表，并且将定义在这些AndroidProucts.mk文件中的变量PRODUCT_MAKEFILES的值提取出来，形成一个列表返回给调用者。 例如，在build/target/product/AndroidProducts.mk文件中，变量PRODUCT_MAKEFILES的值如下所示： 12345678910111213141516171819202122[plain] view plain copy# Unbundled apps will be built with the most generic product config. ifneq ($(TARGET_BUILD_APPS),) PRODUCT_MAKEFILES := \\ $(LOCAL_DIR)/full.mk \\ $(LOCAL_DIR)/full_x86.mk \\ $(LOCAL_DIR)/full_mips.mk else PRODUCT_MAKEFILES := \\ $(LOCAL_DIR)/core.mk \\ $(LOCAL_DIR)/generic.mk \\ $(LOCAL_DIR)/generic_x86.mk \\ $(LOCAL_DIR)/generic_mips.mk \\ $(LOCAL_DIR)/full.mk \\ $(LOCAL_DIR)/full_x86.mk \\ $(LOCAL_DIR)/full_mips.mk \\ $(LOCAL_DIR)/vbox_x86.mk \\ $(LOCAL_DIR)/sdk.mk \\ $(LOCAL_DIR)/sdk_x86.mk \\ $(LOCAL_DIR)/sdk_mips.mk \\ $(LOCAL_DIR)/large_emu_hw.mk endif 里列出的每一个文件都对应于一个产品。 我们再来看函数import-products的实现，它定义在文件build/core/product.mk中，如下所示： 12345678[plain] view plain copy# # $(1): product makefile list # #TODO: check to make sure that products have all the necessary vars defined define import-products $(call import-nodes,PRODUCTS,$(1),$(_product_var_list)) endef 它调用另外一个函数import-nodes来加载由参数$1所指定的产品Makefile文件，并且指定了另外两个参数PRODUCTS和$(_product_var_list)。其中，变量_product_var_list也是定义在文件build/core/product.mk中，它的值如下所示： 123456789101112131415161718192021222324252627282930313233[plain] view plain copy_product_var_list := \\ PRODUCT_NAME \\ PRODUCT_MODEL \\ PRODUCT_LOCALES \\ PRODUCT_AAPT_CONFIG \\ PRODUCT_AAPT_PREF_CONFIG \\ PRODUCT_PACKAGES \\ PRODUCT_PACKAGES_DEBUG \\ PRODUCT_PACKAGES_ENG \\ PRODUCT_PACKAGES_TESTS \\ PRODUCT_DEVICE \\ PRODUCT_MANUFACTURER \\ PRODUCT_BRAND \\ PRODUCT_PROPERTY_OVERRIDES \\ PRODUCT_DEFAULT_PROPERTY_OVERRIDES \\ PRODUCT_CHARACTERISTICS \\ PRODUCT_COPY_FILES \\ PRODUCT_OTA_PUBLIC_KEYS \\ PRODUCT_EXTRA_RECOVERY_KEYS \\ PRODUCT_PACKAGE_OVERLAYS \\ DEVICE_PACKAGE_OVERLAYS \\ PRODUCT_TAGS \\ PRODUCT_SDK_ADDON_NAME \\ PRODUCT_SDK_ADDON_COPY_FILES \\ PRODUCT_SDK_ADDON_COPY_MODULES \\ PRODUCT_SDK_ADDON_DOC_MODULES \\ PRODUCT_DEFAULT_WIFI_CHANNELS \\ PRODUCT_DEFAULT_DEV_CERTIFICATE \\ PRODUCT_RESTRICT_VENDOR_FILES \\ PRODUCT_VENDOR_KERNEL_HEADERS \\ PRODUCT_FACTORY_RAMDISK_MODULES \\ PRODUCT_FACTORY_BUNDLE_MODULES 它描述的是在产品Makefile文件中定义在各种变量。 函数import-nodes定义在文件build/core/node_fns.mk中，如下所示： 12345678910111213141516171819202122[plain] view plain copy# # $(1): output list variable name, like &quot;PRODUCTS&quot; or &quot;DEVICES&quot; # $(2): list of makefiles representing nodes to import # $(3): list of node variable names # define import-nodes $(if \\ $(foreach _in,$(2), \\ $(eval _node_import_context := _nic.$(1).[[$(_in)]]) \\ $(if $(_include_stack),$(eval $(error ASSERTION FAILED: _include_stack \\ should be empty here: $(_include_stack))),) \\ $(eval _include_stack := ) \\ $(call _import-nodes-inner,$(_node_import_context),$(_in),$(3)) \\ $(call move-var-list,$(_node_import_context).$(_in),$(1).$(_in),$(3)) \\ $(eval _node_import_context :=) \\ $(eval $(1) := $($(1)) $(_in)) \\ $(if $(_include_stack),$(eval $(error ASSERTION FAILED: _include_stack \\ should be empty here: $(_include_stack))),) \\ ) \\ ,) endef 这个函数主要是做了三件事情： 12345671. 调用函数_import-nodes-inner将参数$2描述的每一个产品Makefile文件加载进来。 2. 调用函数move-var-list将定义在前面所加载的产品Makefile文件里面的由参数$3指定的变量的值分别拷贝到另外一组独立的变量中。 3. 将参数$2描述的每一个产品Makefile文件路径以空格分隔保存在参数$1所描述的变量中，也就是保存在变量PRODUCTS中。 上述第二件事情需要进一步解释一下。由于当前加载的每一个文件都会定义相同的变量，为了区分这些变量，我们需要在这些变量前面加一些前缀。例如，假设加载了build/target/product/full.mk这个产品Makefile文件，它里面定义了以下几个变量： 123456789101112[plain] view plain copy# Overrides PRODUCT_NAME := full PRODUCT_DEVICE := generic PRODUCT_BRAND := Android PRODUCT_MODEL := Full Android on Emulator 当调用了函数move-var-list对它进行解析后，就会得到以下的新变量：[plain] view plain copyPRODUCTS.build/target/product/full.mk.PRODUCT_NAME := full PRODUCTS.build/target/product/full.mk.PRODUCT_DEVICE := generic PRODUCTS.build/target/product/full.mk.PRODUCT_BRAND := Android PRODUCTS.build/target/product/full.mk.PRODUCT_MODEL := Full Android on Emulator 正是由于调用了函数move-var-list，我们在build/core/product_config.mk文件中可以通过PRODUCTS.$(INTERNAL_PRODUCT).PRODUCT_DEVICE来设置变量TARGET_DEVICE的值。 回到build/core/config.mk文件中，接下来我们再看BoardConfig.mk文件的加载过程。前面提到，当前要加载的BoardConfig.mk文件由变量TARGET_DEVICE来确定。例如，假设我们在运行lunch命令时，输入的文本为full-eng，那么build/target/product/full.mk就会被加载，并且我们得到TARGET_DEVICE的值就为generic，接下来加载的BoradConfig.mk文件就会在build/target/board/generic目录中找到。 BoardConfig.mk文件定义的信息可以参考build/target/board/generic/BoardConfig.mk文件的内容，如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[plain] view plain copy# config.mk # # Product-specific compile-time definitions. # # The generic product target doesn&apos;t have any hardware-specific pieces. TARGET_NO_BOOTLOADER := true TARGET_NO_KERNEL := true TARGET_ARCH := arm # Note: we build the platform images for ARMv7-A _without_ NEON. # # Technically, the emulator supports ARMv7-A _and_ NEON instructions, but # emulated NEON code paths typically ends up 2x slower than the normal C code # it is supposed to replace (unlike on real devices where it is 2x to 3x # faster). # # What this means is that the platform image will not use NEON code paths # that are slower to emulate. On the other hand, it is possible to emulate # application code generated with the NDK that uses NEON in the emulator. # TARGET_ARCH_VARIANT := armv7-a TARGET_CPU_ABI := armeabi-v7a TARGET_CPU_ABI2 := armeabi ARCH_ARM_HAVE_TLS_REGISTER := true HAVE_HTC_AUDIO_DRIVER := true BOARD_USES_GENERIC_AUDIO := true # no hardware camera USE_CAMERA_STUB := true # Enable dex-preoptimization to speed up the first boot sequence # of an SDK AVD. Note that this operation only works on Linux for now ifeq ($(HOST_OS),linux) ifeq ($(WITH_DEXPREOPT),) WITH_DEXPREOPT := true endif endif # Build OpenGLES emulation guest and host libraries BUILD_EMULATOR_OPENGL := true # Build and enable the OpenGL ES View renderer. When running on the emulator, # the GLES renderer disables itself if host GL acceleration isn&apos;t available. USE_OPENGL_RENDERER := true 它描述了产品的Boot Loader、Kernel、CPU体系结构、CPU ABI和Opengl加速等信息。 再回到build/core/config.mk文件中，它最后加载build/core/dumpvar.mk文件。加载build/core/dumpvar.mk文件是为了生成make目标，以便可以对这些目标进行操作。例如，在我们这个情景中，我们要执行的make目标是dumpvar-TARGET_DEVICE，因此在加载build/core/dumpvar.mk文件的过程中，就会生成dumpvar-TARGET_DEVICE目标。 文件build/core/dumpvar.mk的内容也比较多，这里我们只关注生成make目标相关的逻辑： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546[plain] view plain copy...... # The &quot;dumpvar&quot; stuff lets you say something like # # CALLED_FROM_SETUP=true \\ # make -f config/envsetup.make dumpvar-TARGET_OUT # or # CALLED_FROM_SETUP=true \\ # make -f config/envsetup.make dumpvar-abs-HOST_OUT_EXECUTABLES # # The plain (non-abs) version just dumps the value of the named variable. # The &quot;abs&quot; version will treat the variable as a path, and dumps an # absolute path to it. # dumpvar_goals := \\ $(strip $(patsubst dumpvar-%,%,$(filter dumpvar-%,$(MAKECMDGOALS)))) ifdef dumpvar_goals ifneq ($(words $(dumpvar_goals)),1) $(error Only one &quot;dumpvar-&quot; goal allowed. Saw &quot;$(MAKECMDGOALS)&quot;) endif # If the goal is of the form &quot;dumpvar-abs-VARNAME&quot;, then # treat VARNAME as a path and return the absolute path to it. absolute_dumpvar := $(strip $(filter abs-%,$(dumpvar_goals))) ifdef absolute_dumpvar dumpvar_goals := $(patsubst abs-%,%,$(dumpvar_goals)) ifneq ($(filter /%,$($(dumpvar_goals))),) DUMPVAR_VALUE := $($(dumpvar_goals)) else DUMPVAR_VALUE := $(PWD)/$($(dumpvar_goals)) endif dumpvar_target := dumpvar-abs-$(dumpvar_goals) else DUMPVAR_VALUE := $($(dumpvar_goals)) dumpvar_target := dumpvar-$(dumpvar_goals) endif .PHONY: $(dumpvar_target) $(dumpvar_target): @echo $(DUMPVAR_VALUE) endif # dumpvar_goals ...... 我们在执行make命令时，指定的目示会经由MAKECMDGOALS变量传递到Makefile中，因此通过变量MAKECMDGOALS可以获得make目标。 上述代码的逻辑很简单，例如，在我们这个情景中，指定的make目标为dumpvar-TARGET_DEVICE，那么就会得到变量DUMPVAR_VALUE的值为$(TARGET_DEVICE)。TARGET_DEVICE的值在前面已经被设置为“generic”，因此变量DUMPVAR_VALUE的值就等于“generic”。此外，变量dumpvar_target的被设置为“dumpvar-TARGET_DEVICE”。最后我们就可以得到以下的make规则： [plain] view plain copy.PHONY dumpvar-TARGET_DEVICEdumpvar-TARGET_DEVICE: @echo generic 至此，在build/envsetup.sh文件中定义的函数check_product就分析完成了。看完了之后，小伙伴们可能会问，前面不是说这个函数是用来检查用户输入的产品名称是否合法的吗？但是这里没看出哪一段代码给出了true或者false的答案啊。实际上，在前面分析的build/core/config.mk和build/core/product_config.mk等文件的加载过程中，如果发现输入的产品名称是非法的，也就是找不到相应的产品Makefile文件，那么就会通过调用error函数来产生一个错误，这时候函数check_product的返回值$?就会等于非0值。 接下来我们还要继续分析在build/envsetup.sh文件中定义的函数check_variant的实现，如下所示： 123456789101112131415[plain] view plain copyVARIANT_CHOICES=(user userdebug eng) # check to see if the supplied variant is valid function check_variant() &#123; for v in $&#123;VARIANT_CHOICES[@]&#125; do if [ &quot;$v&quot; = &quot;$1&quot; ] then return 0 fi done return 1 &#125; 这个函数的实现就简单多了。合法的编译类型定义在数组VARIANT_CHOICES中，并且它只有三个值user、userdebug和eng。其中，user表示发布版本，userdebug表示带调试信息的发布版本，而eng表标工程机版本。 最后，我们再来分析在build/envsetup.sh文件中定义的函数printconfig的实现，如下所示： 12345678910[plain] view plain copyfunction printconfig() &#123; T=$(gettop) if [ ! &quot;$T&quot; ]; then echo &quot;Couldn&apos;t locate the top of the tree. Try setting TOP.&quot; &gt;&amp;2 return fi get_build_var report_config &#125; 对比我们前面对函数check_product的分析，就会发现函数printconfig的实现与这很相似，都是通过调用get_build_var来获得相关的信息，但是这里传递给函数get_build_var的参数为report_config。 我们跳过前面build/core/config.mk和build/core/envsetup.mk等文件对目标产品Makefile文件的加载，直接跳到build/core/dumpvar.mk文件来查看与report_config这个make目标相关的逻辑： 1234567891011121314151617181920212223242526272829303132[plain] view plain copy...... dumpvar_goals := \\ $(strip $(patsubst dumpvar-%,%,$(filter dumpvar-%,$(MAKECMDGOALS)))) ..... ifneq ($(dumpvar_goals),report_config) PRINT_BUILD_CONFIG:= endif ...... ifneq ($(PRINT_BUILD_CONFIG),) HOST_OS_EXTRA:=$(shell python -c &quot;import platform; print(platform.platform())&quot;) $(info ============================================) $(info PLATFORM_VERSION_CODENAME=$(PLATFORM_VERSION_CODENAME)) $(info PLATFORM_VERSION=$(PLATFORM_VERSION)) $(info TARGET_PRODUCT=$(TARGET_PRODUCT)) $(info TARGET_BUILD_VARIANT=$(TARGET_BUILD_VARIANT)) $(info TARGET_BUILD_TYPE=$(TARGET_BUILD_TYPE)) $(info TARGET_BUILD_APPS=$(TARGET_BUILD_APPS)) $(info TARGET_ARCH=$(TARGET_ARCH)) $(info TARGET_ARCH_VARIANT=$(TARGET_ARCH_VARIANT)) $(info HOST_ARCH=$(HOST_ARCH)) $(info HOST_OS=$(HOST_OS)) $(info HOST_OS_EXTRA=$(HOST_OS_EXTRA)) $(info HOST_BUILD_TYPE=$(HOST_BUILD_TYPE)) $(info BUILD_ID=$(BUILD_ID)) $(info OUT_DIR=$(OUT_DIR)) $(info ============================================) endif 变量PRINT_BUILD_CONFIG定义在文件build/core/envsetup.mk中，默认值设置为true。当make目标为report-config的时候，变量PRINT_BUILD_CONFIG的值就会被设置为空。因此，接下来就会打印一系列用来描述编译环境配置的变量的值，也就是我们执行lunch命令后看到的输出。注意，这些环境配置相关的变量量都是在加载build/core/config.mk和build/core/envsetup.mk文件的过程中设置的，就类似于前面我们分析的TARGET_DEVICE变量的值的设置过程。 至此，我们就分析完成Android编译系统环境的初始化过程了。从分析的过程可以知道，Android编译系统环境是由build/core/config.mk、build/core/envsetup.mk、build/core/product_config.mk、AndroidProducts.mk和BoardConfig.mk等文件来完成的。这些mk文件涉及到非常多的细节，而我们这里只提供了一个大体的骨架和脉络，希望能够起到抛砖引玉的作用。","categories":[{"name":"AOSP","slug":"AOSP","permalink":"http://wenyiqingnian.xyz/categories/AOSP/"}],"tags":[{"name":"编译","slug":"编译","permalink":"http://wenyiqingnian.xyz/tags/编译/"},{"name":"aosp","slug":"aosp","permalink":"http://wenyiqingnian.xyz/tags/aosp/"}]},{"title":"添加SE安全策略","slug":"添加SE安全策略","date":"2017-03-15T11:10:10.000Z","updated":"2018-05-06T13:07:29.000Z","comments":true,"path":"2017/03/15/添加SE安全策略/","link":"","permalink":"http://wenyiqingnian.xyz/2017/03/15/添加SE安全策略/","excerpt":"","text":"一、 问题复现12341.service ro_isn /system/bin/isn.sh 2.class late_start3.user root4.oneshot kernel log会打印以下log： 1Warning! Service ro_isn needs a SELinux domain defined; please fix! 这是因为Service ro_isn没有在SELinux的监控之下，这种情况会提示你定义一个SELinux。在这种情况下，你可以：1.无视该条log，Service功能不受影响。各种权限不受限制。但是这样做会有风险。2.为Service ro_isn定义一个SELinux domain，仅添加需要的权限，未允许的权限操作会被拒绝。具体方法请参照下节。 二、解决方法1.1devices/qcom/sepolicy/common/ 目录下新增ro_isn.te文件，内容如下： 12type ro_isn, domain; type ro_isn_exec, exec_type, file_type; 2.在1devices/qcom/sepolicy/Android.mk 中添加ro_isn.te文件，内容如下： 1234BOARD_SEPOLICY_UNION := \\... \\ hostapd.te \\ ro_isn.te 3.在1devices/qcom/sepolicy/common/file_contexts 中增加如下内容： ################################### 1234567# System files#.../system/vendor/bin/slim_ap_daemonu:object_r:location_exec:s0/system/bin/isn.shu:object_r:ro_isn_exec:s0 4.在init.rc中service ro_isn下添加12345678secure context by seclabel service ro_isn /system/bin/isn.sh class late_start user root oneshot seclabel u:r:ro_isn:s0 5.编译并烧录bootimage 6.如果编译不成功，失败原因如下： 123Error while expanding policylibsepol.check_assertion_helper: neverallow on line 233 of external/sepolicy/domain.te (or line 5194 of policy.conf) violated by allow ro_isn system_file:file &#123; entrypoint &#125;;make: *** [out/target/product/msm8226/obj/ETC/sepolicy_intermediates/sepolicy] 错误 1 这是因为系统在domain.te中定义了全局的neverallow策略，与ro_isn.te中allow的策略有冲突： 12allow ro_isn system_file:file &#123; entrypoint &#125;;neverallow domain &#123; file_type -exec_type &#125;:file entrypoint; 请确定自己的service有必要需要这个权限。如无必要，请在自己的code中删除掉相关操作；如必要，可以在1external/sepolicy/domain.te 中冲突的neverallow语句中添加自己为例外： 1234neverallow &#123; domain -ro_isn&#125; &#123; file_type -exec_type &#125;:file entrypoint; 7.在service ro_isn运行时，搜索关于“ro_isn”的1avc: denied log 123&lt;6&gt;[ 13.547188](CPU:0-pid:320:logd.auditd) type=1400 audit(17468992.410:7): avc: denied &#123; entrypoint &#125; for pid=272 comm=&quot;init&quot; path=&quot;/system/bin/isn.sh &quot; dev=&quot;mmcblk0p38&quot; ino=631 scontext=u:r:ro_isn:s0 tcontext=u:object_r:system_file:s0 tclass=file 8.按照如下规则在ro_isn.te添加权限SELinux规则语句一般如下： 1allow A B:C D; 可以从log中分别获取ABCD四个参数。比如这行12345678warning log：avc: denied &#123; entrypoint &#125; for pid=272 comm=&quot;init&quot; path=&quot;/system/bin/isn.sh &quot; dev=&quot;mmcblk0p38&quot; ino=631 scontext=u:r:ro_isn:s0 tcontext=u:object_r:system_file:s0 tclass=fileavc: denied &#123; transition &#125; for pid=320 comm=&quot;init&quot; path=&quot;/system/xbin/fcgiserver.sh &quot; dev=&quot;mmcblk0p21&quot; ino=7873 scontext=u:r:init:s0 tcontext=u:r:fcgiserver:s0 tclass=process permissive=1 那么我们就得出最后的规则是： 1allow qcomsysd block_device:dir &#123; search &#125;; 1allow ro_isn system_file:file &#123; entrypoint &#125;; 重复步骤5-8,直到没有关于ro_isn的avc: denied log","categories":[{"name":"AOSP","slug":"AOSP","permalink":"http://wenyiqingnian.xyz/categories/AOSP/"}],"tags":[{"name":"编译","slug":"编译","permalink":"http://wenyiqingnian.xyz/tags/编译/"},{"name":"SEAndroid","slug":"SEAndroid","permalink":"http://wenyiqingnian.xyz/tags/SEAndroid/"}]},{"title":"fiddler抓android数据包","slug":"抓包工具 - Fiddler（如何捕获Android数据包）","date":"2016-08-03T12:20:17.000Z","updated":"2018-05-06T13:18:26.000Z","comments":true,"path":"2016/08/03/抓包工具 - Fiddler（如何捕获Android数据包）/","link":"","permalink":"http://wenyiqingnian.xyz/2016/08/03/抓包工具 - Fiddler（如何捕获Android数据包）/","excerpt":"","text":"抓包工具 - Fiddler（如何捕获Android数据包）移动设备访问网络原理 先看看移动设备是怎么去访问网络，如图所示，可以看到，移动端的数据包是从wifi出去的。可以看得出，移动端的数据包，都是要走wifi出去，所以我们可以把自己的电脑开启热点，将手机连上电脑，Fiddler开启代理后，让这些数据通过Fiddler，Fiddler就可以抓到这些包，然后发给路由器（如图）： 二、Fiddler抓取android数据包所需条件 1、电脑需要安装Fiddler 2、测试手机需要支持Wifi 3、测试手机与电脑需要同一网络 4、所测APP需支持代理 注：Iphone、Ipad、WinPhone等支持代理手机均适用 打开Wifi热点，让手机连上（我这里用的360wifi，其实随意一个都行） 打开Fidder，点击菜单栏中的 [Tools] –&gt; [Fiddler Options]Connections，设置代理端口：8888， 勾选 Allow remote computers to connect，即允许远程计算机连接Fiddler. 注：8888为默认端口号，可修改，但需注意两点，一是本机空闲端口，二是手机代理设置时要与fiddler的端口一致。 3、设置解密HTTPS的网络数据 Tools –&gt; Options-&gt; Https，勾选”Decrypt HTTPS traffic”、”Ignore server certificate errors”， 4、查看本机的无线网卡IP 设置了上面的步骤后，就可以在 Fiddler看到自己本机无线网卡的IP了（要是没有的话，重启Fiddler，或者可以在cmd中ipconfig找到自己的网卡IP，注：一定要开启本机的wifi热点）， 也可以在CMD中查看本机网卡的IP，输入命令：ipconfig， 5、手机连接本机的Wifi，并设置代理 每个品牌的手机设置wifi的方式可能不一样，这里以华为手机为例，如图8所示，将手机连接至PC的wifi 勾选“显示高级选项”-&gt; 代理 选择“手动” -&gt;输入服务器主机名和服务器端口 -&gt;IP选择“DHCP”-&gt;连接，即完成手机端设置代理操作，如图9所示 注：服务器主机名：Fiddler所在电脑IP（即开启wifi后，在fiddler或cmd中看到的无线网卡IP地址） 服务器端口： Fiddler使用的端口（即Options-Connections中设置的端口号） 6、手机下载安装Fiddler证书 连接上wifi后，手机打开浏览器输入代理IP+端口号（即是本机无线网卡IP，也是手机连接wifi时所设置的服务器主机名，这里的ip+端口号为192.168.191.1：8888），进入fiddler echo service页面，下载Fiddler的证书，如图10所示，点击FiddlerRoot certificate 下载完成后，进行安装证书 【注意】：如果打开浏览器碰到类似下面的报错，请打开Fiddler的证书解密模式（如上面的步骤3所示）：No root certificate was found. Have you enabled HTTPS traffic decryption in Fiddler yet? 设置完上面6个步骤后，即表明已设置完毕，此时用手机访问应用，就可以看到fiddler抓取到的数据包了.","categories":[{"name":"Android","slug":"Android","permalink":"http://wenyiqingnian.xyz/categories/Android/"}],"tags":[{"name":"android","slug":"android","permalink":"http://wenyiqingnian.xyz/tags/android/"},{"name":"抓包","slug":"抓包","permalink":"http://wenyiqingnian.xyz/tags/抓包/"}]},{"title":"Linux vi用法","slug":"Linux vi命令使用方法","date":"2016-07-04T13:11:15.000Z","updated":"2018-05-06T13:12:58.000Z","comments":true,"path":"2016/07/04/Linux vi命令使用方法/","link":"","permalink":"http://wenyiqingnian.xyz/2016/07/04/Linux vi命令使用方法/","excerpt":"","text":"vi编辑器支持编辑模式和命令模式，编辑模式下可以完成文本的编辑功能，命令模式下可以完成对文件的操作命令，要正确使用vi编辑器就必须熟练掌握着两种模式的切换。默认情况下，打开vi编辑器后自动进入命令模式。从编辑模式切换到命令模式使用“esc”键，从命令模式切换到编辑模式使用“A”、“a”、“O”、“o”、“I”、“i”键。 vi编辑器提供了丰富的内置命令，有些内置命令使用键盘组合键即可完成，有些内置命令则需要以冒号“：”开头输入。常用内置命令如下： 12345678910111213141516171819202122232425262728293031323334Ctrl+u：向文件首翻半屏；Ctrl+d：向文件尾翻半屏；Ctrl+f：向文件尾翻一屏；Ctrl+b：向文件首翻一屏；Esc：从编辑模式切换到命令模式；ZZ：命令模式下保存当前文件所做的修改后退出vi；:行号：光标跳转到指定行的行首；:$：光标跳转到最后一行的行首；x或X：删除一个字符，x删除光标后的，而X删除光标前的；D：删除从当前光标到光标所在行尾的全部字符；dd：删除光标行正行内容；ndd：删除当前行及其后n-1行；nyy：将当前行及其下n行的内容保存到寄存器？中，其中？为一个字母，n为一个数字；p：粘贴文本操作，用于将缓存区的内容粘贴到当前光标所在位置的下方；P：粘贴文本操作，用于将缓存区的内容粘贴到当前光标所在位置的上方；/字符串：文本查找操作，用于从当前光标所在位置开始向文件尾部查找指定字符串的内容，查找的字符串会被加亮显示；？name：文本查找操作，用于从当前光标所在位置开始向文件头部查找指定字符串的内容，查找的字符串会被加亮显示；a，bs/F/T：替换文本操作，用于在第a行到第b行之间，将F字符串换成T字符串。其中，“s/”表示进行替换操作；a：在当前字符后添加文本；A：在行末添加文本；i：在当前字符前插入文本；I：在行首插入文本；o：在当前行后面插入一空行；O：在当前行前面插入一空行；:wq：在命令模式下，执行存盘退出操作；:w：在命令模式下，执行存盘操作；:w！：在命令模式下，执行强制存盘操作；:q：在命令模式下，执行退出vi操作；:q！：在命令模式下，执行强制退出vi操作；:e文件名：在命令模式下，打开并编辑指定名称的文件；:n：在命令模式下，如果同时打开多个文件，则继续编辑下一个文件；:f：在命令模式下，用于显示当前的文件名、光标所在行的行号以及显示比例；:set number：在命令模式下，用于在最左端显示行号；:set nonumber：在命令模式下，用于在最左端不显示行号；","categories":[{"name":"Linux","slug":"Linux","permalink":"http://wenyiqingnian.xyz/categories/Linux/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"http://wenyiqingnian.xyz/tags/linux命令/"}]}]}